<?xml version="1.0" ?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>ArxivAutoJob - AI/ML 论文更新</title>
    <description>每周自动更新的AI和机器学习领域最新论文摘要</description>
    <link>https://github.com/jchenibm/ArxivAutoJob</link>
    <lastBuildDate>Sun, 10 Aug 2025 10:37:02 GMT</lastBuildDate>
    <item>
      <title>Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文提出了一种基于强化学习（RL）的众群导航方法，旨在提高机器人在面对分布外（OOD）场景时的安全性和泛化能力。核心思想是通过自适应共形推断（ACI）量化行人轨迹预测的不确定性，并将其融入到受约束的强化学习（CRL）框架中。该方法利用不确定性估计来指导智能体的行为，使其能够适应分布变化。实验结果表明，在分布内（ID）环境中，该方法达到了96.93%的成功率，相比现有技术提高了8.80%以上，碰撞次数减少了3.72倍，侵入人类轨迹的次数减少了2.43倍。在三种OOD场景中，该方法在速度变化、策略变化以及个体到群体动态的转变中表现出更强的鲁棒性。此外，该方法还在真实机器人上进行了部署，验证了其在稀疏和密集人群中的安全性和鲁棒性。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了一种基于共形不确定性处理的强化学习框架，用于提高众群导航的泛化安全性。&lt;/li&gt;&lt;li&gt;利用自适应共形推断（ACI）量化行人轨迹预测的不确定性，使其能够适应分布变化。&lt;/li&gt;&lt;li&gt;采用受约束的强化学习（CRL）框架，利用不确定性估计来指导智能体的行为，提高策略的鲁棒性。&lt;/li&gt;&lt;li&gt;在多种分布外（OOD）场景中进行了实验验证，证明了该方法在速度变化、策略变化以及个体到群体动态转变中的有效性。&lt;/li&gt;&lt;li&gt;将该方法部署到真实机器人上，验证了其在实际场景中的可行性和安全性。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**自适应共形推断 (ACI):** 用于量化人类轨迹预测的不确定性。ACI 能够在线更新其校准，因此可以快速适应底层人群动态的变化。&lt;/li&gt;&lt;li&gt;**受约束的强化学习 (CRL):** 用于将不确定性估计整合到决策过程中。CRL 增强了决策系统的可控性，并利用不确定性估计来指导学习过程和智能体的行为。&lt;/li&gt;&lt;li&gt;**结合注意力机制的策略网络：**策略网络结合了人类-人类注意力（H-H注意力）和人类-机器人注意力（H-R注意力），用于建模人类之间的交互以及人类与机器人之间的交互。&lt;/li&gt;&lt;li&gt;**PPO Lagrangian:** 使用PPO Lagrangian 进行优化，并设置两个评论家网络来计算奖励和成本的状态价值。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文提出了一种基于强化学习的轨迹规划框架，通过将共形不确定性融入到受约束的强化学习方案中，有效缓解了分布外（OOD）性能下降的问题。与传统的过度拟合且在分布变化下表现不佳的强化学习规划器不同，该方法动态利用不确定性估计来适应速度变化、策略变化以及个体到群体动态的转变。广泛的模拟结果表明，该方法在各种OOD场景中具有强大的稳定性，并且真实世界的试验证实了该方法的实际有效性。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://gen-safe-nav.github.io/&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05634v1</link>
      <guid isPermaLink="false">2508.05634v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:59:43 GMT</pubDate>
    </item>
    <item>
      <title>KuaiLive: A Real-time Interactive Dataset for Live Streaming Recommendation</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文介绍了一个名为KuaiLive的大规模真实世界直播推荐数据集，旨在弥补学术界在直播推荐领域缺乏公开数据集的现状。该数据集从中国领先的直播平台快手收集，包含23,772名用户和452,621名主播在21天内的互动日志。KuaiLive相较于现有数据集的优势在于，它包含了精确的直播间开始和结束时间戳，多种类型的实时用户互动（点击、评论、点赞、送礼），以及丰富的用户和主播侧面信息特征。这些特征能够更真实地模拟动态候选物品，并更好地建模用户和主播的行为。论文对KuaiLive进行了多角度的全面分析，并在其上评估了几种代表性的推荐方法，为未来的研究建立了强大的基准。KuaiLive可以支持直播领域的各种任务，例如Top-K推荐、点击率预测、观看时长预测和礼物价格预测。此外，其细粒度的行为数据还支持多行为建模、多任务学习和公平感知推荐的研究。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了KuaiLive，一个从快手收集的大规模真实世界直播推荐数据集，包含超过23,000名用户和450,000名主播的互动数据。&lt;/li&gt;&lt;li&gt;KuaiLive数据集包含直播间的开始和结束时间戳，允许研究人员模拟真实直播推荐场景。&lt;/li&gt;&lt;li&gt;数据集记录了多种用户行为（点击、评论、点赞、送礼），支持多任务学习和多行为建模的研究。&lt;/li&gt;&lt;li&gt;KuaiLive提供了丰富的用户、主播和直播间侧面信息特征，促进了特征感知的建模。&lt;/li&gt;&lt;li&gt;对KuaiLive数据集进行了全面的统计分析，揭示了直播场景的独特特征，例如长尾效应和用户行为的周期性。&lt;/li&gt;&lt;li&gt;在KuaiLive数据集上评估了多种代表性的推荐模型和点击率预测模型，建立了可复现的基准。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;数据收集：从快手平台收集用户行为数据，包括点击、评论、点赞和送礼等。&lt;/li&gt;&lt;li&gt;用户采样：随机抽取约25,000名活跃用户，这些用户在快手直播领域参与了所有四种类型的互动。&lt;/li&gt;&lt;li&gt;互动收集：收集用户在21天内的细粒度互动数据，并记录每次互动的时间戳。&lt;/li&gt;&lt;li&gt;侧面信息收集：收集用户、主播和直播间的侧面信息，包括人口统计学特征、内容特征和行为总结。&lt;/li&gt;&lt;li&gt;匿名化：对数据进行匿名化处理，包括ID哈希、时间戳偏移和文本数据向量化，以保护用户隐私。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;KuaiLive是一个有价值的直播推荐数据集，它具有真实性、动态性和丰富性等特点。对KuaiLive的分析揭示了直播场景的独特挑战和机遇。实验结果表明，时间感知模型和冷启动问题的解决是直播推荐的关键。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://imgkkk574.github.io/KuaiLive&lt;/li&gt;&lt;li&gt;https://github.com/THUwangcy/ReChorus&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05633v1</link>
      <guid isPermaLink="false">2508.05633v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:59:36 GMT</pubDate>
    </item>
    <item>
      <title>- ON THE GENERALIZATION OF SFT: A REINFORCEMENT LEARNING PERSPECTIVE WITH REWARD RECTIFICATION</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文提出了对大型语言模型（LLM）的监督式微调（SFT）的一种简单但理论上有依据的改进方法，旨在解决SFT与强化学习（RL）相比泛化能力有限的问题。通过数学分析，该研究揭示了标准SFT梯度隐式地编码了一种有问题的奖励结构，这可能会严重限制模型的泛化能力。为了纠正这个问题，作者提出了动态微调（DFT），通过动态地使用token的概率重新调整目标函数来稳定每个token的梯度更新。实验结果表明，这种单行代码的修改在多个具有挑战性的基准测试和基础模型上显著优于标准SFT，展示了大大提高的泛化能力。此外，该方法在离线RL设置中也显示出具有竞争力的结果，提供了一种有效但更简单的替代方案。这项工作桥接了理论洞察和实际解决方案，显著提高了SFT的性能。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;通过数学分析，将LLM的SFT视为策略梯度空间中的一种特殊的RL，并找出了SFT泛化能力有限的根本原因。&lt;/li&gt;&lt;li&gt;提出了动态微调（DFT），这是一种原则性的解决方案，通过token概率简单地重新调整标准SFT目标，有效地消除了导致意外奖励结构和无界方差的逆概率加权。&lt;/li&gt;&lt;li&gt;实验证明，DFT仅需一行代码即可显著提高LLM SFT在各种任务和模型上的性能和泛化能力。&lt;/li&gt;&lt;li&gt;DFT在多个具有挑战性的数学推理基准测试中始终且大幅优于标准SFT，表明其具有更强的泛化能力。&lt;/li&gt;&lt;li&gt;DFT在离线RL设置中表现出色，甚至超过了已建立的在线和离线RL算法，突显了其有效性和效率。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**数学分析：** 将SFT的梯度更新解释为一种特殊的策略梯度方法，具有特定的、隐式定义的奖励结构。分析表明，这种隐式奖励非常稀疏，并且与策略分配给专家行为的概率成反比，从而导致优化问题。&lt;/li&gt;&lt;li&gt;**动态微调（DFT）：** 针对每个token，使用token概率重新调整标准SFT目标，从而抵消导致意外奖励结构和无界方差的逆概率加权。具体来说，使用公式 *L* DFT ( *θ* ) = E ( *x,y* *⋆* ) *∼D*  *−*  *|y* *[⋆]* *|*   *t* =1 sg  *π* *θ* ( *y* *t* *[⋆]* *[|][ y]* *&lt;t* *[⋆]* *[, x]* [)]  log *π* *θ* ( *y* *t* *[⋆]* *[|][ y]* *&lt;t* *[⋆]* *[, x]* [)]  *.*&lt;/li&gt;&lt;li&gt;**奖励修正：** 通过乘以策略概率给出的校正反比来动态地重新加权奖励。由此产生的“动态微调”梯度为 *∇* *θ* *L* DFT ( *θ* ) = *∇* *θ* *L* SFT ( *θ* ) *·* sg( *π* *θ* ( *y* *[⋆]* *| x* )) .&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;这项工作解决了监督式微调和强化学习之间广为人知的泛化差距。作者提供了一种新颖的理论分析，证明了标准SFT梯度等同于一个策略梯度更新，该更新具有与模型置信度成反比的不适定隐式奖励。这一见解解释了SFT过度拟合的趋势及其不稳定的优化动态。在此分析的基础上，作者引入了DFT，这是一种简单但功能强大的方法，通过使用token概率动态地重新加权SFT损失来纠正此问题。这种单行修改稳定了学习过程并促进了更好的泛化。广泛的实验表明，DFT始终且显着地优于各种模型和具有挑战性的数学推理基准中的标准SFT。此外，当适应于离线RL设置时，DFT出人意料地超越了已建立的在线和离线RL算法，突显了其有效性和效率。这项工作不仅提供了对SFT的更深入的理解，而且还提供了一种实用的，具有高影响力的解决方案，可以显着缩小与更复杂的RL方法的性能差距。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/yongliang-wu/DFT&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05629v1</link>
      <guid isPermaLink="false">2508.05629v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:59:04 GMT</pubDate>
    </item>
    <item>
      <title>H-NET ++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;本论文提出了H-NET++，一个用于形态丰富的语言（MRLs）的层级动态分块模型，它无需tokenizer即可进行语言建模。传统的基于token的语言模型在处理MRLs时会遇到词汇量爆炸和分词不准确的问题。H-NET++通过端到端训练学习具有语言学信息的分割。该模型包含以下关键创新：轻量级的Transformer上下文混合器用于跨块注意力，一个双层潜在超先验用于文档级一致性，对正字法伪像（如波斯语ZWNJ）的专门处理，以及基于课程学习的训练，通过分阶段的序列长度。在14亿token的波斯语语料库上，H-NET++实现了最先进的结果，包括更好的压缩率、下游任务准确性和对正字法噪声的鲁棒性。学习到的块与波斯语形态对齐，无需显式监督，表明层级动态分块为MRLs提供了一种有效的无tokenizer解决方案，同时保持了计算效率。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**新颖架构 (H-NET++).** 一个Transformer增强的层级路由器，带有潜在超先验，适用于形态丰富的语言。&lt;/li&gt;&lt;li&gt;**课程优化.** 一种分阶段的AdamW训练方案，稳定了长序列byte级别训练。&lt;/li&gt;&lt;li&gt;**鲁棒性评估套件.** 字符级别噪声鲁棒性基准测试和一个新的波斯语黄金分割数据集。&lt;/li&gt;&lt;li&gt;**最先进的性能.** 在BPB、下游准确性和鲁棒性方面取得了领先的结果。&lt;/li&gt;&lt;li&gt;**动态分块.** 证明了动态分块方法可以学习到与语言学相关的形态单元，而不需要像传统分词器那样进行人工干预。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**层级路由器:** 使用L层路由器，每层包含一个双向GRU和一个边界预测器。边界预测使用Gumbel Softmax采样边界门。&lt;/li&gt;&lt;li&gt;**Transformer上下文混合器:** 使用一个4头多头自注意力块，将非局部上下文融入到块序列中。&lt;/li&gt;&lt;li&gt;**双层潜在超先验:** 使用全局潜在向量来捕获文档级别的形态一致性。&lt;/li&gt;&lt;li&gt;**ZWNJ感知byte嵌入:** 对波斯语的零宽度非连接符（ZWNJ）进行特殊处理，通过独立的embedding pathway，学习ZWNJ特有的模式。&lt;/li&gt;&lt;li&gt;**课程学习:** 通过三个阶段的课程学习策略逐步增加序列长度，以稳定优化。&lt;/li&gt;&lt;li&gt;**损失函数:** 综合了语言建模损失、KL散度正则化损失和形态对齐损失。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;H-Net++成功地消除了形态丰富语言的tokenization瓶颈，同时保持了计算效率。通过对波斯语的系统评估，证明了学习到的分割在多个维度上优于精心设计的tokenizer。该研究挑战了固定词汇对于实际语言建模是必要的这一普遍假设。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05628v1</link>
      <guid isPermaLink="false">2508.05628v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:59:01 GMT</pubDate>
    </item>
    <item>
      <title>How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文研究了大型语言模型 (LLMs) 如何在多轮对话中说服人类，并深入了解这种动态的机制。论文采用线性探针，一种轻量级的模型分析工具，来研究LLM中的说服能力。受到了认知科学的启发，研究人员训练了三种不同的探针，分别针对说服成功率、被说服者的性格和说服策略。实验结果表明，这些简单的探针能够有效地捕捉到说服过程中的关键方面，例如识别对话中被说服者被说服的时刻或整个数据集中说服成功的普遍发生点。此外，探针在揭示说服策略方面表现优异，甚至优于基于提示的方法，同时在计算效率上具有显著优势。这项研究提出使用探针作为一种可行的手段来研究其他复杂的行为，例如欺骗和操纵，尤其是在多轮对话环境和大规模数据集分析中，在这些情况下，基于提示的方法在计算上效率较低。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**一个使用线性探针分析LLM驱动对话中说服动态的框架。** 设计了轻量级、高效的探针，可以捕捉说服的关键方面，从而实现细粒度的turn级别分析。 这些探针不仅匹配甚至超过了基于提示的方法的性能，而且还提供了显著的计算效率，使其成为大规模说服分析的实用工具。&lt;/li&gt;&lt;li&gt;**探测说服结果、修辞策略和人格特征。** 证明了在LLM激活上训练的线性探针可以准确地识别说服成功或失败发生的位置，检测说服者使用的修辞策略，并估计整个对话中被说服者的人格。&lt;/li&gt;&lt;li&gt;**关于跨合成和人类数据集的说服轨迹的经验见解。** 结果表明，说服线索集中在人类对话的中间turn附近，但在LLM生成的对话中转移到最后的一两个turn，揭示了自然数据和合成数据之间说服展开方式的系统性差异。&lt;/li&gt;&lt;li&gt;**策略和人格之间的相关性。** 通过关联探针输出，揭示了外向性等特质会调节不同修辞策略（例如，可信度或情感诉求）的有效性，从而提供了一个关于LLM如何调整说服策略的细致入微的画面。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**线性探针 (Linear Probes):** 使用线性探针作为分析LLM内部表征的工具。线性探针是一种轻量级的模型分析技术，通过训练简单的线性分类器来预测模型内部状态（激活值）所代表的信息。&lt;/li&gt;&lt;li&gt;**多类 Logistic 回归:**  每个探针执行多类logistic回归，通过经验风险最小化在冻结的LLM激活上进行训练。&lt;/li&gt;&lt;li&gt;**训练数据集生成:** 使用GPT-4o生成用于训练线性探针的合成多轮对话数据。这些数据被标记为说服成功/失败、被说服者的人格以及说服者使用的修辞策略（逻辑、情感、可信度）。&lt;/li&gt;&lt;li&gt;**探针应用:**  将探针应用于不同对话粒度（对话结束时、每个turn后或每个token后），跟踪说服动态在对话中的演变。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;论文的核心结论是：线性探针可以有效地用于理解LLM如何在多轮对话中说服人类。通过训练探针来识别说服结果、人格特质和说服策略，研究人员能够揭示说服过程中的关键动态，并发现LLM生成的对话和人类对话之间的差异。此外，研究还表明，人格特质和说服策略之间存在复杂的关系，外向性等特质可能会影响个体对不同说服策略的反应。线性探针在计算效率方面具有优势，使其成为大规模分析LLM说服能力的可行工具。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE&lt;/li&gt;&lt;li&gt;https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/USE_POLICY.md&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05625v1</link>
      <guid isPermaLink="false">2508.05625v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:58:41 GMT</pubDate>
    </item>
    <item>
      <title>Simulating Human-Like Learning Dynamics with LLM-Empowered Agents</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文提出了一个名为 LearnerAgent 的新型多智能体框架，利用大型语言模型（LLM）来模拟真实的教学环境，旨在捕捉人类的学习行为。该框架构建了具有不同心理学基础的学习者角色（如深度学习者、表面学习者、懒惰学习者）以及一个无角色的通用学习者，用于观察基础 LLM 的默认行为。通过每周的知识获取、每月的策略选择、定期的测试和同伴互动，该框架能够追踪个体学习者在为期一年的学习过程中的动态学习进展。研究发现深度学习者能够实现持续的认知增长，表面学习者则表现出知识的脆弱性，通用学习者则表现出一种勤奋但脆弱的表面学习者特性。实验结果表明 LearnerAgent 能够较好地模拟真实场景，并为理解 LLM 的行为提供有价值的见解。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了 LearnerAgent 框架，这是一个基于 LLM 的多智能体系统，能够模拟真实的教学环境，并研究不同学习者的学习过程。&lt;/li&gt;&lt;li&gt;构建了具有不同心理学特征的学习者角色（深度学习者、表面学习者、懒惰学习者）和一个通用学习者，用于探索 LLM 的默认行为。&lt;/li&gt;&lt;li&gt;设计了一套全面的评估体系，包括每周知识获取、每月策略选择、定期测试和同伴互动，用于跟踪学习者的动态学习进展。&lt;/li&gt;&lt;li&gt;通过实验揭示了不同学习者在学习策略、推理和认知努力方面的行为模式，并验证了这些模式与他们的心理学特征密切相关。&lt;/li&gt;&lt;li&gt;发现基础 LLM 默认表现出一种“勤奋但脆弱的表面学习者”的风格，即模仿优秀学生的行为，但缺乏真正、可泛化的理解。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**LearnerAgent 框架:** 构建了一个包含教师智能体和多个学习者智能体的仿真环境，模拟为期一年的学习旅程。&lt;/li&gt;&lt;li&gt;**角色profile构建:**  教师智能体负责知识传递和任务分配，学习者智能体根据学习动机、自我概念得分和发展策略等维度被分为深度学习者、表面学习者、懒惰学习者和通用学习者四种类型。&lt;/li&gt;&lt;li&gt;**学习与改进:** 学习者每周学习新知识，每月进行复习和测试，并通过同伴互动和辩论来模拟社会学习。&lt;/li&gt;&lt;li&gt;**记忆机制:** 采用短期记忆和长期记忆机制，短期记忆用于维护对话上下文，长期记忆用于存储学习者的完整学习和改进历史，并引入了上下文相关的检索策略。&lt;/li&gt;&lt;li&gt;**综合评估:** 通过周期性的考试（初始考试、每周练习、月度考试、期末考试）和专门设计的陷阱题（Trap Questions）来评估学习者的知识和能力发展，同时还对学习者的心理变化进行评估。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;论文的主要结论是：LearnerAgent 框架能够有效地模拟人类学习的复杂动态，揭示了不同学习者的学习行为差异，并指出了基础 LLM 存在“勤奋但脆弱的表面学习者”的倾向，强调需要认知引导来帮助 LLM 发展更强大、更像人类的深入理解。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05622v1</link>
      <guid isPermaLink="false">2508.05622v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:57:46 GMT</pubDate>
    </item>
    <item>
      <title>The Missing Reward: Active Inference in the Era of Experience</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文探讨了主动推理（AIF）在开发能够从经验中学习而无需持续人工奖励工程的自主AI智能体中的关键作用。随着AI系统开始耗尽高质量的训练数据并依赖于越来越庞大的人力来进行奖励设计，当前的范式面临着重大的可扩展性挑战，这可能会阻碍真正自主智能的发展。论文认为，虽然“经验时代”——智能体从自我生成的数据中学习——是一个很有希望的方向，但它仍然依赖于大量的人工奖励函数工程，有效地将瓶颈从数据整理转移到奖励整理。论文提出了AIF可以通过用内在的自由能最小化驱动来弥合这一差距，允许智能体通过统一的贝叶斯目标来自然地平衡探索和利用。通过将大型语言模型（LLM）作为生成世界模型与AIF的原则性决策框架相结合，可以创建能够从经验中有效学习，同时保持与人类价值观一致的智能体。这种结合为开发能够在遵守计算和物理约束的同时自主发展的AI系统提供了一条引人注目的道路。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;指出了当代AI中存在的“扎根代理差距”（grounded-agency gap），即AI系统无法自主地形成、评估和调整目标。&lt;/li&gt;&lt;li&gt;论证了主动推理（AIF）通过内在的自由能最小化提供了一种有吸引力的理论基础，可以消除对持续奖励工程的需求。&lt;/li&gt;&lt;li&gt;提出了一个新颖的集成方案，其中大型语言模型（LLM）充当主动推理决策框架中学习到的生成世界模型，将现代深度学习的可扩展性与自由能原理的理论严谨性相结合。&lt;/li&gt;&lt;li&gt;将该提案置于AI发展的物理约束中，认为自由能最小化的能源效率不仅在计算上具有优势，而且可能是可持续AI进展的热力学必要条件。&lt;/li&gt;&lt;li&gt;详细分析了为什么基于奖励工程和自我博弈的方法不能实现真正的代理能力，并说明了AIF如何弥补这些不足。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**主动推理（Active Inference, AIF）:** 使用自由能最小化作为智能体的内在驱动力，取代外部奖励信号。AIF将感知和行动视为一个统一的贝叶斯推理过程，智能体通过最小化其世界模型与感官输入之间的差异（即自由能）来学习和行动。&lt;/li&gt;&lt;li&gt;**大型语言模型（Large Language Models, LLMs）:** 利用LLMs作为生成世界模型，LLMs通过大量的文本数据训练，拥有丰富的常识知识，能够理解世界实体、关系和动态。LLMs的Transformer架构可以近似贝叶斯推理，为AIF提供可扩展的推理机制。&lt;/li&gt;&lt;li&gt;**LLM-AIF架构:** 集成LLM世界模型、AIF控制循环和在线优化三个关键组件。LLM负责编码观察动态和转移概率，AIF负责指导探索、学习和行动选择，在线优化则不断更新世界模型。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文的主要结论是，主动推理（AIF）为开发能够在经验时代中自主学习的AI系统提供了一个有前景的框架。通过将AIF与大型语言模型（LLM）相结合，可以创建一个能够从自身经验中学习、适应环境变化、并保持与人类价值观一致的AI系统。AIF通过内在的自由能最小化取代了外部奖励工程，解决了当前AI系统对大量人工标注数据和精心设计的奖励函数的依赖问题。此外，AIF还具有能源效率优势，有助于实现可持续的AI发展。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05619v1</link>
      <guid isPermaLink="false">2508.05619v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:57:12 GMT</pubDate>
    </item>
    <item>
      <title>TRAJEVO: Trajectory Prediction Heuristics Design via LLM-driven Evolution</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文提出了一个名为TRAJEVO的框架，它利用大型语言模型（LLMs）自动设计轨迹预测启发式算法。轨迹预测是模拟人类行为的关键任务，尤其是在社交机器人和自动驾驶等安全关键领域。TRAJEVO通过进化算法从过去的轨迹数据中生成和优化预测启发式算法，旨在解决传统启发式方法准确性和泛化能力不足的问题，以及深度学习方法计算成本高、可解释性差和分布外（OOD）泛化能力差的问题。论文提出了两个关键创新：交叉生成精英采样（Cross-Generation Elite Sampling）以鼓励种群多样性，以及统计反馈循环（Statistics Feedback Loop），使LLM能够分析和改进替代预测。实验结果表明，TRAJEVO在多个真实世界的数据集上优于现有的启发式方法，并且在泛化到未见过的OOD真实世界数据集时，显著超越了启发式和深度学习方法。TRAJEVO为自动设计快速、可解释和可泛化的轨迹预测启发式算法迈出了有希望的一步。论文开源了源代码，以促进未来的研究。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了TRAJEVO，这是首个将LLM与进化算法相结合，用于自动发现和设计快速、可解释和鲁棒的轨迹预测启发式算法的框架，适用于真实世界的应用。&lt;/li&gt;&lt;li&gt;引入了一种交叉生成精英采样（Cross-Generation Elite Sampling）策略，以维持种群多样性。&lt;/li&gt;&lt;li&gt;引入了一个统计反馈循环（Statistics Feedback Loop），使LLM能够分析启发式算法的性能，并根据过去的轨迹数据指导改进候选算法的生成。&lt;/li&gt;&lt;li&gt;实验证明，TRAJEVO生成的启发式算法显著优于公共开放真实世界数据集上的现有启发式方法，并且表现出卓越的泛化能力，在未见过的OOD数据集上实现了超过20%的性能提升，优于传统启发式算法和深度学习方法，同时保持了计算速度和可解释性。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;进化框架：使用LLM作为核心遗传算子，通过初始种群生成、选择交叉亲本、反射（短期和长期）、交叉和精英变异等步骤，迭代生成、评估和优化启发式算法。&lt;/li&gt;&lt;li&gt;交叉生成精英采样（CGES）：维护一个跨代的高性能启发式算法历史档案，并使用基于历史精英的Softmax分布进行采样，从而增强探索能力，促进跳出局部最优解。&lt;/li&gt;&lt;li&gt;统计反馈循环（SFL）：分析启发式算法生成的不同预测策略的贡献，计算每个预测索引提供最小平均位移误差（ADE）的频率分布，并将此统计信息反馈给LLM，以指导启发式算法的改进。&lt;/li&gt;&lt;li&gt;损失函数采用均方误差（MSE）作为优化目标。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;TRAJEVO是一个利用大型语言模型和进化算法来自动设计轨迹预测启发式算法的新颖框架。实验表明，TRAJEVO生成的启发式算法不仅优于标准基准上的传统方法，而且在分布外泛化性能方面表现出色，显著优于未见数据上的深度学习模型，同时保持了快速和可解释性。TRAJEVO代表了朝着自动发现高效、可解释和可泛化轨迹预测启发式算法迈出的重要第一步，为传统的黑盒模型提供了一种实用而强大的替代方案。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/ai4co/trajevo&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05616v1</link>
      <guid isPermaLink="false">2508.05616v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:55:10 GMT</pubDate>
    </item>
    <item>
      <title>Test-Time Reinforcement Learning for GUI Grounding via Region Consistency</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文提出了一种新的方法来提高图形用户界面（GUI）接地的准确性，即能够将自然语言指令映射到屏幕上的精确坐标。该研究观察到，当模型为同一GUI元素生成多个预测时，空间重叠模式揭示了可以指导更准确定位的隐式置信度信号。论文提出了GUI-RC（区域一致性），一种测试时缩放方法，通过从多个采样预测中构建空间投票网格来识别模型显示最高一致性的共识区域。此外，还提出了GUI-RCPO（区域一致性策略优化），将这些一致性模式转换为测试时强化学习的奖励。通过计算每个预测与集体共识的对齐程度，GUI-RCPO使模型能够在推理期间迭代地优化其在未标记数据上的输出。实验表明，该方法在ScreenSpot基准测试中提高了各种架构的准确性，并且通过自监督优化进一步提高了性能。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了GUI-RC，一种用于GUI接地的测试时缩放方法，它利用跨多个预测的空间投票来提高定位精度，而无需额外的训练或标记数据。&lt;/li&gt;&lt;li&gt;介绍了GUI-RCPO，一种测试时强化学习方法，它使用区域一致性作为自监督奖励信号，使模型能够通过在未标记的GUI屏幕截图上进行策略优化来提高接地能力。&lt;/li&gt;&lt;li&gt;证明了在多个基准和模型架构上的一致改进。GUI-RC平均提高2-3%的准确率，而GUI-RCPO通过无标签优化平均提高4-5%。&lt;/li&gt;&lt;li&gt;揭示了在GUI-RCPO之后进一步应用GUI-RC可以产生额外的性能提升，证明了该方法支持逐步的、自引导的改进，而无需外部监督，并为GUI自动化提供了训练时优化的补充替代方案。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**GUI-RC (GUI Region Consistency):** 提出了一个测试时缩放方法，通过空间聚合多个模型的预测结果来提高接地精度。该方法包括三个阶段：多样本生成、空间投票和共识提取。&lt;/li&gt;&lt;li&gt;**GUI-RCPO (GUI Region Consistency Policy Optimization):**  提出了一个测试时强化学习方法，通过区域一致性信号来指导模型改进。它将GUI接地公式化为一个强化学习问题，其中VLM充当策略，并使用Group Relative Policy Optimization (GRPO) 来优化预期区域一致性奖励。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文介绍了GUI-RC，一种用于GUI接地的测试时缩放方法，它利用跨多个预测的区域一致性来提高模型性能，而无需额外的训练。基于此，进一步提出了GUI-RCPO，一种测试时强化学习方法，该方法将区域一致性转换为自监督奖励信号，使模型能够在推理期间自我改进，而无需标记数据。广泛的实验表明，该方法能够提高GUI接地性能，并很好地推广到分布外场景，为GUI代理的测试时训练开辟了新的方向。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/zju-real/gui-rcpo&lt;/li&gt;&lt;li&gt;https://zju-real.github.io/gui-rcpo&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05615v1</link>
      <guid isPermaLink="false">2508.05615v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:54:27 GMT</pubDate>
    </item>
    <item>
      <title>OmniEAR：在具身任务中对智能体推理进行基准测试</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;本文介绍了OmniEAR，一个用于评估大型语言模型在具身任务中推理能力的综合框架。现有基准测试通常提供预定义的工具集或明确的协作指令，而OmniEAR要求智能体动态地获取能力，并自主地根据任务需求确定协作策略。OmniEAR通过基于文本的环境表示，对连续的物理属性和复杂的空间关系进行建模，涵盖家庭和工业领域的1500个场景。该研究发现，当模型必须从约束条件进行推理时，性能会严重下降。虽然在显式指令下可以达到85-96%的成功率，但工具推理的性能下降到56-85%，隐式协作的性能下降到63-85%，复合任务的失败率超过50%。令人惊讶的是，完整的环境信息反而会降低协作性能，表明模型无法过滤与任务相关的约束。微调可以显著提高单智能体任务的性能（0.6%到76.3%），但对多智能体任务的增益微乎其微（1.5%到5.5%），这暴露了底层架构的局限性。这些发现表明，具身推理提出了与当前模型不同的根本性挑战，OmniEAR建立了一个严格的基准，用于评估和推进具身人工智能系统。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了OmniEAR框架，该框架通过要求智能体理解物理属性如何决定动作、能力和协作需求的情景来评估具身推理，解决了当前评估方法中的根本性差距。&lt;/li&gt;&lt;li&gt;开发了EAR-Bench，这是一个包含1500个场景的基准，具有连续的物理属性和动态能力，由EAR-Sim和自动生成管道支持。&lt;/li&gt;&lt;li&gt;提供了经验证据，表明当前的语言模型缺乏核心的具身推理能力，从显式指令转向具身推理时，性能下降超过60%，揭示了推进具身人工智能的关键要求。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**环境表示:** 使用有向图 Gt = (Vt, Et, At) 对具身环境进行形式化表示，其中节点 Vt 包含空间节点（房间和区域）、对象节点和智能体节点。每个节点维护一个属性字典 At，存储连续物理属性（如重量、温度、材料成分和几何尺寸）。边集 Et 通过静态包含关系（如“在…中”、“在…上”）和动态邻近关系 Enear 编码空间关系。&lt;/li&gt;&lt;li&gt;**任务形式化:** 每个评估任务定义为一个元组 T = (Sinit, I, Ggoal, Atask)，其中 Sinit 指定初始环境状态，I 提供自然语言指令，Ggoal 通过逻辑谓词定义成功条件，Atask 标识参与的智能体。评估目标是评估智能体是否可以生成一个动作序列 Π = (π1, . . ., πT)，将环境从 Sinit 转换为满足 Ggoal 中所有谓词的终端状态 Sfinal。&lt;/li&gt;&lt;li&gt;**动态能力管理:** 通过动态的工具-能力绑定系统，智能体的动作被分为基本动作（移动、抓取、打开）和工具依赖动作（清洁、加热、修理）。每个工具对象维护一个能力属性，指定其启用的动作。当智能体抓取工具时，系统动态地将相关能力绑定到智能体的动作集；释放工具时，这些能力自动解除绑定。&lt;/li&gt;&lt;li&gt;**涌现式协作:** 当智能体尝试对属性超过个人能力的对象执行动作时，系统启用协作请求机制。例如，如果智能体尝试移动一个重量 A t ( v , weight) &gt; C max (agent) 的对象，它可以识别合适的伙伴并协调联合动作来发起协作。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;论文提出了OmniEAR，这是一个用于评估具身智能体推理的基准，包含1500个需要从物理约束进行推理的场景。评估表明，当从显式指令转向基于约束的推理时，当前的模型表现出严重的性能下降，工具使用和协作任务的性能从超过85%下降到低于65%。确定了维持多步计划的关键参数阈值、环境信息对协作产生的矛盾影响，以及微调无法解决多智能体推理差距的问题。结果表明，具身推理需要与当前语言模型不同的根本计算机制。OmniEAR为这些局限性提供了系统的诊断，并为开发下一代具身AI系统提供了一个严格的平台。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/ZJU-REAL/OmniEmbodied&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05614v1</link>
      <guid isPermaLink="false">2508.05614v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:54:15 GMT</pubDate>
    </item>
    <item>
      <title>COOPER: CO-OPTIMIZING POLICY AND REWARD MODELS IN REINFORCEMENT LEARNING FOR LARGE LANGUAGE MODELS</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文提出了Cooper，一种用于大型语言模型（LLMs）强化学习（RL）的框架，旨在解决现有基于模型和基于规则的奖励方法的局限性。基于规则的奖励缺乏鲁棒性，而基于模型的奖励容易受到奖励欺骗的影响。Cooper通过联合优化策略模型和奖励模型来解决这些问题，利用基于规则的奖励在高精度识别正确响应方面的优势，并动态构建和选择正负样本对，以持续训练奖励模型，从而提高鲁棒性并减轻奖励欺骗的风险。论文还引入了一种混合标注策略，高效准确地生成奖励模型的训练数据，并提出了一种基于参考答案的奖励建模范式。实验结果表明，Cooper不仅减轻了奖励欺骗，还提高了端到端RL的性能。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了一个奖励建模数据集，使用结合了基于规则的验证和LLM-as-a-judge验证的混合标注策略进行标注，从而实现了高效且可靠的正确性监督。在该数据集上训练的奖励模型在VerifyBench上实现了89.42%的准确率，超过了同等规模的现有奖励模型。&lt;/li&gt;&lt;li&gt;基于规则的奖励在高精度识别正确答案方面的优势，提出了Cooper，一个同时协同优化策略模型和奖励模型的强化学习框架。该框架减轻了奖励模型驱动的RL中常见的奖励欺骗问题，并提高了整体训练性能。&lt;/li&gt;&lt;li&gt;研究表明，在RL训练过程中动态调整奖励模型的参数可以有效缓解奖励欺骗现象，为研究界如何更好地在强化学习中利用奖励模型提供了宝贵的见解。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**VerifyRM训练：** 构建基于参考答案的奖励模型，使用混合标注策略（基于规则的验证器和LLM-as-a-judge）进行数据标注，并使用二元交叉熵损失进行训练。&lt;/li&gt;&lt;li&gt;**Cooper框架：** 策略模型优化（遵循GRPO范式，使用参考答案感知奖励模型进行采样和评分，并基于组内归一化优势和KL正则化执行策略更新）和奖励模型优化（通过对比学习不断优化奖励模型，使用高精度规则信号识别的正样本和由辅助LLM将正确响应转换为不正确响应而生成的负样本）。&lt;/li&gt;&lt;li&gt;**正样本选择：** 使用基于规则的奖励函数筛选出正确的响应。&lt;/li&gt;&lt;li&gt;**负样本生成：** 使用辅助LLM将正确的推理过程转化为最终产生不正确答案的过程。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;Cooper是一个有效的RL框架，通过共同训练策略模型和奖励模型，有效地减轻了奖励欺骗的问题，并实现了比单独使用任何一种奖励类型更好的性能。动态更新奖励模型在RL训练中可以有效对抗奖励欺骗。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/zju-real/cooper&lt;/li&gt;&lt;li&gt;https://github.com/huggingface/Math-Verify&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05613v1</link>
      <guid isPermaLink="false">2508.05613v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:53:56 GMT</pubDate>
    </item>
    <item>
      <title>Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文提出了一种名为Shuffle-R1的强化学习（RL）框架，旨在提高多模态大型语言模型（MLLM）的训练效率。当前的RL训练流程存在“优势崩溃”（Advantage Collapsing）和“Rollout沉默”（Rollout Silencing）两个问题，导致次优的梯度更新和长期学习效率低下。“优势崩溃”是指一个批次中的大多数优势值都集中在接近零的区域，从而削弱了有效梯度信号。“Rollout沉默”是指随着时间的推移，对梯度有贡献的rollout比例逐渐减少。Shuffle-R1通过动态调整轨迹抽样和批次构成来解决这些问题。它引入了“成对轨迹抽样”（Pairwise Trajectory Sampling），选择具有较大优势值的高对比度轨迹对，以提高梯度信号质量；以及“基于优势的批次重排”（Advantage-based Batch Shuffle），通过策略性地重组批次来增加有价值rollout的曝光度。实验结果表明，该框架在多个推理基准测试中始终优于强大的RL基线，且计算开销极小，突出了以数据为中心的调整对于更高效的MLLM的RL训练的重要性。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;揭示了RL微调MLLM时影响训练效率的两个关键但未被充分探索的限制：优势崩溃（Advantage Collapsing）和Rollout沉默（Rollout Silencing）。&lt;/li&gt;&lt;li&gt;提出了Shuffle-R1，一种新颖的自适应RL框架，该框架动态选择高对比度轨迹并重塑训练批次，以强调信息丰富的样本。&lt;/li&gt;&lt;li&gt;通过跨模型规模以及领域内和领域外基准的广泛实验，证明了该框架的有效性和泛化性。&lt;/li&gt;&lt;li&gt;引入pairwise trajectory sampling (PTS) 选择高对比度轨迹对，增加有效梯度信息&lt;/li&gt;&lt;li&gt;引入advantage-based batch shuffle (ABS) 重新调整训练批次，优化数据利用率&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**Pairwise Trajectory Sampling (PTS):**
	*   从扩展的rollout池中选择高对比度的轨迹对，这些轨迹对具有较大的优势值。
	*   通过将具有最高优势的轨迹与具有最低优势的轨迹配对，形成信息丰富的“正-负”样本对。
	*   只保留优势对比度最大的轨迹对用于训练，从而集中学习信号并减轻优势崩溃问题。&lt;/li&gt;&lt;li&gt;**Advantage-based Batch Shuffle (ABS):**
	*   动态地重塑训练批次，优先考虑高价值样本，并增加这些样本的梯度曝光度。
	*   基于每个轨迹对的绝对优势总和分配重要性权重。
	*   根据抽样概率对原始批次进行子抽样，并重新组合子抽样批次以形成重组批次。
	*   重组批次的大小与原始批次相同，以保持梯度更新范式的一致性。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文提出了Shuffle-R1，一个简单但有效的框架，提高了多模态大型语言模型强化学习的训练效率。通过成对轨迹抽样和基于优势的批次重排，该框架在领域内和领域外任务中显著优于代表性算法和模型，证明了以数据为中心的自适应设计的价值。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/XenoZLH/Shuffle-R1&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05612v1</link>
      <guid isPermaLink="false">2508.05612v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:53:47 GMT</pubDate>
    </item>
    <item>
      <title>Non-omniscient backdoor injection with a single poison sample: Proving the one-poison hypothesis for linear regression and linear classification</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文研究了机器学习模型中的后门注入攻击，特别是当模型在来自不可信来源的大量数据上训练时。论文提出了一个核心问题：成功进行后门攻击需要多少中毒数据？现有的攻击方法通常需要大量的关于数据点的信息或者需要中毒大量的数据点。本文提出了“单样本中毒假设”，即一个攻击者在仅有一个中毒样本和有限的背景知识的情况下，就可以成功地注入一个后门，并且对良性学习任务的性能没有显著影响。更重要的是，论文证明了对于线性回归和线性分类，这个假设是成立的。对于利用良性数据分布未使用的方向作为中毒样本的攻击者，论文证明了产生的模型在功能上等同于从训练中排除中毒样本的模型。论文还在统计后门学习的基础上，证明了在所有其他情况下，中毒样本对良性学习任务的影响仍然是有限的。最后，论文通过真实的基准数据集进行了实验验证，证实了理论结果。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;证明了在对训练数据了解有限的情况下，一个中毒样本足以对线性分类或线性回归模型进行后门攻击，并且攻击误差几乎为零，概率接近1。与之前的工作不同，论文的界限经过了证明，并在真实世界的数据上得到了验证。&lt;/li&gt;&lt;li&gt;证明了如果良性数据分布的所有样本在某个方向上的投影幅度都为零，那么如果攻击者选择该方向作为其中毒样本，那么对于任何良性数据样本，干净模型和中毒模型在功能上是等效的。&lt;/li&gt;&lt;li&gt;基于Wang等人在分类方面的先前工作，并将他们的工作扩展到回归，以表明在所有其他情况下，中毒样本对良性学习任务的影响仍然有限。&lt;/li&gt;&lt;li&gt;通过在真实的基准上评估它们来验证理论结果。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**线性回归的单样本中毒后门：** 攻击者的目标是在任何一个方向上对分类器/回归器留下足够大的印记。在推理阶段，攻击者使用一个激活印记的中毒补丁来触发后门行为，从而改变预测。该攻击需要知道良性数据在某个方向上的投影大小的均值和方差。利用这些知识，攻击者可以注入一个后门，使其后门误差为零，并且如果幅度为0（在均值和方差上），则中毒样本根本不会影响良性学习任务。如果这个幅度不为0，那么对良性学习任务的影响是有限的。&lt;/li&gt;&lt;li&gt;**线性分类的单样本中毒后门：** 与线性回归类似，但损失函数与正则化的平方误差损失不同。在分类器f的梯度中，每个具有标签y的数据点x由1（如果fTxy &lt; 1）或0加权。因此，当fTxp接近1时，中毒样本xp对梯度的影响不会减小，因此攻击者不需要考虑这一点。此外，在推理阶段，攻击者必须为测试数据点x构建一个中毒补丁，该补丁将预测从fTx &lt; 0更改为fTpatch(x) ≥ 0，因此无需瞄准特定的预测值。&lt;/li&gt;&lt;li&gt;**对良性学习任务的影响：** 如果来自良性数据分布的所有样本在中毒样本上的投影都是以零为中心的，并且幅度为零，则定理2中描述的后门攻击根本不会影响良性学习任务。在非零幅度的情况下，使用先前的工作来限制中毒模型和最佳干净模型之间的差异。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;论文证明了线性回归和线性分类的单样本中毒假设。攻击表明，可以通过中毒单个数据点，并使用关于其他数据点的有限知识来成功攻击这些模型。论文的界限经过了正式证明，适用于真实世界的实例大小，并且也通过实验进行了验证。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05600v1</link>
      <guid isPermaLink="false">2508.05600v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:41:33 GMT</pubDate>
    </item>
    <item>
      <title>使用 Kolmogorov-Arnold 网络 (KANs) 优化物联网威胁检测</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文探讨了Kolmogorov-Arnold 网络（KANs）在物联网（IoT）网络入侵检测中的潜力，作为传统机器学习模型的替代方案。由于物联网网络的迅速扩张，网络安全问题日益突出，物联网网络成为网络攻击的主要目标。KANs采用可学习的激活函数，能够动态适应复杂的数据模式，这是应对不断演变的物联网威胁环境的关键优势。研究表明，KANs的性能优于传统的多层感知器（MLP），并且在准确性方面与最先进的模型（如随机森林和XGBoost）相比具有竞争力，同时为物联网网络中的入侵检测提供了更强的可解释性。这项研究通过应用KANs和特征选择，旨在优化实时物联网环境中的检测性能和计算效率，为提升物联网安全提供了新的途径。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;将 KANs 应用于 CIC IoT 2023 数据集，展示了边缘上的可学习激活函数如何提高模型的准确性和可解释性。&lt;/li&gt;&lt;li&gt;评估了 KANs 相对于传统模型（例如，随机森林、XGBoost）的性能，以证明它们在 IoT 入侵检测中的竞争性能和适用性。&lt;/li&gt;&lt;li&gt;通过符号公式生成演示了 KANs 的可解释性，从而在安全关键的 IoT 系统中实现透明的决策制定。&lt;/li&gt;&lt;li&gt;利用特征选择和 KANs 优化了实时物联网环境中的检测性能和计算效率。&lt;/li&gt;&lt;li&gt;展示了 KANs 可以通过学习复杂函数来满足 IDS 在计算资源受限的 IoT 环境中的需求。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**数据预处理：** 使用 Pandas、PyTorch 和 Scikit-Learn 等库加载 CIC IoT 2023 数据集，该数据集包含良性和恶意网络流量数据。将数据集分为训练集（67%）和测试集（33%），用于评估模型性能。&lt;/li&gt;&lt;li&gt;**特征选择：** 使用训练后的随机森林模型的 *feature_importances_* 属性评估每个特征的重要性，并选择前 N 个最相关的特征用于进一步分析。&lt;/li&gt;&lt;li&gt;**模型构建：** 构建 KAN 模型，网络拓扑结构包括输入层（神经元数量等于所选特征的数量）、两个隐藏层（分别具有 16 个和 8 个神经元，使用 MultiKAN 架构以允许特征之间的加性和乘性交互），以及一个输出层（具有 2 个神经元，表示分类为“BenignTraffic”和“MaliciousTraffic”）。&lt;/li&gt;&lt;li&gt;**数据标准化：** 使用 *StandardScaler* 对特征进行标准化，将每个特征转换为零均值和单位方差。&lt;/li&gt;&lt;li&gt;**KAN 模型训练：** 使用 Adam 优化器和 CrossEntropyLoss 训练 KAN 模型，进行多次训练迭代，通过基于训练数据调整其参数来最小化损失函数。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该研究表明，Kolmogorov-Arnold网络（KANs）能够有效地捕获IoT环境中复杂的非线性关系，并且在性能上显著优于传统的机器学习模型。优化特征选择的重要性，不仅可以通过减少变量数量来提高模型性能，还可以最大限度地减少训练时间和计算开销，从而有助于KANs在资源受限的IoT系统中的实时应用。KANs与可学习激活函数的集成代表了IoT安全框架领域的重大进步，它提供了一个强大的解决方案，可以提高网络流量分类的准确性和可解释性，这对于保护敏感数据免受不断演变的网络威胁至关重要。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05591v1</link>
      <guid isPermaLink="false">2508.05591v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:29:10 GMT</pubDate>
    </item>
    <item>
      <title>Enhancing PyKEEN with Multiple Negative Sampling Solutions for Knowledge Graph Embedding Models</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文提出了一种针对知识图谱嵌入(KGE)模型的增强方案，重点改进负采样策略。KGE模型依赖于正负样本进行训练，而负样本的生成通常依赖于人工方法。该论文指出，现有的KGE库在负采样策略方面支持不足，缺乏高级解决方案。为了解决这个问题，论文开发了一个PyKEEN的扩展，整合了一系列高级负采样器，包括静态和动态两种类型。该扩展保持了与现有PyKEEN工作流的兼容性，简化了嵌入方法的开发和定制。作为概念验证，论文对所开发的扩展进行了全面的实证研究，评估了其对不同嵌入方法在链接预测任务上的性能影响，并为设计更有效的策略提供了有价值的见解。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;设计并实现了一个模块化的PyKEEN扩展，该扩展集成了多种高级负采样技术，与现有的KGE模型无缝集成。&lt;/li&gt;&lt;li&gt;在PyKEEN框架内，标准化了负采样策略的实现，提高了代码的可重用性和可维护性。&lt;/li&gt;&lt;li&gt;提供了一套静态负采样策略，包括Random Sampling, Bernoulli Sampling, Corrupt Sampling, Typed Sampling, 和 Relational Sampling，这些策略利用了KG的结构和语义信息。&lt;/li&gt;&lt;li&gt;实现了动态负采样策略，包括Nearest Neighbor 和 Adversarial Sampling，这些策略利用预训练的辅助模型来指导负样本的选择。&lt;/li&gt;&lt;li&gt;提供详细的文档、示例和测试用例，以促进社区采用和进一步开发。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**静态负采样:** 通过定义一个标准来选择候选实体子集作为负样本池。包括以下几种策略：&lt;/li&gt;&lt;li&gt;   - **Random Sampling:** 将整个实体集作为负样本候选池，随机采样实体。&lt;/li&gt;&lt;li&gt;   - **Bernoulli Sampling:** 通过分析关系连接实体的倾向（1-to-N或N-to-1）来调整破坏头部或尾部实体的概率。&lt;/li&gt;&lt;li&gt;   - **Corrupt Sampling:** 基于出现在每个关系中的头部或尾部实体来定义负样本池。&lt;/li&gt;&lt;li&gt;   - **Typed Sampling:** 利用KG中实体和关系的类型信息来定义负样本池。&lt;/li&gt;&lt;li&gt;   - **Relational Sampling:** 假设每个头尾对只参与一个关系，基于不同的关系来生成负样本。&lt;/li&gt;&lt;li&gt;**动态负采样:** 使用预训练的辅助模型来指导信息量更大的负样本的选择。包括以下几种策略：&lt;/li&gt;&lt;li&gt;   - **Nearest Neighbor:** 使用辅助模型生成的实体向量表示，选择与头部或尾部向量最相似的k个实体作为负样本。&lt;/li&gt;&lt;li&gt;   - **Adversarial Sampling:** 使用模型预测的向量空间代替实体嵌入，选择最能迷惑模型的负样本。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文提出了PyKEEN框架的一个模块化扩展，旨在提供更广泛的标准化的负采样器实现，以填补高级负采样器可用性的空白。论文提供了一个完全兼容的静态和动态破坏策略的负采样器的实现。实验表明该扩展可以无缝集成到KGE的训练、评估和超参数优化管道中。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/ivandiliso/refactor-negative-sampler/&lt;/li&gt;&lt;li&gt;https://ivandiliso.github.io/refactor-negative-sampler&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05587v1</link>
      <guid isPermaLink="false">2508.05587v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:24:34 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型迭代学习可计算表型以治疗耐药性高血压</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文探讨了大型语言模型（LLMs）在生成可解释的可计算表型（CPs）方面的潜力，特别是针对治疗耐药性高血压。论文提出了一种*合成、执行、调试、指导*（SEDI）策略，利用LLMs生成CPs，并通过数据驱动的反馈进行迭代优化。研究评估了LLMs在零样本学习和SEDI策略下的表现，通过比较不同LLM模型在生成高血压相关临床表型CPs的准确性和简洁性。实验结果表明，结合迭代学习的LLMs能够生成可解释且相当准确的程序，其性能接近最先进的机器学习方法，同时所需的训练样本显著减少。该研究强调了LLMs在自动化CP生成方面的潜力，从而加速临床决策支持系统的开发。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了一种新的*合成、执行、调试、指导*（SEDI）策略，用于迭代优化LLM生成的可计算表型（CPs）。&lt;/li&gt;&lt;li&gt;验证了结合SEDI策略的LLMs能够生成可解释且相当准确的程序，接近最先进的机器学习方法性能，但训练数据量显著减少。&lt;/li&gt;&lt;li&gt;探索了LLMs在处理不同复杂度的临床表型（包括高血压、伴有不明原因低钾血症的高血压和表观治疗抵抗性高血压）方面的能力。&lt;/li&gt;&lt;li&gt;分析了不同提示信息（详细程度和特征数量）对LLM生成CPs性能的影响，为实际应用中LLM的最佳使用提供了指导。&lt;/li&gt;&lt;li&gt;展示了LLMs在自动化CP生成方面的潜力，从而加速临床决策支持系统的开发和应用。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**LLM-Guided CP Generation**: 使用LLMs来构建CPs。研究探索了三个目标表型，并在提示中使用两个级别的细节来指定这些表型，并提供全部特征或更小的预选特征集。&lt;/li&gt;&lt;li&gt;**Zero-shot prompts**: LLM 生成一个 Python 函数，根据可用的特征来预测表型概率，无需接收反馈。&lt;/li&gt;&lt;li&gt;**SEDI prompts**: 该过程遵循合成-执行-调试-指导 (SEDI) 循环，迭代接收关于 CP 在训练数据集上的表现的反馈。如果 CP 执行失败，LLM 会收到包含错误回溯的消息 (Debug)。如果 CP 成功，LLM 会收到性能指标，以及假阳性 (FP) 和假阴性 (FN) 案例示例，并被指示改进其表型定义以提高程序的性能 (Instruct)。在提供 FP 和 FN 案例时，会提供有关表型当前正在使用的特征的信息，以及随机抽样的特征。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;最先进的LLMs可以为高血压表型生成相当准确和简洁的CPs，即使只提供简单的提示。当提供详细且重点突出的提示并配备数据驱动的迭代反馈（即SEDI）时，LLM生成的CPs可以与使用监督ML训练的CPs相媲美。总的来说，利用图表审查示例的传统监督ML方法仍然优于LLM派生的CPs，但产生的模型更大，并且需要访问更大的专家标记数据。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/cavalab/htn-phenotyping-with-llms&lt;/li&gt;&lt;li&gt;https://GitHub.com/FacebookResearch/Nevergrad&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05581v1</link>
      <guid isPermaLink="false">2508.05581v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:15:17 GMT</pubDate>
    </item>
    <item>
      <title>Fairy ±i : the First 2-bit Complex LLM with All Parameters in {± 1, ±i}</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文提出了Fairy ±i，一种新型的2位量化框架，用于复数LLM。该研究的核心思想是，与其专注于最小化量化误差，不如首先提高全精度模型的上限（即准确率），然后再有效地将其量化为2位。Fairy ±i通过利用复数域的表示优势来提高全精度模型的准确率，将权重映射到单位的第四个根{±1, ±i}，形成一种完全对称且信息论上最优的2位表示。这种表示的优势在于，每个量化后的权重要么具有零实部，要么具有零虚部，从而实现仅使用加法和元素交换的无乘法推理。实验结果表明，Fairy ±i在PPL和下游任务方面都优于现有2位量化方法的上限，同时保持了严格的存储和计算效率。这项工作为构建在极低位约束下高度准确且实用的LLM开辟了一个新的方向。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了低位量化的一种新视角：通过提高上限（全精度模型）来提高量化模型的准确率。&lt;/li&gt;&lt;li&gt;设计了一种复数值LLM架构，利用复数域的表示优势，而无需增加参数存储。&lt;/li&gt;&lt;li&gt;设计了一种2位量化方案，将复数权重映射到单位的第四个根{±1, ±i}，充分利用了位容量，同时保留了对称性和稀疏性等关键特性。&lt;/li&gt;&lt;li&gt;实验结果表明，在PPL和下游理解任务方面，该量化模型优于现有2位量化方法的上限。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**复数值Transformer架构：** 将标准的Transformer架构扩展到复数域，包括嵌入层、自注意力层、语言模型头和前馈网络等核心组件，以处理复数值参数和激活。&lt;/li&gt;&lt;li&gt;**相位量化（PhaseQuant）：** 设计了一种确定性的量化方法，将每个全精度复数权重映射到基于其在复平面中的相位的单位的第四个根{±1, ±i}。&lt;/li&gt;&lt;li&gt;**双通道投影嵌入层：** 采用双通道投影策略，使用两个并行的嵌入层分别生成嵌入向量的实部和虚部。&lt;/li&gt;&lt;li&gt;**高效的复数值自注意力：** 采用厄米内积的实部作为注意力分数，并使用优化的实数值FlashAttention内核实现高效计算。&lt;/li&gt;&lt;li&gt;**每token的INT8激活量化：** 采用对称的每token INT8量化方案，独立处理激活的实部和虚部，并根据token的特征向量内的最大绝对值计算动态缩放因子。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;论文提出了Fairy ±i，第一个所有参数都在*{± 1 *, ±i}*中的2-bit复数LLM。 通过将复数值表示集成到Transformer中，并通过所提出的PhaseQuant将权重量化为单位的第四个根*{± 1 *, ±i}*，Fairy ±i在保留对称性、效率和硬件兼容性的同时，充分利用了2-bit空间。 实验结果表明，在perplexity和任务准确性方面，在等效模型大小下，Fairy ±i优于所有现有量化方法的准确率上限。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/PKULab1806/Fairy-plus-minus-i&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05571v1</link>
      <guid isPermaLink="false">2508.05571v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:02:23 GMT</pubDate>
    </item>
    <item>
      <title>具有 Richardson-Romberg 外推的马尔可夫 LSA 的高阶误差界限</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;本文研究了马尔可夫噪声下具有 Polyak-Ruppert (PR) 平均的线性随机逼近 (LSA) 算法的偏差和高阶误差界限。主要关注于使用常数步长 α 的算法版本，并提出了一种通过线性化技术分解偏差的新方法。分析偏差结构，表明其主要项是关于 α 的线性函数，并且无法通过 PR 平均消除。为了解决这个问题，应用了 Richardson-Romberg (RR) 外推程序，可以有效消除主要偏差项。推导了 RR 迭代的高阶矩界限，并表明主要误差项与 vanilla 平均 LSA 迭代的渐近最优协方差矩阵一致。本研究为理解和改进马尔可夫 LSA 的性能提供了新的视角和工具。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了一种量化 θn(α) 渐近偏差的新技术。该方法考虑了联合马尔可夫链 {(θk(α), Zk+1)}k∈N 的极限分布 Πα，并分析了偏差 Πα(θ0) - θ⋆。然后，应用 Aguech, Moulines, and Priouret (2000) 中的 θk(α) 线性化方法。&lt;/li&gt;&lt;li&gt;建立了 Richardson-Romberg 方法的高阶矩误差界限，其中主要项与渐近最优协方差 Σ∞ 一致。分析了其对步数 n、步长 α 和混合时间 tmix 的依赖性。&lt;/li&gt;&lt;li&gt;揭示了 Richardson-Romberg 外推法在 Markovian LSA 中减少偏差和提高收敛速度的有效性。&lt;/li&gt;&lt;li&gt;提供了一个全面的理论框架，用于分析具有 Markovian 噪声的 LSA 算法的误差行为。&lt;/li&gt;&lt;li&gt;通过数值实验验证了理论结果，并展示了所提出方法的实际有效性。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;线性化技术： 通过线性化方法对LSA算法的偏差进行分解和分析。&lt;/li&gt;&lt;li&gt;Richardson-Romberg (RR) 外推： 应用RR外推程序来消除主要的偏差项。&lt;/li&gt;&lt;li&gt;马尔可夫链理论： 使用马尔可夫链理论来研究LSA迭代的性质。&lt;/li&gt;&lt;li&gt;Wasserstein 距离： 使用Wasserstein距离来分析马尔可夫链的收敛性。&lt;/li&gt;&lt;li&gt;耦合技术： 采用耦合技术来构建马尔可夫链，并推导收缩不等式。&lt;/li&gt;&lt;li&gt;扰动理论： 利用扰动理论来分析算法的偏差。&lt;/li&gt;&lt;li&gt;Rosenthal 不等式： 应用 Rosenthal 不等式来获得线性统计量的界限。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;论文研究了 Markovian 线性随机逼近设置中 Richardson-Romberg 外推法的高阶误差界限。通过应用偏差表征的新技术，能够获得与渐近最优协方差矩阵 Σ∞ 对齐的主要项。论文分析揭示了 Richardson-Romberg 外推在减少偏差和提高马尔可夫线性随机逼近收敛速度方面的有效性。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05570v1</link>
      <guid isPermaLink="false">2508.05570v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:02:11 GMT</pubDate>
    </item>
    <item>
      <title>X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文提出了一个新的垂直联邦学习框架X-VFL，旨在解决VFL中两个关键挑战：1）需要完美对齐的数据样本（不允许缺失特征）；2）需要所有客户端参与的联合协作推理/预测（不支持单个客户端上的本地独立推理）。X-VFL通过引入两个新模块来解决这些问题：Cross Completion (XCom) 和 Decision Subspace Alignment (DS-Align)。XCom通过利用其他客户端的信息来完成/重构非对齐数据样本的缺失特征。DS-Align将本地特征与跨所有客户端的已完成和全局特征在决策子空间内对齐，从而支持每个客户端的本地独立推理。论文还提供了X-VFL训练中使用的不同算法的收敛性定理，表明SGD类型算法的收敛速度为O(1/√T)，PAGE类型算法的收敛速度为O(1/T)，其中T表示训练更新步数。在真实世界数据集上的大量实验表明，X-VFL显著优于现有方法，例如在CIFAR-10图像数据集上实现了15%的准确率提升，在MIMIC-III医疗数据集上实现了43%的准确率提升。这些结果验证了X-VFL的实际有效性和优越性，尤其是在涉及部分缺失特征和本地独立推理的场景中。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了X-VFL，一种新颖的VFL框架，旨在处理具有（部分）缺失特征的非对齐数据样本，并支持每个客户端上新的数据样本的本地独立推理。X-VFL引入了两个关键模块：Cross Completion (XCom) 和 Decision Subspace Alignment (DS-Align)，显著增强了VFL处理更复杂和实际场景的能力。&lt;/li&gt;&lt;li&gt;首次引入了VFL中具有*部分*缺失特征的实际设置，其中客户端可以保留一些本地特征，而不是完全丢失非对齐数据样本的所有本地特征。引入了缺失率的概念，用以表示客户端可能丢失的本地特征的比例。这种设置更具普遍性和现实性。&lt;/li&gt;&lt;li&gt;为X-VFL训练中使用的算法提供了理论收敛性定理，表明SGD类型算法的收敛速度为O(1/√T)，PAGE类型算法的收敛速度为O(1/T)，其中T表示训练更新步数。&lt;/li&gt;&lt;li&gt;在真实世界数据集上进行了大量实验，表明X-VFL显著优于现有VFL方法，例如在CIFAR-10上实现了15%的准确率提升，在MIMIC-III医疗数据集上实现了43%的准确率提升。验证了X-VFL在VFL中的实际有效性和优越性，尤其是在涉及部分缺失特征和本地独立推理的实际场景中。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**Cross Completion (XCom):** 该模块旨在利用其他客户端的信息来完成/重构非对齐数据样本的缺失特征。它通过建立不同客户端贡献的不相交本地特征之间的交叉互补依赖关系来实现。利用这些关系，本地客户端可以通过XCom完成其缺失的特征，从而有效地增加可用于训练和推理的数据量。&lt;/li&gt;&lt;li&gt;**Decision Subspace Alignment (DS-Align):** 该模块旨在将所有客户端的特征在决策子空间内对齐，以支持每个客户端的本地独立推理，同时保持与涉及所有客户端的协作推理相当的性能。它通过统一决策子空间内的重构特征和现有特征之间的对齐，以及本地个体特征和来自所有客户端的联合平均特征之间的对齐来实现。&lt;/li&gt;&lt;li&gt;**总体损失函数:** X-VFL框架的总体损失函数结合了决策交叉熵损失和DS-Align模块的损失，通过超参数λ1和λ2进行加权。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文提出了X-VFL，一种新颖的VFL框架，通过有效地处理具有部分缺失特征的数据集，并支持每个客户端的本地独立推理，从而解决了传统VFL的关键挑战。X-VFL引入了两个关键模块：Cross Completion (XCom) 和 Decision Subspace Alignment (DS-Align)。XCom旨在通过利用跨客户端信息来完成非对齐数据样本的缺失特征，从而有效地增加可用于训练和推理的数据量。DS-Align将本地特征与跨所有客户端的已完成和全局特征在决策子空间内对齐，从而使每个客户端都能够执行本地独立推理，即使在存在缺失特征的情况下也是如此。此外，还为X-VFL训练中使用的不同算法建立了理论收敛性定理。在真实世界数据集上的大量实验表明，X-VFL显著优于现有的VFL方法，验证了其在解决缺失特征、本地独立推理和数据不平衡等关键挑战方面的实际有效性和优越性。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05568v1</link>
      <guid isPermaLink="false">2508.05568v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:00:47 GMT</pubDate>
    </item>
    <item>
      <title>L1正则化函数支持向量机</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;本文提出了一种用于多元函数协变量二元分类的L1正则化函数支持向量机(L1-fSVM)。该方法旨在填补函数数据分析中对多元函数协变量分类研究的空白。该算法通过施加L1惩罚项，可以识别与二元响应相关的函数协变量。该算法通过回归样条估计每个轨迹的系数函数，并通过将其投影到系数函数上表示每个函数协变量的影响。然后，在这些投影得分上构建SVM分类器，并使用L1惩罚来实现特征选择。数值模拟和真实数据应用表明，该分类器在预测和特征选择方面都表现良好。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了L1正则化函数支持向量机(L1-fSVM)，用于处理多元函数协变量的二元分类问题。&lt;/li&gt;&lt;li&gt;开发了一种迭代算法来拟合L1-fSVM分类器，该算法可以同时更新系数函数和SVM中的向量。&lt;/li&gt;&lt;li&gt;通过施加L1惩罚项，实现了对相关函数协变量的识别和选择。&lt;/li&gt;&lt;li&gt;使用B-spline基函数表示系数函数，便于积分计算和满足约束条件。&lt;/li&gt;&lt;li&gt;通过仿真研究和真实数据分析验证了L1-fSVM在预测精度和特征选择方面的性能。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**L1正则化SVM:**  使用L1范数惩罚项代替L2范数，以实现特征选择，使模型更加稀疏。&lt;/li&gt;&lt;li&gt;**函数型SVM (fSVM):**  将传统的SVM扩展到函数数据，通过函数系数来表示函数协变量的影响。&lt;/li&gt;&lt;li&gt;**B-spline基函数:** 使用B-spline基函数来近似系数函数，方便计算积分和满足约束条件，同时也保证了函数的光滑性。&lt;/li&gt;&lt;li&gt;**坐标下降算法:**  使用坐标下降算法迭代更新系数函数和SVM参数，直至收敛。&lt;/li&gt;&lt;li&gt;**梯度下降算法:** 使用梯度下降算法更新系数函数中的参数。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;本文提出的L1正则化函数支持向量机(L1-fSVM)在函数数据分类中表现良好。该分类器在仿真研究中具有更好的预测精度和特征选择能力，在真实数据分析中表现出可比的性能。L1-fSVM能够识别与二元响应相关的函数协变量，有助于理解数据背后的机制。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05567v1</link>
      <guid isPermaLink="false">2508.05567v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:00:29 GMT</pubDate>
    </item>
    <item>
      <title>On the Design of Expressive and Trainable Pulse-based Quantum Machine Learning Models</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文研究了脉冲量子机器学习（QML）模型的设计，旨在实现硬件高效的同时保持模型的可表达性和可训练性。先前研究表明，具有动态对称性的脉冲模型由于其良好的损失函数景观（无贫瘠高原）而易于训练。然而，设计不当可能导致模型不可控，从而影响表达能力。本研究探讨了脉冲QML模型在保持可训练性的前提下，如何具备足够表达能力的要求。论文提出了关于系统初始状态、测量算符和动态对称李代数的必要条件，并通过数值模拟验证。研究结果为设计实用的脉冲QML模型提供了一个框架，该框架平衡了表达能力和可训练性。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了脉冲量子机器学习模型（QML）设计中表达性与可训练性之间平衡的必要条件。&lt;/li&gt;&lt;li&gt;利用Dyson级数展开分析了具有动态对称性的脉冲模型表达性，推导出了一个必要条件。&lt;/li&gt;&lt;li&gt;通过数值模拟验证了理论分析，展示了如何通过选择合适的初始状态和测量算符来保持模型表达性。&lt;/li&gt;&lt;li&gt;提出了一个设计框架，用于构建既具有表达性又具有可训练性的脉冲QML模型，特别是在NISQ时代。&lt;/li&gt;&lt;li&gt;探讨了动态对称性对模型表达性和训练的影响，为设计更有效的量子机器学习模型提供了指导。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**Dyson级数展开：** 利用Dyson级数（也称为Fliess级数）将非线性函数进行多项式展开，分析脉冲模型的表达性。&lt;/li&gt;&lt;li&gt;**李代数工具：** 结合李代数理论，评估动态对称性对模型可训练性的影响，并用于设计具有良好性质的脉冲模型。&lt;/li&gt;&lt;li&gt;**数值模拟：** 通过数值模拟验证理论分析，评估不同动态对称性下的模型表达性和可训练性。&lt;/li&gt;&lt;li&gt;**正交投影：** 将哈密顿量正交投影到李代数上，用于估计损失函数的方差。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文建立了一个综合框架，用于设计既具有表达性又具有可训练性的实用脉冲QML模型。该设计结合了Dyson多项式级数展开以及与量子系统中表现出动态对称性的贫瘠高原现象相关的现有李代数理论。理论分析和数值模拟表明，可以利用动态对称性来构建适用于在NISQ设备上进行硬件高效部署的具有表达性和可训练性的脉冲模型。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://dx.doi.org/10.1038/s41586-019-1666-5&lt;/li&gt;&lt;li&gt;https://dx.doi.org/10.1126/science.abe8770&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1016/j.scib.2021.10.017&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1126/science.abn7293&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.7566/JPSJ.90.032001&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PhysRevA.106.010101&lt;/li&gt;&lt;li&gt;http://arxiv.org/abs/1802.06002&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1038/s41467-018-07090-4&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PhysRevApplied.14.064020&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PRXQuantum.2.010101&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PhysRevResearch.3.023092&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1038/s41534-021-00493-0&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.3389/frqst.2023.1273581&lt;/li&gt;&lt;li&gt;https://dx.doi.org/10.1109/QCE53715.2022.00078&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.22331/q-2023-01-26-908&lt;/li&gt;&lt;li&gt;https://dx.doi.org/10.1109/TCAD.2024.3355277&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1038/s41534-023-00685-w&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.22331/q-2023-10-09-1130&lt;/li&gt;&lt;li&gt;https://dx.doi.org/10.1109/TQE.2022.3231124&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PhysRevResearch.5.033159&lt;/li&gt;&lt;li&gt;http://arxiv.org/abs/2304.09253&lt;/li&gt;&lt;li&gt;http://arxiv.org/abs/2402.02880&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1038/s41586-019-0980-2&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PhysRevLett.122.040504&lt;/li&gt;&lt;li&gt;http://arxiv.org/abs/2101.11020&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1038/s41467-023-36144-5&lt;/li&gt;&lt;li&gt;https://dx.doi.org/10.1103/PhysRevLett.75.346&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.22331/q-2022-09-29-824&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1038/s42254-025-00813-9&lt;/li&gt;&lt;li&gt;https://dx.doi.org/10.1088/2058-9565/ac7d06&lt;/li&gt;&lt;li&gt;https://dx.doi.org/10.1088/2058-9565/ad6fca&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PhysRevX.7.041015&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1038/s41467-021-21728-w&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1038/s41467-021-27045-6&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.22331/q-2021-10-05-558&lt;/li&gt;&lt;li&gt;https://dx.doi.org/10.1088/2058-9565/abf51a&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PhysRevLett.126.190501&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PhysRevLett.128.180505&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PRXQuantum.3.010313&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1038/s41598-023-37003-5&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1038/s41467-024-49909-3&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1038/s41467-024-49910-w&lt;/li&gt;&lt;li&gt;http://arxiv.org/abs/2310.11505&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.3389/fphy.2020.00297&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PhysRevLett.127.090506&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PhysRevA.104.012405&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PhysRevA.103.032430&lt;/li&gt;&lt;li&gt;https://proceedings.neurips.cc/paper_files/paper/2022/file/b250de41980b58d34d6aadc3f4aedd4c-Paper-Conference.pdf&lt;/li&gt;&lt;li&gt;https://dx.doi.org/10.1007/978-1-84628-615-5&lt;/li&gt;&lt;li&gt;http://arxiv.org/abs/1412.6980&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1038/s41534-024-00900-2&lt;/li&gt;&lt;li&gt;https://dx.doi.org/https://doi.org/10.1103/PhysRevA.83.062306&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05559v1</link>
      <guid isPermaLink="false">2508.05559v1</guid>
      <pubDate>Thu, 07 Aug 2025 16:40:09 GMT</pubDate>
    </item>
    <item>
      <title>MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文提出了一种名为MV-Debate的多视角agent辩论框架，用于在社交媒体中检测多模态有害内容。该框架旨在解决由于跨模态矛盾、快速文化变化和微妙语用线索导致识别讽刺、仇恨言论或虚假信息等有害内容仍然具有挑战性的问题。MV-Debate集成了四个互补的辩论agent：表面分析师、深度推理者、模态对比者和社会语境主义者，从不同的解释角度分析内容。通过迭代辩论和反思，agent在∆-gain准则下改进响应，从而确保准确性和效率。在三个基准数据集上的实验表明，MV-Debate显著优于强大的单模型和现有的多agent辩论基线，突出了多agent辩论在推进安全关键在线环境中可靠的社会意图检测方面的潜力。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了MV-Debate，一个多agent辩论框架，引导agent采用不同的推理视角，用于社交媒体中的多模态有害内容检测。&lt;/li&gt;&lt;li&gt;设计了四个特定视角的辩论agent，并结合动态反思门控机制，以提高性能。&lt;/li&gt;&lt;li&gt;在多个多模态有害内容基准数据集上进行了实验，验证了所提出方法的有效性。&lt;/li&gt;&lt;li&gt;提出了一种Top-k ∆-reflection gating策略，减少计算开销，提高效率，同时保持或提高准确率。&lt;/li&gt;&lt;li&gt;通过分配专门的角色给辩论代理，强制执行多样化的推理视角，结合表面级别、深度语义、跨模态和社会文化分析，降低了遗漏隐式或上下文相关的有害线索的风险。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**MV-Debate框架**：一个多视角agent辩论框架，包含四个专门的辩论agent（表面分析师、深度推理者、模态对比者和社会语境主义者）以及三个控制agent（裁判agent、反思agent和总结agent）。&lt;/li&gt;&lt;li&gt;**初始响应生成**：每个专门的辩论agent根据其任务视图提示生成初始响应。&lt;/li&gt;&lt;li&gt;**Top-k ∆-Reflection Gating**：引入反思机制来改进响应质量。仅当反射增益∆超过预定义阈值τ时才触发反射。&lt;/li&gt;&lt;li&gt;**历史更新**：在反思后，如果未采用较新的响应，则裁判agent将收集得分最高的响应并将其附加到历史记录中。否则，还将推理错误和修订建议添加到历史记录中。&lt;/li&gt;&lt;li&gt;**辩论循环**：从第二轮开始，将上一轮得分最高的响应纳入每个agent的历史记录中。在接下来的回合中，每个agent都利用这些推理轨迹和解决方案作为附加输入，有选择地从不同的角度提取有用的信息来完善自己的答案。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;MV-Debate通过组织具有互补推理策略的四个特定视角的agent和一个动态反思门控机制，有效地整合了跨模态证据和上下文线索，以识别复杂的社会意图，例如讽刺、仇恨言论和虚假信息。与强大的基线相比，多个基准的广泛实验证实了其卓越的准确性、效率和可解释性。除了性能提升之外，MV-Debate还生成透明的辩论记录，支持模型调试、审计和用户信任。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05557v1</link>
      <guid isPermaLink="false">2508.05557v1</guid>
      <pubDate>Thu, 07 Aug 2025 16:38:25 GMT</pubDate>
    </item>
    <item>
      <title>Adapting Vision-Language Models Without Labels: A Comprehensive Survey</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文全面调查了视觉语言模型（VLM）的无监督自适应方法。由于 VLM 在各种任务中表现出卓越的泛化能力，但直接应用于特定下游场景时性能往往次优，因此无监督自适应旨在提高 VLM 的实用性，同时保持数据效率。该研究提出了一种基于无标签视觉数据可用性和性质的分类方法，将现有方法分为四种主要范式：无数据迁移（Data-Free Transfer）、无监督领域迁移（Unsupervised Domain Transfer）、情景测试时自适应（Episodic Test-Time Adaptation）和在线测试时自适应（Online Test-Time Adaptation）。论文分析了每种范式的核心方法和自适应策略，旨在系统地理解该领域，并回顾了不同应用中的代表性基准，强调了开放性挑战和未来研究方向。论文提供了一个相关文献的活跃维护库。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了一个基于无标签视觉数据可用性的VLM无监督自适应方法的分类体系，包括无数据迁移、无监督领域迁移、情景测试时自适应和在线测试时自适应四个范式。&lt;/li&gt;&lt;li&gt;详细分析了每个范式下的核心方法和自适应策略，为理解和选择合适的自适应技术提供了系统性框架。&lt;/li&gt;&lt;li&gt;回顾了不同应用场景下的代表性基准，为评估无监督VLM自适应方法的实际效果提供了参考。&lt;/li&gt;&lt;li&gt;总结了该领域的新兴趋势，并识别了关键的科学问题，为未来的研究方向提供了指导。&lt;/li&gt;&lt;li&gt;建立并维护了一个包含相关文献的活跃知识库（GitHub 链接）。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**Data-Free Transfer:** 利用文本增强（如LLM生成描述）、图像利用（如检索或生成图像）和网络修改（如调整注意力机制）等策略。&lt;/li&gt;&lt;li&gt;**Unsupervised Domain Transfer:** 采用自训练（利用伪标签）、熵优化和外部资源利用（如LLM、知识蒸馏）等方法。&lt;/li&gt;&lt;li&gt;**Episodic Test-Time Adaptation:** 采用熵最小化、反馈信号（如扩散模型）、分布对齐和自监督学习等策略。&lt;/li&gt;&lt;li&gt;**Online Test-Time Adaptation:** 使用伪标签、记忆机制和分布建模等方法实现持续学习。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文全面概述了视觉语言模型（VLMs）无监督自适应领域，提出了基于无标签视觉数据可用性的分类体系，分析了核心方法，并指出了未来的研究方向。该综述为研究人员和从业人员提供了一个有价值的资源，促进了该领域的进一步创新。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/tim-learn/Awesome-LabelFree-VLMs&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05547v1</link>
      <guid isPermaLink="false">2508.05547v1</guid>
      <pubDate>Thu, 07 Aug 2025 16:27:37 GMT</pubDate>
    </item>
    <item>
      <title>Conformal Sets in Multiple-Choice Question Answering under Black-Box Settings with Provable Coverage Guarantees</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文旨在解决大型语言模型（LLMs）在多项选择题（MCQA）任务中由于幻觉和过度自信等问题导致的不可靠性。研究提出了一种基于频率的黑盒不确定性量化方法，利用共形预测（CP）来确保可证明的覆盖保证。该方法对每个输入进行多次独立的模型输出分布采样，并将最频繁的样本作为参考来计算预测熵（PE）。实验评估在六个LLM和四个数据集（MedMCQA、MedQA、MMLU、MMLU-Pro）上进行，结果表明，基于频率的PE在区分正确和错误预测方面优于基于logit的PE（通过AUROC衡量）。此外，该方法有效地控制了用户指定风险水平下的经验误覆盖率。研究验证了采样频率可以作为黑盒场景中基于logit概率的可行替代方案，提供了一种分布自由、模型无关的框架，用于在MCQA中进行可靠的不确定性量化，从而增强了LLM在实际应用中的可信度。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了一种基于频率的黑盒不确定性量化方法，该方法通过对模型输出分布进行多次独立采样，并使用最频繁的样本作为参考来计算预测熵（PE）。&lt;/li&gt;&lt;li&gt;验证了采样频率可以作为黑盒场景中基于logit概率的可行替代方案，为无法访问内部logit的场景提供了一种有效的不确定性量化方法。&lt;/li&gt;&lt;li&gt;通过实验证明，在多个LLM和数据集上，基于频率的PE在区分正确和错误预测方面优于基于logit的PE（通过AUROC衡量）。&lt;/li&gt;&lt;li&gt;利用共形预测（CP）框架，构建了可证明覆盖保证的预测集，确保预测集包含真实值的概率不低于预先设定的置信水平。&lt;/li&gt;&lt;li&gt;系统地分析了经验误覆盖率（EMR）和平均预测集大小（APSS），验证了构建的校准预测集的性能，并展示了模型性能与预测集大小之间的内在联系。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**频率基准预测熵 (Frequency-based PE):** 对每个多项选择题，在有效答案空间内进行M次独立采样，获得包含M个候选答案的样本集E。计算每个候选答案的频率 P̂(a)，选择频率最高的候选答案。&lt;/li&gt;&lt;li&gt;**风险控制 (Risk Control):** 利用共形预测 (CP) 框架，构建包含真实值的预测集，保证覆盖率不低于预设的置信水平 1 - α。对于校准集中的每个样本 xi，定义其非一致性得分为 si = 1 - F(xi)y∗i，其中 F(xi)y∗i 是模型对真实标签 y∗i 的输出得分。&lt;/li&gt;&lt;li&gt;**经验误覆盖率 (Emperical Miscoverage Rate)** 定义为预测集未能包含正确答案的测试样本比例，用于确保其符合用户指定的阈值。&lt;/li&gt;&lt;li&gt;**平均预测集大小 (Average Prediction Set Size)** 作为效率指标，较小的大小表示增强的实用性。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该研究提出了一种基于频率的预测熵（PE）方法，用于在黑盒设置下量化LLM在MCQA任务中的不确定性。该方法通过对模型输出分布进行多次独立采样，并使用最频繁的样本作为参考。结合共形预测框架，该方法构建了具有可证明覆盖保证的预测集。实验结果表明，基于频率的PE在不确定性量化性能方面通常优于基于logit的方法，并且可以有效地控制经验误覆盖率。这证实了采样频率可以作为黑盒LLM中logit概率的可行替代方案。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05544v1</link>
      <guid isPermaLink="false">2508.05544v1</guid>
      <pubDate>Thu, 07 Aug 2025 16:22:49 GMT</pubDate>
    </item>
    <item>
      <title>Tractable Sharpness-Aware Learning of Probabilistic Circuits</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文研究了概率电路（PCs）的过拟合问题，发现过拟合通常是由于收敛到泛化能力差的尖锐最优解所致。受到神经网络中 sharpness aware minimization 的启发，论文提出了一种基于 Hessian 的正则化方法来训练 PCs。论文的关键贡献在于证明了 PCs 的对数似然 Hessian 迹（一种 sharpness 的代理指标）可以高效计算。通过最小化 Hessian 迹，论文引入了一种基于梯度范数的正则化方法，该方法可以为 EM 算法生成简单的闭式参数更新，并且可以无缝地与基于梯度的学习方法集成。实验结果表明，该方法能够引导 PCs 收敛到更平坦的极小值，从而提高泛化性能。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;推导了树状结构 PCs 对数似然的精确完整 Hessian 的闭式表达式，并表明它可以被可追溯地计算。&lt;/li&gt;&lt;li&gt;对于一般（DAG 结构）PCs，确定了虽然完整 Hessian 可能难以处理，但其迹可以在参数数量和数据集大小中线性时间内精确计算，从而为大规模 PCs 提供了第一个实用的曲率度量。&lt;/li&gt;&lt;li&gt;引入了一种新颖的 sharpness-aware 正则化器，用于学习 PCs，该正则化器源自该 Hessian 迹。&lt;/li&gt;&lt;li&gt;表明虽然通过 EM 直接最小化 Hessian 迹会导致三次更新方程，但可以将此目标重新制定为等效的梯度范数最小化问题，从而产生具有闭式参数更新的二次方程。&lt;/li&gt;&lt;li&gt;在多个合成和真实世界数据集上进行了详尽的实验，表明正则化器强制收敛到更平坦的最优值，并有助于减少过拟合，尤其是在有限数据设置中。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**Hessian 矩阵计算:**  论文推导了树状结构 PCs 对数似然函数的完整 Hessian 矩阵的闭式表达式，并证明其可高效计算。对于一般 DAG 结构的 PCs，论文证明了 Hessian 矩阵的迹仍然可以高效计算。&lt;/li&gt;&lt;li&gt;**Sharpness-Aware 正则化:**  基于 Hessian 矩阵的迹，论文提出了一种新的 sharpness-aware 正则化方法，用于训练 PCs。该方法旨在引导模型收敛到更平坦的极小值，从而提高泛化能力。&lt;/li&gt;&lt;li&gt;**梯度范数最小化:**  为了避免直接最小化 Hessian 迹导致的三次更新方程，论文将目标函数重新表示为等价的梯度范数最小化问题，从而得到具有闭式参数更新的二次方程。&lt;/li&gt;&lt;li&gt;**EM 算法集成:**  论文将提出的 sharpness-aware 正则化方法集成到 EM 算法中，推导了闭式参数更新公式，使得该方法易于扩展并集成到现有的训练流程中。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文通过对数似然曲面几何的视角研究了 PCs 的训练问题。推导了树状结构 PCs 对数似然函数的精确完整 Hessian 的闭式表达式，并证明其可高效计算。对于一般 DAG 结构的 PCs，虽然完整 Hessian 可能难以处理，但其迹仍然可以高效计算。基于此，设计了一种新颖的正则化器，其等效的梯度范数公式产生闭式二次更新，从而实现高效优化。实验结果证实，该方法能够引导训练过程收敛到更平坦的极小值，并减少过拟合，尤其是在低数据的情况下。这项工作为研究 PCs 开辟了一个有前景的新方向。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05537v1</link>
      <guid isPermaLink="false">2508.05537v1</guid>
      <pubDate>Thu, 07 Aug 2025 16:13:24 GMT</pubDate>
    </item>
  </channel>
</rss>
