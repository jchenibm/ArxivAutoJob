<?xml version="1.0" ?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>ArxivAutoJob - AI/ML 论文更新</title>
    <description>每周自动更新的AI和机器学习领域最新论文摘要</description>
    <link>https://github.com/jchenibm/ArxivAutoJob</link>
    <lastBuildDate>Sun, 10 Aug 2025 10:20:16 GMT</lastBuildDate>
    <item>
      <title>Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文提出了一种基于强化学习的 crowd navigation 方法，旨在提高机器人在人群中导航的安全性及泛化能力，特别是在面对分布外(out-of-distribution, OOD)场景时。该方法的核心思想是通过自适应共形推断(adaptive conformal inference, ACI)来量化行人轨迹预测的不确定性，并将这些不确定性估计融入到机器人的观察中。然后，利用约束强化学习(constrained reinforcement learning, CRL)来引导机器人的行为，使其能够适应各种分布偏移。实验结果表明，该方法在分布内(in-distribution)设置下取得了显著的成功率提升，并显著减少了碰撞和侵入行人轨迹的次数。在三种不同的OOD场景中，该方法也表现出更强的鲁棒性。最后，该方法部署在真实机器人上，验证了其在稀疏和密集人群中安全导航的有效性。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了一种基于强化学习的 crowd navigation 框架，通过量化人类轨迹预测的不确定性来缓解过拟合。&lt;/li&gt;&lt;li&gt;采用自适应共形推断(ACI)来量化预测的不确定性，生成包含真实未来位置的预测集，并能在线更新以适应 crowd dynamics 的变化。&lt;/li&gt;&lt;li&gt;使用约束强化学习(CRL)将不确定性估计融入到决策过程中，引导 agent 的学习和行为。&lt;/li&gt;&lt;li&gt;在分布内(in-distribution)和分布外(out-of-distribution, OOD)场景下都实现了 state-of-the-art (SOTA) 的安全性能，并显著提高了泛化能力。&lt;/li&gt;&lt;li&gt;成功将该方法部署到真实机器人上，验证了其在真实环境中的可行性。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**轨迹预测:** 采用基于规则的 constant velocity (CV) 预测器和基于学习的 Gumbel social transformer (GST) 预测器，以验证算法对不同预测模型的适应性。&lt;/li&gt;&lt;li&gt;**不确定性量化:** 使用自适应共形推断(ACI)的动态调整版本(DtACI)来量化预测的不确定性。DtACI 通过运行多个预测误差估计器，并根据历史性能自适应地选择最佳输出，从而适应分布偏移。&lt;/li&gt;&lt;li&gt;**策略网络:** 设计包含 attention 机制的策略网络，将 uncertainty 量化结果与预测轨迹连接起来，使 RL agent 能够在决策过程中考虑 uncertainty。&lt;/li&gt;&lt;li&gt;**约束强化学习(CRL):** 采用 CRL 来增强可控性，并利用 uncertainty 估计来指导 agent 的行为。通过约束 cumulative intrusions of the robot into other agents’ uncertainty areas 来提供行为层面的指导。&lt;/li&gt;&lt;li&gt;**优化算法:** 使用 PPO Lagrangian 进行优化，设置两个 critic 来分别评估 reward 和 cost，并使用梯度下降来更新 Lagrangian 乘子。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文提出了一种基于强化学习的轨迹规划框架，通过将 conformal uncertainty 融入到 CRL 方案中，有效地缓解了 OOD 性能下降的问题。该方法能够动态利用 uncertainty 估计来适应速度变化、策略变化以及从个体到群体动态的转变。仿真和真实环境实验验证了该方法的有效性。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://gen-safe-nav.github.io/&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05634v1</link>
      <guid isPermaLink="false">2508.05634v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:59:43 GMT</pubDate>
    </item>
    <item>
      <title>KuaiLive: A Real-time Interactive Dataset for Live Streaming Recommendation</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;本文介绍了一个名为KuaiLive的真实互动直播推荐数据集，旨在解决学术界缺乏能够准确反映直播环境动态性的公开数据集的问题。该数据集来自中国领先的直播平台快手，包含了23772名用户和452621名主播在21天内的互动日志。KuaiLive相比现有数据集的优势在于：包含精确的直播间开始和结束时间戳，多种类型的实时用户互动（点击、评论、点赞、礼物），以及丰富的用户和主播的辅助信息特征。这些特征可以更真实地模拟动态候选项目，更好地建模用户和主播的行为。作者对KuaiLive进行了多角度的全面分析，并评估了几种具有代表性的推荐方法，为未来的研究建立了一个强大的基准。KuaiLive能够支持直播领域的各种任务，如top-K推荐、点击率预测、观看时长预测和礼物价格预测。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了KuaiLive，这是一个大规模的、真实的直播推荐数据集，来自快手平台，包含丰富的用户互动行为和辅助信息。&lt;/li&gt;&lt;li&gt;KuaiLive数据集包含了直播间的开始和结束时间戳，可以模拟真实直播推荐场景中候选项目的动态变化。&lt;/li&gt;&lt;li&gt;KuaiLive数据集记录了多种用户行为（点击、评论、点赞、礼物），可以用于研究多任务学习和多行为建模。&lt;/li&gt;&lt;li&gt;KuaiLive数据集包含了用户观看时长和礼物价格，可以用于更广泛的研究任务，例如观看时长预测和礼物价格预测。&lt;/li&gt;&lt;li&gt;对KuaiLive数据集进行了全面的分析，揭示了直播场景的独特特性，并为未来的研究提供了有价值的见解。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;数据收集：从快手平台收集用户在直播间的点击、评论、点赞和送礼等行为数据，以及用户、主播和直播间的相关信息。&lt;/li&gt;&lt;li&gt;数据清洗：过滤掉异常用户行为，并对数据进行匿名化处理，以保护用户隐私。&lt;/li&gt;&lt;li&gt;数据分析：对数据集进行统计分析，包括用户、主播和直播间的数量、互动行为的分布、用户活跃时间和主播直播时间等。&lt;/li&gt;&lt;li&gt;基准模型评估：在数据集上评估了多种推荐算法和点击率预测算法的性能，为未来的研究提供基准。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;KuaiLive是一个具有代表性的直播推荐数据集，它包含了丰富的用户互动行为和辅助信息，可以用于研究各种直播推荐任务。实验结果表明，直播推荐具有独特的挑战，例如冷启动问题和动态性，需要专门的模型来解决。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://imgkkk574.github.io/KuaiLive&lt;/li&gt;&lt;li&gt;https://github.com/THUwangcy/ReChorus&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05633v1</link>
      <guid isPermaLink="false">2508.05633v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:59:36 GMT</pubDate>
    </item>
    <item>
      <title>论SFT的泛化性：一种基于奖励修正的强化学习视角</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;本文提出了一种简单但理论上合理的改进监督微调（SFT）的方法，用于大型语言模型（LLM），旨在解决其与强化学习（RL）相比有限的泛化能力。通过数学分析，揭示了标准SFT梯度隐式编码了一个有问题的奖励结构，这可能严重限制模型的泛化能力。为了纠正这个问题，论文提出了动态微调（DFT），通过动态地使用token概率重新缩放目标函数，来稳定每个token的梯度更新。这种单行代码的修改显著优于多个具有挑战性的基准测试和基础模型的标准SFT，展示了大大提高的泛化性。此外，该方法在离线RL设置中表现出有竞争力的结果，提供了一种有效但更简单的替代方案。这项工作桥接了理论洞察和实际解决方案，大大提高了SFT的性能。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;从理论上建立了LLM SFT作为策略梯度空间中的一种特殊RL，指出了SFT有限泛化的根本原因，并推导出一种改进它的方法。&lt;/li&gt;&lt;li&gt;提出动态微调（DFT），一种通过token概率动态调整SFT损失的简单有效方法，以解决隐式奖励结构中的偏差问题。&lt;/li&gt;&lt;li&gt;实验表明，DFT在各种任务和模型上始终且显著地优于标准SFT，特别是在标准SFT性能下降的具有挑战性的基准上。&lt;/li&gt;&lt;li&gt;在离线RL环境中，DFT的性能优于已建立的离线和在线RL算法，突出了其有效性和效率。&lt;/li&gt;&lt;li&gt;分析了DFT对模型的影响，揭示了DFT导致token概率分布发生显著变化，这与SFT的均匀增加token概率的趋势形成对比。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;数学分析：将SFT梯度解释为一种特殊的策略梯度方法，具有隐式定义的奖励结构，该奖励结构与策略分配给专家动作的概率成反比。&lt;/li&gt;&lt;li&gt;动态微调（DFT）：通过使用token概率动态重新缩放SFT目标函数，中和导致意外奖励结构和无限方差的逆概率权重。&lt;/li&gt;&lt;li&gt;奖励修正：通过策略概率乘以校正逆比率来动态地重新加权奖励。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;本文通过理论分析和实验验证，表明标准SFT梯度等价于具有病态隐式奖励的策略梯度更新，这解释了SFT容易过拟合和优化不稳定的问题。提出的DFT方法通过动态重加权SFT损失来解决这个问题，从而稳定学习过程并促进更好的泛化。DFT在各种模型和具有挑战性的数学推理基准测试中始终优于标准SFT，并在离线RL环境中也表现出色。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/yongliang-wu/DFT&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05629v1</link>
      <guid isPermaLink="false">2508.05629v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:59:04 GMT</pubDate>
    </item>
    <item>
      <title>H-NET ++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;本论文提出了H-NET++，一种用于形态丰富的语言(MRLs)的无分词器语言建模的分层动态分块模型。该模型通过端到端训练学习语言信息分割，旨在解决传统分词器在处理MRLs时遇到的词汇量爆炸和正字法伪像问题。H-NET++的关键创新包括：(1)用于跨块注意力的轻量级Transformer上下文混合器(1.9M参数)；(2)用于文档级别一致性的两级潜在超先验；(3)对正字法伪像(如波斯语ZWNJ)的专门处理；(4)具有分阶段序列长度的基于课程的训练。在1.4B token的波斯语语料库上，H-NET++实现了最先进的结果，并在ParsGLUE上取得了显著的提升。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了新的架构（H-NET++）：一个具有潜在超先验的Transformer增强分层路由器，专为形态丰富的语言设计。&lt;/li&gt;&lt;li&gt;设计了课程优化方法：一种分阶段的AdamW训练方案，稳定了长序列字节级别训练。&lt;/li&gt;&lt;li&gt;构建了鲁棒性评估套件：包括字符级别的噪声鲁棒性基准和一个新的波斯语黄金分割数据集。&lt;/li&gt;&lt;li&gt;实现了最先进的性能：在BPB、下游任务准确性和鲁棒性方面取得了领先的结果。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;分层路由器：由L层组成，每层包含一个双向GRU和一个边界预测器。该路由器动态地将字节路由到下一层，从而实现形态感知的分割。&lt;/li&gt;&lt;li&gt;Transformer上下文混合器：一个单层多头自注意力模块，用于在块之间传递全局上下文。&lt;/li&gt;&lt;li&gt;两级潜在超先验：用于捕获文档级别的形态一致性。&lt;/li&gt;&lt;li&gt;ZWNJ感知的字节嵌入：专门处理U+200C（零宽度非连接符）字符。&lt;/li&gt;&lt;li&gt;课程学习：通过逐步增加序列长度来稳定训练过程。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;论文的主要结论是，H-NET++成功地消除了形态丰富语言的分词瓶颈，同时保持了计算效率。通过在波斯语上的系统评估，证明了学习到的分割可以超越精心设计的分词器，并在多个维度上优于现有方法：困惑度、下游任务性能、鲁棒性和形态有效性。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05628v1</link>
      <guid isPermaLink="false">2508.05628v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:59:01 GMT</pubDate>
    </item>
    <item>
      <title>How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文研究了大型语言模型（LLMs）在多轮对话中如何进行说服。面对LLM说服能力日益增强，但对其运作机制的理解有限的现状，该研究借鉴认知科学的理论，利用线性探针这一轻量级工具，分析LLM内部表征，来揭示说服过程的动态。具体来说，论文训练了三种探针，分别用于检测说服结果、评估被说服者的性格以及识别说服策略。实验结果表明，这些探针能够有效地捕捉说服过程的关键要素，例如识别对话中说服成功的关键节点。研究还发现探针在效率和性能上可以与基于提示的方法相媲美，甚至在某些情况下表现更优，尤其是在分析大规模数据集和多轮对话时。该研究为理解LLM的说服机制提供了一种有效的方法，并为未来研究LLM中的其他复杂行为（如欺骗和操纵）提供了思路。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**提出了一个使用线性探针分析LLM驱动的对话中的说服动态的框架**。该框架设计了轻量级、高效的探针，能够捕捉说服的关键方面，实现细粒度的turn级别分析。实验表明，这些探针不仅能够匹配甚至超越基于提示的方法的性能，而且还提供了显著的计算效率，使其成为大规模说服分析的实用工具。&lt;/li&gt;&lt;li&gt;**探究了说服结果、修辞策略和性格特征**。研究证明，基于LLM激活训练的线性探针可以准确地识别说服成功或失败发生的位置，检测说服者使用的修辞策略，并评估对话中被说服者的性格。&lt;/li&gt;&lt;li&gt;**对合成和人类数据集中的说服轨迹进行了实证研究**。结果显示，在人类对话中，说服线索集中在中间的turn，但在LLM生成的对话中，说服线索转移到最后的一两个turn，揭示了自然数据和合成数据在说服展开方式上的系统性差异。&lt;/li&gt;&lt;li&gt;**揭示了策略和性格之间的相关性**。通过关联探针的输出，研究发现外向性等特征调节了不同修辞策略的有效性（例如，可信度或情感诉求），从而提供了LLM如何调整说服策略的细致画面。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**线性探针（Linear Probes）：** 使用多类logistic回归，通过最小化经验风险在冻结的LLM激活上训练线性探针。探针被应用于不同的对话粒度，例如对话结束时、每个turn之后或每个token之后。&lt;/li&gt;&lt;li&gt;**多类Logistic回归：** 具体来说，训练集由d维激活和整数标签组成。i表示残差流层（即transformer block的输出），而j表示提取激活的token索引。线性探针计算softmax函数。&lt;/li&gt;&lt;li&gt;**交叉熵损失函数和梯度下降：** 使用交叉熵损失目标（sample-wise）和梯度下降来优化参数。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文的核心结论是：线性探针可以有效地用于理解LLM在多轮对话中的说服动态。这些探针能够捕捉说服过程的关键要素，例如识别对话中说服成功的关键节点。此外，研究还发现探针在效率和性能上可以与基于提示的方法相媲美，甚至在某些情况下表现更优，尤其是在分析大规模数据集和多轮对话时。该研究为未来研究LLM中的其他复杂行为（如欺骗和操纵）提供了思路。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE&lt;/li&gt;&lt;li&gt;https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/USE_POLICY.md&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05625v1</link>
      <guid isPermaLink="false">2508.05625v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:58:41 GMT</pubDate>
    </item>
    <item>
      <title>Simulating Human-Like Learning Dynamics with LLM-Empowered Agents</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;本文提出了一种名为 LearnerAgent 的新型多智能体框架，该框架基于大型语言模型（LLM）来模拟真实的教学环境，旨在捕捉人类学习行为的动态过程。研究通过构建具有不同心理学特征（如深度学习者、表面学习者和懒惰学习者）以及一个无特定性格的通用学习者，来探索类人学习的动态特性。通过每周的知识获取、每月的策略选择、周期性测试和同伴互动，可以追踪个体学习者在为期一年的学习过程中的动态学习进展。研究发现，只有深度学习者才能实现持续的认知增长，表面学习者掌握的知识较为浅薄，容易被“陷阱问题”所迷惑，而通用学习者（即基础 LLM）表现出“勤奋但脆弱的表面学习者”的特点，即模仿优秀学生的行为，但缺乏真正的、可泛化的理解。此外，研究还观察到学习者的自我概念会随着时间而变化，通用学习者尽管认知能力有限，但仍会发展出令人惊讶的高自我效能感。实验结果表明，LearnerAgent 能够较好地模拟真实场景，并对 LLM 的行为产生更深刻的见解。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了 LearnerAgent 框架，该框架能够在一个逼真的教学环境中模拟不同的学习者（深度学习者、表面学习者、懒惰学习者），每个学习者都表现出与其个人资料相符的学习策略、推理和认知努力。&lt;/li&gt;&lt;li&gt;纵向分析表明，只有深度学习者才能实现可持续的认知增长，而表面学习者的知识被证明是脆弱的，表现出走捷径的学习行为。&lt;/li&gt;&lt;li&gt;学习者的自我概念会动态发展。有特定性格的学习者保持稳定的自我认知，而无特定性格的通用学习者会发展出越来越高的自我效能感，这与人类般的自信心增长相符。&lt;/li&gt;&lt;li&gt;学习者对同伴的影响反应不同：深度学习者充当理性辩论者，表面学习者在认知上保持僵化，而懒惰学习者非常容易受到说服。&lt;/li&gt;&lt;li&gt;通用学习者（基础 LLM）默认为“勤奋但脆弱的表面学习者”风格，模仿理想学生的行为，但缺乏更深入的理解，这反映了对浅层模式匹配的依赖。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;角色扮演模拟：构建 Teacher Agent 和 Learner Agents，模拟全年学习过程。&lt;/li&gt;&lt;li&gt;Profile Construction：基于学习动机、自我概念和发展策略等多维度构建不同的学习者角色（深度学习者、表面学习者、懒惰学习者和通用学习者）。&lt;/li&gt;&lt;li&gt;Learning and Improvement：设计结构化的学习、改进和评估周期，包括每周学习和策略选择（知识巩固、认知反思），每月回顾和评估，以及同伴互动和辩论。&lt;/li&gt;&lt;li&gt;Memory Mechanism：采用短期记忆（维护对话上下文）和长期记忆（存储学习历史）机制，并通过上下文相关的检索策略动态提供最相关的记忆片段。&lt;/li&gt;&lt;li&gt;Competent Assessment：采用全面的评估策略，包括学术表现评估（初始、每周、每月和期末考试以及陷阱问题）和心理评估（自我概念评估）。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;LearnerAgent 能够有效地模拟人类学习的复杂动态，并揭示不同学习者的学习行为、发展轨迹和社会互动。基础 LLM 倾向于采用“勤奋但脆弱的表面学习者”模式，即掌握表面能力但缺乏稳健的、可泛化的理解。自我概念膨胀会导致过度自信，最终阻碍成长。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05622v1</link>
      <guid isPermaLink="false">2508.05622v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:57:46 GMT</pubDate>
    </item>
    <item>
      <title>The Missing Reward: Active Inference in the Era of Experience</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;This paper argues that Active Inference (AIF) is crucial for developing autonomous AI agents that can learn from experience without continuous human reward engineering. The current AI paradigm, relying on large human workforces for reward design, faces scalability challenges. The paper identifies a "grounded-agency gap," where AI systems struggle to autonomously formulate and adapt objectives. It proposes that AIF can bridge this gap by replacing external reward signals with an intrinsic drive to minimize free energy, enabling agents to balance exploration and exploitation. Integrating Large Language Models (LLMs) as generative world models within AIF's framework can create agents that learn efficiently from experience while aligned with human values. This combination offers a path to truly autonomous AI systems adhering to computational and physical constraints.&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Identification of the "grounded-agency gap" in contemporary AI: the inability to autonomously form, evaluate, and adapt objectives.&lt;/li&gt;&lt;li&gt;Proposal of Active Inference (AIF) as a theoretical foundation for bridging the grounded-agency gap by offering intrinsic motivation through free energy minimization, eliminating continuous reward engineering.&lt;/li&gt;&lt;li&gt;Integration of Large Language Models (LLMs) as learned generative world models within an Active Inference decision-making framework, leveraging the scalability of deep learning with the rigor of the Free Energy Principle.&lt;/li&gt;&lt;li&gt;Argument that the energy efficiency of free energy minimization in AIF is not just computationally advantageous but potentially a thermodynamic necessity for sustainable AI progress.&lt;/li&gt;&lt;li&gt;A detailed example execution trace of an autonomous lab assistant in Appendix A, demonstrating how each component of the LLM-AIF architecture operates and interacts through hierarchical message passing.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;The paper proposes a novel integration of Active Inference (AIF) with Large Language Models (LLMs).&lt;/li&gt;&lt;li&gt;LLMs serve as learned generative world models within the AIF decision-making framework.&lt;/li&gt;&lt;li&gt;The AIF framework utilizes free energy minimization as an intrinsic drive for learning and action selection.&lt;/li&gt;&lt;li&gt;Variational Free Energy (VFE) is minimized, balancing model complexity and prediction accuracy.  VFE is defined as: *F* ( *Q, o* ) = *D* KL [ *Q* ( *s* ) *∥P* ( *s* )] *−* E *Q* ( *s* ) [ln *P* ( *o|s* )]&lt;/li&gt;&lt;li&gt;Expected Free Energy (EFE) is used to select policies, balancing epistemic value (information gain) and pragmatic value (preference satisfaction). EFE is defined as: *G* ( *π* ) = *−* E *Q* ˜ [[] *[D]* *[KL]* [[] *[Q]* [(˜] *[s][|][o, π]* [˜] [)] *[||][Q]* [(˜] *[s][|][π]* [)]]] *−* E *Q* ˜ [[ln] *[ P]* [(˜] *[o][|][C]* [)]]&lt;/li&gt;&lt;li&gt;The proposed LLM-AIF architecture integrates three key components: the LLM world model, the AIF control loop, and online refinement.&lt;/li&gt;&lt;li&gt;An LLM provides the amortized inference machinery while Active Inference provides the decision rule.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;The paper concludes that Active Inference, combined with experiential data, can address the limitations of current AI paradigms related to resource saturation and externalized cognition. By turning data scarcity into an engine for self-generated experience and internalizing judgment through free-energy minimization, AIF offers a mathematically principled framework for efficiency gains and sustainable AI development. The convergence of LLMs' world knowledge with AIF's exploration offers a unique opportunity to achieve both capability and sustainability.&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05619v1</link>
      <guid isPermaLink="false">2508.05619v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:57:12 GMT</pubDate>
    </item>
    <item>
      <title>TRAJEVO: Trajectory Prediction Heuristics Design via LLM-driven Evolution</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文介绍了一种名为TRAJEVO的新框架，该框架利用大型语言模型（LLMs）来自动设计轨迹预测的启发式方法。由于传统的手工启发式方法缺乏准确性和泛化性，而深度学习方法计算成本高、可解释性有限，并且在分布外（OOD）场景中泛化能力差。TRAJEVO通过进化算法从过去的轨迹数据中生成和改进预测启发式方法。该论文提出了两项关键创新：交叉生成精英采样，以鼓励种群多样性；统计反馈循环，使LLM能够分析和改进替代预测。实验结果表明，TRAJEVO在多个真实世界数据集中优于现有的启发式方法，并且在泛化到未见过的OOD真实世界数据集时，明显优于启发式和深度学习方法。TRAJEVO标志着在自动设计快速、可解释和可泛化的轨迹预测启发式方法方面迈出了有希望的一步。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了TRAJEVO，据作者所知，这是第一个将LLM与进化算法相结合的框架，专门用于自动发现和设计快速、可解释和鲁棒的轨迹预测启发式方法，用于真实世界的应用。&lt;/li&gt;&lt;li&gt;引入了一种交叉生成精英采样策略，以保持种群多样性。&lt;/li&gt;&lt;li&gt;引入了一个统计反馈循环，使LLM能够分析启发式方法的性能，并根据过去的轨迹数据指导生成改进的候选方法。&lt;/li&gt;&lt;li&gt;实验证明TRAJEVO生成的启发式方法在公共开放的真实世界数据集上显著优于之前的启发式方法，并且表现出卓越的泛化能力，在未见过的OOD数据集上实现了超过20%的性能提升，优于传统的启发式方法和深度学习方法，同时保持了计算速度和可解释性。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;进化框架：利用LLM作为核心遗传算子，通过迭代生成、评估和改进预测启发式方法。&lt;/li&gt;&lt;li&gt;初始种群：使用任务规范和基本启发式方法（如恒定速度模型）来引导LLM生成初始种群。&lt;/li&gt;&lt;li&gt;交叉选择：从当前种群中成功执行的启发式方法中选择父代进行交叉，平衡探索和利用。&lt;/li&gt;&lt;li&gt;反馈：通过比较交叉父代的性能提供短期反馈，并通过长期反馈识别有效的设计模式。&lt;/li&gt;&lt;li&gt;交叉：使用LLM将来自两个父代启发式方法的代码组合起来，生成新的后代。&lt;/li&gt;&lt;li&gt;精英突变：使用LLM修改精英启发式方法。&lt;/li&gt;&lt;li&gt;交叉生成精英采样（CGES）：维护一个跨越所有过去世代的高性能启发式方法历史档案，以提高探索能力。&lt;/li&gt;&lt;li&gt;统计反馈循环（SFL）：分析由启发式方法生成的不同预测策略的贡献，为LLM提供有价值的信息以改进启发式方法。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;TRAJEVO代表了在自动发现高效、可解释和可泛化的轨迹预测启发式方法方面迈出的重要一步，为传统的黑盒模型提供了一种实用而强大的替代方案。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/ai4co/trajevo&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05616v1</link>
      <guid isPermaLink="false">2508.05616v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:55:10 GMT</pubDate>
    </item>
    <item>
      <title>Test-Time Reinforcement Learning for GUI Grounding via Region Consistency</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文提出了一种名为GUI-RC（区域一致性）的测试时缩放方法，以及GUI-RCPO（区域一致性策略优化）的测试时强化学习方法，用于改进图形用户界面（GUI）基础任务，即把自然语言指令映射到屏幕上的精确坐标。论文观察到，当模型对同一GUI元素生成多个预测时，空间重叠模式揭示了隐含的置信度信号，可以引导更准确的定位。GUI-RC通过构建来自多个采样预测的空间投票网格来识别模型显示最高一致性的共识区域，无需任何训练即可提高ScreenSpot基准测试的准确性。GUI-RCPO将这些一致性模式转化为奖励，用于测试时强化学习。通过计算每个预测与集体共识的对齐程度，GUI-RCPO使模型能够在推理期间迭代地细化未标记数据上的输出。实验结果表明，该方法具有通用性，GUI-RC将Qwen2.5-VL-3B-Instruct在ScreenSpotv2上的准确率从80.11%提高到83.57%，而GUI-RCPO通过自监督优化进一步将其提高到85.14%。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了GUI-RC，一种用于GUI基础的测试时缩放方法，它利用多个预测之间的空间投票来提高定位精度，而无需额外的训练或标记数据。&lt;/li&gt;&lt;li&gt;介绍了GUI-RCPO，一种测试时强化学习方法，它使用区域一致性作为自监督奖励信号，使模型能够通过在未标记的GUI屏幕截图上进行策略优化来提高基础能力。&lt;/li&gt;&lt;li&gt;证明了在多个基准和模型架构上的一致改进。GUI-RC平均提高了2-3%的准确率，而GUI-RCPO通过无标签优化平均实现了4-5%的进一步提升。&lt;/li&gt;&lt;li&gt;揭示了在GUI-RCPO之后进一步应用GUI-RC可以产生额外的性能提升，表明该方法支持渐进式的、自举的改进，而无需外部监督，并为GUI自动化提供了训练时优化的补充替代方案。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**GUI-RC：**&lt;/li&gt;&lt;li&gt;   - **多样本生成：** 使用基于温度的采样从模型中采样K个预测。&lt;/li&gt;&lt;li&gt;   - **空间投票机制：** 构建一个与屏幕截图分辨率匹配的空间投票网格v。每个采样预测都向该网格贡献投票。&lt;/li&gt;&lt;li&gt;   - **共识提取：** 通过一个原则性的选择过程提取共识区域，该过程首先识别整个网格中的最大投票数，然后找到每个像素都具有此最大投票数的所有连续区域。&lt;/li&gt;&lt;li&gt;**GUI-RCPO：**&lt;/li&gt;&lt;li&gt;   - **区域一致性作为奖励：** 对于rollout中的每个采样预测rk，计算其区域一致性奖励。该奖励衡量预测区域内的平均投票密度，通过区域大小和最大可能投票数进行标准化。&lt;/li&gt;&lt;li&gt;   - **策略优化：** 将GUI基础构建为一个强化学习问题，其中VLM充当策略θ。使用Group Relative Policy Optimization (GRPO)优化预期的区域一致性奖励。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文介绍了GUI-RC，一种用于GUI基础的测试时缩放方法，它利用多个预测之间的区域一致性来增强模型性能，而无需额外的训练。在此基础上，进一步提出了GUI-RCPO，一种测试时强化学习方法，它将区域一致性转化为自监督奖励信号，使模型能够在推理期间自我改进，而无需标记数据。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/zju-real/gui-rcpo&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05615v1</link>
      <guid isPermaLink="false">2508.05615v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:54:27 GMT</pubDate>
    </item>
    <item>
      <title>OmniEAR：在具身任务中评估智能体推理能力</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;本文提出了OmniEAR，一个综合性的框架，用于评估大型语言模型在具身任务中关于物理交互、工具使用和多智能体协作的推理能力。与现有基准测试不同，OmniEAR要求智能体动态地获取能力，并根据任务需求自主决定协作策略。该框架通过基于文本的环境表示，对跨越家庭和工业领域的1500个场景中的连续物理属性和复杂空间关系进行建模。系统的评估揭示了当模型必须从约束中进行推理时，性能会严重下降。精调可以显著提高单智能体任务的性能，但对多智能体任务的提升效果甚微，这暴露了基础架构的局限性。这些发现表明，具身推理提出了与当前模型所能解决的根本不同的挑战，从而将OmniEAR确立为评估和推进具身AI系统的严格基准。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了OmniEAR框架，该框架通过要求智能体理解物理属性如何决定动作、能力和协调需求，从而评估具身推理，解决了当前评估方法中的根本差距。&lt;/li&gt;&lt;li&gt;开发了EAR-Bench，一个包含1500个具有连续物理属性和动态能力的场景的基准测试，由EAR-Sim和自动生成流水线支持。&lt;/li&gt;&lt;li&gt;提供了经验证据，表明当前的语言模型缺乏核心的具身推理能力，从显式指令转向具身推理时，性能下降超过60%，揭示了推进具身AI的关键需求。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**环境表示：** 使用有向图 Gt = (Vt, Et, At) 对具身环境进行建模，其中 Vt 包含空间节点、对象节点和智能体节点，Et 编码空间关系，At 存储连续物理属性。&lt;/li&gt;&lt;li&gt;**任务形式化：** 每个评估任务定义为一个元组 T = (Sinit, I, Ggoal, Atask)，其中 Sinit 指定初始环境状态，I 提供自然语言指令，Ggoal 通过逻辑谓词定义成功条件，Atask 标识参与智能体。&lt;/li&gt;&lt;li&gt;**动态能力管理：** 通过动态工具-能力绑定系统，智能体的动作分为基本动作和工具相关动作，工具对象维护一个能力属性，指定其启用的动作。当智能体抓住工具时，系统动态地将相关能力绑定到智能体的动作集。&lt;/li&gt;&lt;li&gt;**突发协作：** 当智能体尝试对属性超出个人能力的对象执行动作时，系统启用协作请求机制。&lt;/li&gt;&lt;li&gt;**自动基准生成：** 通过四阶段流程，结合LLM和基于规则的验证，生成场景、任务、评估逻辑和专家轨迹。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;OmniEAR基准测试表明，当前语言模型在具身推理方面存在显著局限性，尤其是在需要从物理约束中进行推理的情况下。模型在工具使用和协作任务中的性能从85%以上降至65%以下。同时，结果揭示了维持多步计划的关键参数阈值、环境信息对协作的悖论性影响，以及微调无法解决多智能体推理差距的问题。这些结果表明，具身推理需要与当前语言模型不同的计算机制。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/ZJU-REAL/OmniEmbodied&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05614v1</link>
      <guid isPermaLink="false">2508.05614v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:54:15 GMT</pubDate>
    </item>
    <item>
      <title>COOPER: CO-OPTIMIZING POLICY AND REWARD MODELS IN REINFORCEMENT LEARNING FOR LARGE LANGUAGE MODELS</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文提出了Cooper，一个用于大型语言模型（LLMs）的强化学习（RL）框架，旨在解决现有基于模型和基于规则的奖励范式的局限性。基于规则的奖励缺乏鲁棒性，而基于模型的奖励容易受到奖励攻击。Cooper通过联合优化策略模型和奖励模型来应对这些问题，利用基于规则的奖励在识别正确响应时的高精度，并动态构建和选择正负样本对，以持续训练奖励模型。为了支持Cooper，论文还引入了一种混合标注策略，以高效准确地生成奖励模型的训练数据，并提出了一个基于参考的奖励建模范式，其中奖励模型以参考答案作为输入。实验结果表明，Cooper不仅减轻了奖励攻击，还提高了端到端RL的性能，例如在Qwen2.5-1.5B-Instruct上平均准确率提高了0.54%。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了一个新的奖励建模数据集，该数据集使用混合标注策略进行标注，结合了基于规则的验证和基于LLM的验证，实现了高效且可靠的正确性监督。在该数据集上训练的奖励模型在VerifyBench上实现了89.42%的准确率，超过了现有同等规模的奖励模型。&lt;/li&gt;&lt;li&gt;基于基于规则的奖励在识别正确答案时的高精度，提出了Cooper，一个同时共同优化策略模型和奖励模型的强化学习框架。该框架缓解了在基于奖励模型的RL中常见的奖励攻击问题，并提高了整体训练性能。&lt;/li&gt;&lt;li&gt;研究表明，在RL训练过程中动态调整奖励模型的参数可以有效缓解奖励攻击现象，为研究界如何更好地在强化学习中利用奖励模型提供了有价值的见解。&lt;/li&gt;&lt;li&gt;提出了基于参考答案的奖励模型VerifyRM，通过引入参考答案作为奖励模型的输入，提高了奖励模型在推理任务中的准确性。&lt;/li&gt;&lt;li&gt;提出了一个两阶段训练流程：策略模型优化和奖励模型优化，通过协同优化策略模型和奖励模型，提高了策略模型的推理能力。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**VerifyRM训练方法:**
   *   **数据准备:** 收集包含推理问题、参考答案和模型生成的补全的数据三元组。使用了7个常用的数学推理数据集，并使用11个主流LLM生成补全。采用混合标注策略，结合基于规则的验证器(Math-verify)和LLM-as-a-judge(Qwen3-4B)进行自动正确性标注。&lt;/li&gt;&lt;li&gt;**VerifyRM的奖励模型训练:**
   *   将奖励模型构建为一个文本分类器，并引入参考答案作为奖励模型的输入。使用二元交叉熵损失进行训练，目标函数为公式(1)和(2)。&lt;/li&gt;&lt;li&gt;**Cooper强化学习框架:**
   *   **阶段1: 策略模型优化:** 遵循GRPO范式，使用策略模型对每个训练样本采样一组响应，并使用参考答案感知的奖励模型对每个 rollout进行评估，根据组内归一化优势和KL正则化更新策略。奖励计算公式如公式(3)。&lt;/li&gt;&lt;li&gt;**阶段2: 奖励模型优化:** 使用对比学习优化奖励模型，通过最大化正确响应和不正确响应之间的奖励差异来更新奖励模型参数。优化目标函数如公式(4)。
   *   **正样本选择:**  利用基于规则的奖励的高精度，从rollout中选择被规则判断为正确的响应作为正样本，如公式(5)。
   *   **负样本生成:** 使用辅助LLM，通过一个精心设计的提示，将正确的推理过程转化为最终产生错误答案的过程，从而生成负样本，如公式(6)。引入验证机制，确保生成的响应确实不正确。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;论文的核心结论是：Cooper是一个有效的强化学习框架，它通过协同训练策略模型和奖励模型来缓解奖励攻击问题，并提高整体训练性能。通过结合基于规则的奖励的高精度和基于模型的奖励的鲁棒性，Cooper优于单独使用任何一种奖励类型。此外，基于参考答案的奖励模型VerifyRM在VerifyBench基准测试中优于现有的同等规模的模型。研究结果表明，在RL训练过程中动态更新奖励模型可以有效地对抗奖励攻击。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/zju-real/cooper&lt;/li&gt;&lt;li&gt;https://github.com/huggingface/Math-Verify&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05613v1</link>
      <guid isPermaLink="false">2508.05613v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:53:56 GMT</pubDate>
    </item>
    <item>
      <title>Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文提出了Shuffle-R1，一个针对多模态大型语言模型（MLLM）的强化学习（RL）框架，旨在提升训练效率。论文指出，现有的RL训练流程存在两个未充分探索的问题：优势崩溃（Advantage Collapsing），即批次中的大多数优势值集中在接近零的区域，导致梯度更新不佳；以及Rollout沉默（Rollout Silencing），即随着训练的进行，产生非零梯度的rollout比例逐渐减少，造成计算资源的浪费。为了解决这些问题，Shuffle-R1引入了（1）成对轨迹采样（Pairwise Trajectory Sampling），选择具有较大优势差异的高对比度轨迹来改善梯度信号质量；以及（2）基于优势的批次洗牌（Advantage-based Batch Shuffle），通过策略性地重组批次，增加有价值的rollout的曝光度。实验结果表明，该框架在多个推理基准测试中优于现有的强化学习基线，且计算开销很小，强调了以数据为中心的自适应方法对于MLLM中更高效的RL训练的重要性。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;揭示了在MLLM的RL微调中影响训练效率的两个关键但未被充分探索的限制：优势崩溃（Advantage Collapsing）和Rollout沉默（Rollout Silencing）。&lt;/li&gt;&lt;li&gt;提出了Shuffle-R1，一种新颖的自适应RL框架，可以动态选择高对比度轨迹并重塑训练批次，以强调信息量大的样本。&lt;/li&gt;&lt;li&gt;通过跨模型规模和领域内外基准的广泛实验，证明了该框架的有效性和泛化性。&lt;/li&gt;&lt;li&gt;提出了成对轨迹采样（Pairwise Trajectory Sampling），选择具有较大优势差异的高对比度轨迹来改善梯度信号质量。&lt;/li&gt;&lt;li&gt;提出了基于优势的批次洗牌（Advantage-based Batch Shuffle），通过策略性地重组批次，增加有价值的rollout的曝光度。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**Pairwise Trajectory Sampling (PTS)**: 从扩展的 rollout 池中选择具有大优势值的高对比度轨迹对，从而集中学习信号以减轻优势崩溃。&lt;/li&gt;&lt;li&gt;**Advantage-based Batch Shuffle (ABS)**: 动态地重塑训练批次，以优先处理信息量大的轨迹，同时降低无效轨迹的权重，从而缓解Rollout沉默问题，提高数据利用率。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;Shuffle-R1是一种简单但有效的框架，可以提高多模态大型语言模型强化学习的训练效率。通过成对轨迹采样和基于优势的批次洗牌，Shuffle-R1在领域内外任务中都显著优于代表性算法和模型，证明了以数据为中心的自适应设计的价值。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/XenoZLH/Shuffle-R1&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05612v1</link>
      <guid isPermaLink="false">2508.05612v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:53:47 GMT</pubDate>
    </item>
    <item>
      <title>Non-omniscient backdoor injection with a single poison sample: Proving the one-poison hypothesis for linear regression and linear classification</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文研究了机器学习模型中的后门注入攻击，特别是针对线性回归和线性分类模型。论文提出了一个名为“单毒药假设”的理论，即在训练数据中仅使用一个恶意样本，且攻击者对训练数据了解有限的情况下，也能成功地将后门植入模型，并且不会对模型的良性学习任务产生显著影响。论文通过理论证明和实验验证，证实了这一假设在线性回归和线性分类模型中的有效性。研究表明，攻击者可以利用数据集中良性数据分布未使用的方向上的单个毒药样本实现后门注入，且不会影响良性数据的学习。此外，论文还建立了在其他情况下毒药样本对良性学习任务影响的界限。这项研究对于理解和防范机器学习模型中的数据投毒攻击具有重要意义。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;证明了在对训练数据了解甚少的情况下，仅使用一个中毒样本足以对线性分类或线性回归模型进行后门攻击，且攻击错误概率接近于零。与之前的工作不同，论文中的界限经过了证明并在真实数据上得到了验证。&lt;/li&gt;&lt;li&gt;证明了如果良性数据分布的所有样本在某个方向上的投影幅度为零，那么对于任何良性数据样本，干净模型和中毒模型在功能上是等效的。攻击者选择该方向用于其单个中毒样本。&lt;/li&gt;&lt;li&gt;扩展了Wang et al. [16] 在分类方面的工作，并将其扩展到回归，以表明在所有其他情况下，中毒样本对良性学习任务的影响仍然有限。&lt;/li&gt;&lt;li&gt;通过在现实基准上评估来验证理论结果。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;理论证明：通过数学方法证明单毒药假设在线性回归和线性分类模型中的有效性，包括构建攻击者模型和推导后门攻击成功率的下界。&lt;/li&gt;&lt;li&gt;函数等价分析：在特定条件下（良性数据在某方向上的投影幅度为零），证明干净模型和中毒模型在功能上的等价性，从而说明单毒药攻击不会影响良性学习任务。&lt;/li&gt;&lt;li&gt;统计风险分析：基于Wang et al. [16] 的工作，推导中毒样本对良性学习任务影响的界限，并将其扩展到线性回归模型。&lt;/li&gt;&lt;li&gt;实验验证：在真实数据集上进行实验，验证理论结果，并评估单毒药攻击的有效性和对良性学习任务的影响。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;论文证明了线性回归和线性分类的单毒药假设。研究表明，通过毒化单个数据点，且对其他数据点了解有限，可以成功攻击这些模型。论文中的界限经过了正式证明，适用于真实世界的实例大小，并且通过实验也得到了验证。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05600v1</link>
      <guid isPermaLink="false">2508.05600v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:41:33 GMT</pubDate>
    </item>
    <item>
      <title>使用 Kolmogorov-Arnold 网络 (KANs) 优化物联网威胁检测</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文探讨了Kolmogorov-Arnold网络 (KANs) 在物联网 (IoT) 网络入侵检测中的潜力，作为传统机器学习模型的替代方案。随着物联网的快速发展，安全问题日益突出，物联网网络已成为网络攻击的主要目标。KANs 采用可学习的激活函数，克服了传统多层感知机 (MLP) 的局限性，同时实现了与随机森林和 XGBoost 等先进模型相媲美的准确性。此外，KANs 为物联网网络中的入侵检测提供了卓越的可解释性，使其成为一种更具优势的选择。研究结果表明，KANs 在提高物联网安全性和威胁检测能力方面具有显著潜力。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;将 KANs 应用于 CIC IoT 2023 数据集，展示了边缘的可学习激活函数如何提高模型的准确性和可解释性。&lt;/li&gt;&lt;li&gt;评估 KANs 与传统模型（例如，随机森林、XGBoost）的性能，以证明其具有竞争力的性能和适用于物联网入侵检测。&lt;/li&gt;&lt;li&gt;通过符号公式生成展示了 KANs 的可解释性，从而在安全关键型物联网系统中实现透明的决策制定。&lt;/li&gt;&lt;li&gt;探讨了使用 KANs 作为深度学习模型中 MLP 层的替代方案，强调了其在近似复杂函数方面的潜力，这对于物联网环境中的 IDS 至关重要。&lt;/li&gt;&lt;li&gt;详细评估了各种机器学习模型（包括 KANs）在物联网入侵检测中的性能，考虑了精度、召回率、F1 分数、训练时间和预测时间等指标。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**数据预处理：** 使用 Pandas、PyTorch 和 Scikit-Learn 等库加载 CIC IoT 2023 数据集，并将数据分为训练集 (67%) 和测试集 (33%)，以评估模型性能。&lt;/li&gt;&lt;li&gt;**特征选择：** 使用 StandardScaler 规范化特征，并通过使用训练后的随机森林模型评估特征重要性来应用特征选择。选择前 N 个最相关的特征。&lt;/li&gt;&lt;li&gt;**KAN 模型构建：** 构建具有输入层、两个隐藏层（分别具有 16 和 8 个神经元）和输出层的 KAN 模型。使用 MultiKAN 架构允许特征之间的加法和乘法交互。&lt;/li&gt;&lt;li&gt;**模型训练：** 使用 Adam 优化器和 CrossEntropyLoss 训练 KAN 模型。该模型经过多次训练迭代，以通过基于训练数据调整参数来最小化损失函数。&lt;/li&gt;&lt;li&gt;**性能评估：** 评估各种机器学习模型的性能，包括 Logistic Regression、Random Forest、Decision Trees、K-Nearest Neighbors、Gradient Boosting、XGBoost、Naive Bayes、Multi-Layer Perceptron 和 AdaBoost。使用精度、召回率、F1 分数和整体准确率等指标评估模型。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;这项研究表明，Kolmogorov-Arnold 网络 (KAN) 在捕获物联网环境中复杂的非线性关系方面非常有效，明显优于传统机器学习模型。这项研究强调了优化特征选择的关键重要性，它不仅可以通过减少变量数量来提高模型性能，还可以最大限度地减少训练时间和计算开销，从而促进资源受限的物联网系统中的实时应用。KANs 与可学习激活函数的集成代表了物联网安全框架领域的一项重大进步。这种集成提供了一种强大的解决方案，可以提高网络流量分类的准确性和可解释性，这对于保护敏感数据免受不断演变的网络威胁至关重要。作为未来的工作，通过硬件加速（GPU）优化 KANs 可以弥合训练效率差距，使其适用于大规模物联网部署。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05591v1</link>
      <guid isPermaLink="false">2508.05591v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:29:10 GMT</pubDate>
    </item>
    <item>
      <title>Enhancing PyKEEN with Multiple Negative Sampling Solutions for Knowledge Graph Embedding Models</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文针对知识图谱嵌入(KGE)模型中负采样策略的局限性，提出了一个针对PyKEEN框架的扩展。该扩展集成了一系列先进的负采样器，包括静态和动态corruption策略，旨在生成更有意义的负样本。论文指出，现有的KGE库通常只支持基本的负采样策略，缺乏高级解决方案。通过提供一个模块化的架构，该扩展与现有的PyKEEN工作流兼容，并简化了嵌入方法的开发和定制。作为概念验证，论文对开发的扩展进行了全面的实证研究，评估了它们对不同嵌入方法在链接预测任务上的性能影响，并为设计更有效的策略提供了有用的见解。此研究强调了负采样策略对KGE模型性能的重要影响。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;开发了一个针对PyKEEN框架的模块化扩展，集成了一系列先进的负采样策略，包括静态和动态corruption策略。&lt;/li&gt;&lt;li&gt;提供了一个通用的、可重用的抽象实现，用于处理每个三元组的ad hoc负样本池。&lt;/li&gt;&lt;li&gt;实现了五个新的静态负采样器：Corrupt、Typed (with domain and range)、Typed (with only entity classes)和Relational，这些采样器探索了实体选择的结构和语义标准。&lt;/li&gt;&lt;li&gt;实现了两个动态负采样器：NearestNeighbour和Adversarial，这些采样器利用预训练的辅助模型来指导信息量更大的负样本的选择。&lt;/li&gt;&lt;li&gt;提供了一套完整的文档，包括Python Docstrings、READMEs、Bash脚本和示例，以支持代码重用和社区采用。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**静态Corruption：** 通过定义一个标准来选择候选实体的子集，用作从中抽取实体的负样本池。主要区别在于计算负样本池的逻辑。&lt;/li&gt;&lt;li&gt;  *Random Sampling:* 将整个实体集合定义为负样本池，并随机抽取实体。&lt;/li&gt;&lt;li&gt;  *Bernoulli Sampling:* 类似于随机抽样，但通过分析关系如何连接实体来调整corrupt头部或尾部实体的概率。&lt;/li&gt;&lt;li&gt;  *Corrupt Sampling:* 基于出现在每个关系中的头部或尾部实体来corrupt样本，利用关系结构信息来定义可用的候选负样本三元组池。&lt;/li&gt;&lt;li&gt;  *Typed Sampling:* 利用知识图谱中存在的强类型关系和实体，使用关系域和范围类来定义每个三元组的负样本池。&lt;/li&gt;&lt;li&gt;  *Relational Sampling:* 假设每个头尾对仅参与一种关系，负样本池基于与其他关系相关的实体。&lt;/li&gt;&lt;li&gt;**动态Corruption：** 利用预训练的辅助模型来指导信息量更大的负样本的选择。动态采样器利用实体和预测实体向量空间表示来查找更多信息性负样本。&lt;/li&gt;&lt;li&gt;  *Nearest Neighbor:* 使用辅助预训练模型来生成实体的向量表示，并通过检索k个最接近头部（尾部）向量表示的实体来选择hard negatives。&lt;/li&gt;&lt;li&gt;  *Adversarial Sampling:* 与上一种动态采样器采用完全相同的公式，但使用向量空间中的模型预测而不是实体嵌入。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该工作介绍并验证了PyKEEN框架的模块化扩展。该扩展旨在为采用KGE方法时提供广泛的标准化的负采样器实现，从而填补了更高级实现的负采样器可用性的重要空白。具体来说，提供了一个完全兼容的静态和动态corruption策略的五个负采样器的实现。通过一系列实验证明了实用性，展示了如何将扩展无缝集成到KGE的训练、评估和超参数优化管道中。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/ivandiliso/refactor-negative-sampler/&lt;/li&gt;&lt;li&gt;https://ivandiliso.github.io/refactor-negative-sampler&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05587v1</link>
      <guid isPermaLink="false">2508.05587v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:24:34 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型迭代学习可计算的表型，以治疗耐药性高血压</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;本文探讨了大型语言模型(LLM)在生成可解释的可计算表型(CP)方面的潜力，特别是在高血压治疗领域。研究提出了一种*合成、执行、调试、指导*(SEDI)的迭代策略，利用LLM生成CP，并通过数据驱动的反馈不断优化。研究评估了LLM在六种不同复杂程度的临床表型上的零样本表现，并将其与传统机器学习方法进行比较。结果表明，结合迭代学习，LLM能够生成具有可解释性的、相当精确的程序，其性能接近最先进的机器学习方法，同时需要的训练样本显著减少。该研究强调了LLM在自动化CP生成和临床决策支持方面的潜力，特别是在标签数据成本高昂的医疗领域。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了一种新颖的迭代学习策略(SEDI)，利用LLM自动生成和优化可计算表型(CP)。&lt;/li&gt;&lt;li&gt;验证了LLM在生成高血压相关疾病(包括HTN, HTN-HypoK, aTRH)的CP方面的可行性。&lt;/li&gt;&lt;li&gt;对比了LLM生成的CP与传统机器学习方法(如决策树、逻辑回归和符号回归)的性能和可解释性。&lt;/li&gt;&lt;li&gt;证明了通过结合SEDI策略，LLM生成的CP在性能上可以接近甚至超过最先进的机器学习方法，同时保持了良好的可解释性。&lt;/li&gt;&lt;li&gt;强调了LLM在减少手动特征工程和促进可扩展临床决策支持方面的潜力，尤其是在数据标注成本高昂的医疗领域。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**零样本提示(Zero-shot prompts):** LLM直接根据提供的特征生成Python函数，用于预测表型的概率，不接收任何反馈。&lt;/li&gt;&lt;li&gt;**SEDI提示(SEDI prompts):** 采用合成-执行-调试-指导(SEDI)循环，LLM迭代接收CP在训练数据集上的表现反馈。如果CP执行失败，LLM接收包含错误回溯的消息进行调试。如果CP执行成功，LLM接收性能指标以及假阳性(FP)和假阴性(FN)案例，并根据这些信息改进表型定义。&lt;/li&gt;&lt;li&gt;**Prompt构建:**  通过两种模式构建提示：简单提示和详细提示。简单提示只包含表型的名称，而详细提示则包含表型的详细描述。&lt;/li&gt;&lt;li&gt;**Feature的选择:**  使用全部特征和专家特征子集两种设置，其中专家特征子集是基于专家知识选择的，与表型的定义密切相关。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;最先进的LLM可以为高血压表型生成相当准确和简洁的CP，即使在简单提示的情况下也是如此。当给出详细且重点突出的提示并配备数据驱动的迭代反馈（即SEDI）时，LLM生成的CP可以与使用监督ML训练的CP相媲美。传统监督ML方法在利用图表审查示例方面仍然优于LLM衍生的CP，但会产生更大的模型，并且需要访问更大的专家标记数据集。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/cavalab/htn-phenotyping-with-llms&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05581v1</link>
      <guid isPermaLink="false">2508.05581v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:15:17 GMT</pubDate>
    </item>
    <item>
      <title>Fairy ±i : the First 2-bit Complex LLM with All Parameters in {± 1, ±i}</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文提出了Fairy ±i，一种新型的2-bit复数LLM量化框架。该框架通过利用复数域的表达优势来提升全精度模型的准确率，从而打破现有量化方法的精度上限。论文将权重映射到单位根{±1, ±i}，形成一个对称且信息论上最优的2-bit表示。每个量化后的权重都有零实部或虚部，从而实现无乘法器的推理，仅使用加法和元素交换。实验结果表明，Fairy ±i在PPL和下游任务上均优于现有2-bit量化方法的全精度模型，同时保持严格的存储和计算效率。这项工作为构建高精度和实用的极低比特LLM开辟了新方向。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了低比特量化的新视角：通过提高全精度模型的精度来提高量化模型的精度。&lt;/li&gt;&lt;li&gt;设计了一种复数值LLM架构，利用复数域的表达优势，且不增加参数存储。&lt;/li&gt;&lt;li&gt;设计了一种2比特量化方案，将复数权重映射到第四个单位根{±1, ±i}，充分利用了比特容量，同时保留了对称性和稀疏性等关键特性。&lt;/li&gt;&lt;li&gt;实验结果表明，该量化模型在PPL和下游理解任务方面均优于现有2比特量化方法的精度上限。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**复数值Transformer架构：** 将Transformer架构扩展到复数域，使用复数表示模型参数和中间表示，利用Hermitian内积进行线性投影。&lt;/li&gt;&lt;li&gt;**双通道投影嵌入层：** 使用两个并行的嵌入层，分别生成实部和虚部，将离散的token空间桥接到连续的复数值表示空间。&lt;/li&gt;&lt;li&gt;**高效复数值自注意力：** 采用Hermitian内积的实部作为注意力得分，并利用FlashAttention kernel加速计算。&lt;/li&gt;&lt;li&gt;**复数值前馈网络：** 使用平方ReLU（ReLU^2）作为非线性激活函数，保持非线性，同时限制操作在实数域。&lt;/li&gt;&lt;li&gt;**复数语言模型头：** 将最终的复数隐藏状态投影回词汇空间，使用与输入嵌入层对称的设计。&lt;/li&gt;&lt;li&gt;**复数旋转位置嵌入（RoPE）：** 通过复数指数实现旋转，直接且均匀地将相对位置信息编码到内积中。&lt;/li&gt;&lt;li&gt;**PhaseQuant量化方案：** 一种确定性的方法，基于复数权重在复平面上的相位，将每个全精度复数权重映射到四个单位根{±1, ±i}之一。&lt;/li&gt;&lt;li&gt;**复数值激活量化：** 采用对称的按token INT8量化方案，独立处理激活的实部和虚部。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;论文提出了Fairy ±i，一种新型的2比特复数LLM。通过将复数表示集成到Transformer中，并采用PhaseQuant量化，Fairy ±i充分利用了2比特空间，同时保持了对称性、效率和硬件兼容性。实验结果表明，Fairy ±i在同等模型尺寸下，性能优于现有量化方法的全精度模型。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/PKULab1806/Fairy-plus-minus-i&lt;/li&gt;&lt;li&gt;https://huggingface.co/1bitLLM&lt;/li&gt;&lt;li&gt;https://huggingface.co/meta-llama/Llama-2-7b-hf&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05571v1</link>
      <guid isPermaLink="false">2508.05571v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:02:23 GMT</pubDate>
    </item>
    <item>
      <title>High-Order Error Bounds for Markovian LSA with Richardson-Romberg Extrapolation</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文研究了在马尔可夫噪声下，使用Polyak-Ruppert (PR)平均的线性随机逼近(LSA)算法的偏差和高阶误差界限。论文重点关注具有恒定步长 α 的算法版本，并提出了一种通过线性化技术分解偏差的新方法。论文分析了偏差的结构，表明主要项是 α 的线性函数，不能通过PR平均消除。为了解决这个问题，论文应用了Richardson-Romberg (RR) 外推程序，有效地消除了主要的偏差项。论文导出了RR迭代的高阶矩界限，并表明主要误差项与vanilla平均LSA迭代的渐近最优协方差矩阵一致。此研究对于理解和改进具有马尔科夫噪声的随机逼近算法具有重要意义。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了一种量化 θn(α)渐近偏差的新技术。该方法考虑了联合马尔可夫链 {(θk(α), Zk+1)}k∈N 的极限分布 Πα，并分析了偏差 Πα(θ0) − θ⋆。然后，应用Aguech, Moulines, and Priouret (2000)提出的 θk(α) 的线性化方法。这使得我们能够研究分量的极限分布，其平均值显示为按 α 的幂排序。&lt;/li&gt;&lt;li&gt;建立了Richardson-Romberg方法的高阶矩误差界限，其中主要项与渐近最优协方差 Σ∞一致。分析了其对步数 n、步长 α 和混合时间 tmix 的依赖性。&lt;/li&gt;&lt;li&gt;数值实验验证了理论结果，展示了Richardson-Romberg外推法在减少偏差方面的有效性，并证实了论文所获得的边界的准确性。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;线性化技术分解偏差: 通过线性化技巧将偏差分解为易于分析的项。&lt;/li&gt;&lt;li&gt;Richardson-Romberg (RR) 外推程序: 应用RR外推程序消除主要偏差项。&lt;/li&gt;&lt;li&gt;马尔可夫链理论分析: 利用马尔科夫链理论分析算法的收敛性和稳定性。&lt;/li&gt;&lt;li&gt;Wasserstein距离: 使用Wasserstein距离量化概率分布之间的差异。&lt;/li&gt;&lt;li&gt;耦合方法: 使用耦合方法构造具有共同噪声序列的迭代。&lt;/li&gt;&lt;li&gt;扰动展开框架: 使用扰动展开框架来分析算法的误差。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文研究了马尔可夫线性随机逼近中Richardson-Romberg外推法的高阶误差界限。通过应用偏差表征的新技术，能够获得与渐近最优协方差矩阵 Σ∞ 对齐的主要项。对于进一步的工作，考虑将获得的结果推广到非线性马尔可夫SA和具有状态相关噪声的SA的设置。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05570v1</link>
      <guid isPermaLink="false">2508.05570v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:02:11 GMT</pubDate>
    </item>
    <item>
      <title>X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文提出了一种新的垂直联邦学习框架X-VFL，旨在解决传统VFL中两个关键挑战：一是需要所有客户端的样本完全对齐（不允许缺失特征），二是需要所有客户端联合进行协同推断/预测（不支持单个客户端本地独立推断）。X-VFL通过引入两个新模块来解决这些问题：Cross Completion (XCom) 和 Decision Subspace Alignment (DS-Align)。XCom通过利用其他客户端的信息来完成/重建非对齐数据样本的缺失特征。DS-Align将本地特征与决策子空间中所有客户端的已完成和全局特征对齐，从而支持每个客户端的本地独立推断。论文还为X-VFL中使用的不同算法提供了收敛性定理，证明SGD类算法具有O(1/√T)的收敛速度，PAGE类算法具有O(1/T)的收敛速度。在真实数据集上的大量实验表明，X-VFL显著优于现有方法，例如在图像CIFAR-10数据集上实现了15%的精度提升，在医疗MIMIC-III数据集上实现了43%的精度提升。这些结果验证了X-VFL的实际有效性和优越性，尤其是在涉及部分缺失特征和本地独立推断的场景中。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了X-VFL，一种新的VFL框架，旨在处理具有（部分）缺失特征的非对齐数据样本，并支持每个客户端对新数据样本进行本地独立推理。X-VFL引入了两个关键模块：Cross Completion（XCom）和Decision Subspace Alignment（DS-Align），这显著增强了VFL解决更复杂和实际场景的能力。&lt;/li&gt;&lt;li&gt;首次在VFL中引入了具有*部分*缺失特征的实际设置，其中客户端可以保留一些本地特征，而不是完全缺少非对齐数据样本的所有本地特征。这更贴近现实，增强了VFL的实用性。&lt;/li&gt;&lt;li&gt;为X-VFL中使用的算法提供了理论收敛性定理，表明SGD类算法的收敛速度为O(1/√T)，PAGE类算法的收敛速度为O(1/T)。&lt;/li&gt;&lt;li&gt;在真实世界的数据集上进行了广泛的实验，证明X-VFL明显优于现有的VFL方法，例如在CIFAR-10上提高了15%的准确率，在MIMIC-III医疗数据集上提高了43%的准确率。&lt;/li&gt;&lt;li&gt;XCom模块的设计利用不同客户端贡献的不相交本地特征建立交叉互补依赖关系，从而完成缺失特征，显著提高了模型性能。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**Cross Completion (XCom):** 该模块通过利用其他客户端的信息，为非对齐的数据样本完成或重建缺失的特征，从而增加可用于训练的数据量，提高推理性能。&lt;/li&gt;&lt;li&gt;**Decision Subspace Alignment (DS-Align):** 该模块将所有客户端的本地特征与决策子空间中已完成的全局特征对齐，从而支持每个客户端的本地独立推理，同时保持与所有客户端协同推理相当的性能。&lt;/li&gt;&lt;li&gt;**整体损失函数:** X-VFL的总体损失函数结合了决策交叉熵损失、DS-Align模块的两个损失分量，使用超参数进行加权。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;本文提出了 X-VFL，这是一种新的 VFL 框架，它通过有效地处理具有部分缺失特征的数据集，并支持每个客户端本地的独立推理，从而解决了传统 VFL 的关键挑战。 特别是，X-VFL 引入了两个关键模块：交叉完成（XCom）和决策子空间对齐（DS-Align）。 XCom 旨在通过利用跨客户端信息来完成非对齐数据样本的缺失特征，从而有效地增加可用于训练和推理的数据量。 DS-Align 将本地特征与决策子空间内所有客户端的已完成和全局特征对齐，从而使每个客户端即使在存在缺失特征的情况下也能执行本地独立推理。 此外，还为用于训练 X-VFL 的不同算法建立了理论收敛定理。 在真实世界数据集上的大量实验表明，X-VFL 显着优于现有的 VFL 方法，验证了其在解决缺失特征、本地独立推理和数据不平衡等关键挑战方面的实际有效性和优越性。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05568v1</link>
      <guid isPermaLink="false">2508.05568v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:00:47 GMT</pubDate>
    </item>
    <item>
      <title>L1正则化函数支持向量机</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文提出了一种用于多元函数协变量二元分类的L1正则化函数支持向量机（L1-fSVM）。论文旨在填补在函数数据分析中，考虑多元函数协变量进行分类的空白。该方法通过施加L1惩罚，能够识别二元响应的相关函数协变量。论文开发了一种算法来拟合分类器，该算法通过回归样条估计每个轨迹的系数函数，并在这些投影分数上构建SVM分类器。仿真和真实数据应用结果表明，所提出的分类器在预测和特征选择方面都具有良好的性能。该研究为函数型数据的分类问题提供了一种有效的方法，并能同时进行特征选择，具有重要的理论和应用价值。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了L1正则化函数支持向量机（L1-fSVM），用于处理具有多个函数协变量的二元分类问题。&lt;/li&gt;&lt;li&gt;开发了一种迭代更新算法来拟合L1-fSVM分类器，该算法可以同时更新系数函数和SVM中的向量。&lt;/li&gt;&lt;li&gt;通过在SVM中施加L1惩罚，实现了函数协变量的特征选择，从而识别与二元响应相关的函数。&lt;/li&gt;&lt;li&gt;通过仿真研究，验证了L1-fSVM在预测准确性和特征选择方面的性能，并与现有方法进行了比较。&lt;/li&gt;&lt;li&gt;将L1-fSVM应用于脑电图（EEG）数据集，用于预测酒精依赖状态，并识别与酒精依赖相关的脑电通道。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**L1正则化：** 在支持向量机（SVM）的目标函数中引入L1正则化项，以实现特征选择，即通过将不相关函数协变量的系数压缩为零，从而筛选出重要特征。&lt;/li&gt;&lt;li&gt;**B-样条表示：** 使用B-样条基函数来近似表示每个函数协变量的系数函数，从而将无限维的函数空间问题转化为有限维的参数估计问题。这样做可以简化计算，并保证系数函数的平滑性。&lt;/li&gt;&lt;li&gt;**坐标下降算法：** 开发了一种坐标下降算法来迭代地更新模型参数，包括SVM的参数和B-样条系数。该算法交替地固定一部分参数，优化另一部分参数，直到收敛。&lt;/li&gt;&lt;li&gt;**平方hinge损失函数:** 为了简化计算，采用平方hinge损失函数，该损失函数在函数值超过1时，以平方的形式进行惩罚。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文提出了一种L1正则化函数支持向量机，用于函数数据分类。该方法能够有效地处理多个函数协变量，并进行特征选择。实验结果表明，该方法在预测准确性和特征选择方面具有良好的性能，并成功应用于酒精依赖状态的预测。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05567v1</link>
      <guid isPermaLink="false">2508.05567v1</guid>
      <pubDate>Thu, 07 Aug 2025 17:00:29 GMT</pubDate>
    </item>
    <item>
      <title>On the Design of Expressive and Trainable Pulse-based Quantum Machine Learning Models</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文深入研究了基于脉冲的量子机器学习（QML）模型的设计，重点关注如何同时保证模型具有足够的表达能力（expressivity）和可训练性（trainability）。由于其卓越的硬件效率，基于脉冲的QML在量子人工智能领域崭露头角。以往的研究表明，具有动态对称性的脉冲模型可以被有效训练，因为其损失函数没有贫瘠高原（barren plateaus）。然而，模型设计不当可能会导致不可控性，从而影响表达能力。本文通过数值模拟，探讨了脉冲QML模型在保持可训练性的同时，实现高表达能力的要求，并提出了一个关于系统初始状态、测量可观测值和潜在的动态对称李代数的必要条件。研究结果为设计实用的脉冲QML模型提供了一个框架，从而平衡了表达能力和可训练性。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了脉冲QML模型同时具备表达能力和可训练性的设计框架。&lt;/li&gt;&lt;li&gt;通过Dyson级数展开分析了脉冲模型的表达能力，并推导出一个必要条件。&lt;/li&gt;&lt;li&gt;指出了在动态对称性存在的情况下，不合适的初始状态或测量可观测值选择会导致表达能力丧失。&lt;/li&gt;&lt;li&gt;利用李代数工具设计具有动态对称性的表达性脉冲模型。&lt;/li&gt;&lt;li&gt;通过数值模拟验证了理论分析，并展示了在选定的动态对称性下，脉冲QML模型的表达能力和可训练性之间的平衡。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**Dyson级数展开：** 将脉冲模型的输出函数展开为关于输入变量的多项式级数，用于分析模型的表达能力。&lt;/li&gt;&lt;li&gt;**李代数理论：** 利用李代数框架评估动态对称性对模型可训练性的影响，并推导损失函数的方差公式。&lt;/li&gt;&lt;li&gt;**递归过程：** 通过递归方式评估与多项式系数相关的算子集合，用于验证模型表达能力的必要条件。&lt;/li&gt;&lt;li&gt;**数值模拟：** 通过数值模拟验证理论分析，包括模型在不同动态对称性下的表达能力和可训练性。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;本文建立了一个全面的框架，用于设计兼具表达性和可训练性的实用脉冲QML模型。该设计结合了Dyson多项式级数展开以及与量子系统中表现出动态对称性的贫瘠高原现象相关的现有李代数理论。理论分析和数值模拟表明，可以利用动态对称性来构建表达性强且可训练的脉冲模型，这些模型适用于在NISQ设备上进行硬件高效部署。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05559v1</link>
      <guid isPermaLink="false">2508.05559v1</guid>
      <pubDate>Thu, 07 Aug 2025 16:40:09 GMT</pubDate>
    </item>
    <item>
      <title>MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文提出了一个名为 MV-Debate 的多视角代理辩论框架，用于统一的多模态有害内容检测。该框架旨在解决社交媒体中，由于跨模态矛盾、快速的文化转变和微妙的语用线索，导致难以识别的有害意图问题。MV-Debate 整合了四个互补的辩论代理：表面分析师、深度推理者、模态对比者和社会语境主义者，从不同的解释角度分析内容。通过迭代辩论和反思，这些代理在 ∆-gain 标准下改进响应，确保准确性和效率。在三个基准数据集上的实验表明，MV-Debate 显著优于强大的单模型和现有的多代理辩论基线。这项工作强调了多代理辩论在推进安全关键在线环境中可靠的社会意图检测方面的潜力。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了 MV-Debate，一个多代理辩论框架，引导代理采用不同的推理视角，用于社交媒体中的多模态有害内容检测。&lt;/li&gt;&lt;li&gt;设计了四个具有动态反思门控机制的特定视角的辩论代理，以提高性能。&lt;/li&gt;&lt;li&gt;在多个多模态有害内容基准上，通过实验验证了所提出方法的有效性。&lt;/li&gt;&lt;li&gt;提出了Top-k Δ-reflection gating策略，在减少计算开销的同时，保证了性能&lt;/li&gt;&lt;li&gt;通过实验验证，异构agent比同构agent表现更好&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**MV-Debate 框架**：一个多视角的代理辩论框架，用于统一的多模态有害内容检测。&lt;/li&gt;&lt;li&gt;**四个专业辩论代理**：表面分析师 (SA)、深度推理者 (DR)、模态对比者 (MC) 和社会语境主义者 (SC)，每个代理采用不同的推理视角。&lt;/li&gt;&lt;li&gt;**动态反思门控机制**：通过 ∆-gain 标准，自适应地触发反思，提高辩论质量和效率。&lt;/li&gt;&lt;li&gt;**Judge Agent**：根据逻辑连贯性、一致性和合理性对辩论代理生成的论点进行评估并打分&lt;/li&gt;&lt;li&gt;**Reflection Agent**：针对top-k的agent的输出结果，提出逻辑缺陷和改进建议&lt;/li&gt;&lt;li&gt;**Summary Agent**：汇总辩论历史，并进行最终预测。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该研究引入了 MV-Debate，这是一个用于社交媒体上多模态有害内容检测的新型多视角辩论框架。通过协调四个具有互补推理策略和动态反思门控机制的特定视角代理，MV-Debate 有效地整合了跨模态证据和语境线索，以识别复杂的社会意图，如讽刺、仇恨言论和虚假信息。在多个基准上的广泛实验证实了其与强大的基线相比具有卓越的准确性、效率和可解释性。除了性能提升之外，MV-Debate 还生成透明的辩论记录，支持模型调试、审计和用户信任。展望未来，该框架为将多代理辩论方法扩展到更广泛的安全关键型多模态推理任务奠定了基础。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05557v1</link>
      <guid isPermaLink="false">2508.05557v1</guid>
      <pubDate>Thu, 07 Aug 2025 16:38:25 GMT</pubDate>
    </item>
    <item>
      <title>Adapting Vision-Language Models Without Labels: A Comprehensive Survey</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;这篇论文是一篇关于视觉语言模型（VLMs）无监督自适应方法的全面综述。VLMs在各种任务中展示了卓越的泛化能力，但在没有针对特定任务进行自适应的情况下，其性能往往不尽如人意。为了提高VLMs的实用性并保持数据效率，最近的研究越来越多地关注于不依赖标记数据的无监督自适应方法。论文提出了一个基于无标签视觉数据可用性和性质的分类方法，将现有的方法分为四个关键范式：无数据迁移（没有数据）、无监督领域迁移（大量数据）、情景测试时自适应（批量数据）和在线测试时自适应（流数据）。论文分析了每个范式相关的核心方法和自适应策略，旨在系统地理解该领域，回顾了跨多个应用的代表性基准，并强调了未来的开放挑战和有希望的研究方向。相关文献的维护仓库可从GitHub链接访问。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了一个基于无标签视觉数据可用性的分类方法，将现有的VLM无监督自适应方法分为四个关键范式：Data-Free Transfer, Unsupervised Domain Transfer, Episodic Test-Time Adaptation, Online Test-Time Adaptation。&lt;/li&gt;&lt;li&gt;对每个范式中的核心方法和自适应策略进行了详细的分析，提供了对现有技术的系统性理解。&lt;/li&gt;&lt;li&gt;回顾了各种应用场景中具有代表性的基准数据集，概述了无监督VLM自适应的实际影响。&lt;/li&gt;&lt;li&gt;强调了该领域的开放挑战和有希望的未来研究方向。&lt;/li&gt;&lt;li&gt;提供了一个活跃维护的相关文献仓库，方便研究者查找和跟踪最新的进展。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Data-Free Transfer: 文本增强（利用LLM生成更多信息性描述，例如DCLIP, CuPL），图像利用（从外部数据集检索或生成相关图像，例如ReCo, SuS-X），网络修改（修改VLM架构以增强其对下游任务的适用性，例如MaskCLIP, CALIP）。&lt;/li&gt;&lt;li&gt;Unsupervised Domain Transfer: 自训练（使用伪标签作为监督信号迭代改进模型，例如UPL, LaFTer），熵优化（鼓励模型对未标记数据进行自信预测，例如POUF, CDBN），外部资源利用（利用外部资源，如检索到的图像、MLLM和知识蒸馏，例如Neural Priming, PEST）。&lt;/li&gt;&lt;li&gt;Episodic Test-Time Adaptation: 熵最小化（调整模型参数以产生更自信的预测，例如TPT, DiffTPT），反馈信号（利用来自扩散模型或CLIP的反馈信号，例如Diffusion-TTA, RLCF），分布对齐（将测试样本分布与已知源特征对齐或改进表示以提高一致性，例如PromptAlign, MTA），自监督学习（采用自监督学习策略来学习可迁移的表示，例如Self-TPT, LoRA-TTT）。&lt;/li&gt;&lt;li&gt;Online Test-Time Adaptation: 伪标记（将类标签分配给未标记的测试样本并优化交叉熵损失，例如DART, CLIPArTT），存储机制（利用动态或静态存储结构来存储和检索来自测试样本的特征表示和伪标签，例如TDA, DMN），分布建模（对视觉或多模态特征的分布进行建模，通常使用高斯估计，例如OGA, DOTA）。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;论文对无监督视觉语言模型自适应领域进行了全面而结构化的概述，突出了该领域的主要方法和挑战。论文提出了一个基于无标签视觉数据可用性的新颖分类方法，该方法为理解不同场景中的独特挑战和假设提供了一个系统的框架。论文总结了该领域的关键挑战和未来研究方向，为该领域未来的创新提供了明确的比较基础。&lt;/p&gt;&lt;h3&gt;GitHub链接&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;https://github.com/tim-learn/Awesome-LabelFree-VLMs&lt;/li&gt;&lt;/ul&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05547v1</link>
      <guid isPermaLink="false">2508.05547v1</guid>
      <pubDate>Thu, 07 Aug 2025 16:27:37 GMT</pubDate>
    </item>
    <item>
      <title>Conformal Sets in Multiple-Choice Question Answering under Black-Box Settings with Provable Coverage Guarantees</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文提出了一种在黑盒环境下，利用基于频率的不确定性量化方法解决多项选择题（MCQA）中大语言模型（LLMs）的不可靠性问题，特别是幻觉和过度自信。该方法结合了共形预测（CP），以确保可证明的覆盖率保证。具体来说，针对每个输入，对模型的输出分布进行多次独立采样，并将最频繁的样本作为参考，计算预测熵（PE）。在六个LLMs和四个数据集（MedMCQA, MedQA, MMLU, MMLU-Pro）上的实验结果表明，基于频率的PE在区分正确和错误的预测方面优于基于logit的PE（以AUROC衡量）。该方法还可以在用户指定的风险水平下有效地控制经验误覆盖率。研究结果验证了采样频率可以作为黑盒场景中基于logit概率的可行替代方案。这项工作提供了一个分布自由、模型无关的框架，用于MCQA中可靠的不确定性量化，并保证了覆盖率，从而提高了LLMs在实际应用中的可信度。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;提出了一种基于频率的不确定性量化方法，该方法通过对模型输出分布进行多次独立采样，并将最频繁的样本作为参考来计算预测熵（PE），从而量化模型的不确定性。&lt;/li&gt;&lt;li&gt;验证了采样频率可以作为黑盒场景中基于logit概率的可行替代方案，为黑盒LLMs的不确定性量化提供了一种有效手段。&lt;/li&gt;&lt;li&gt;结合共形预测（CP）框架，构建了具有可证明覆盖率保证的预测集，提高了LLMs在实际应用中的可信度。&lt;/li&gt;&lt;li&gt;实验证明，基于频率的PE在区分正确和错误的预测方面优于基于logit的PE，并且可以有效控制经验误覆盖率。&lt;/li&gt;&lt;li&gt;提供了一个分布自由、模型无关的框架，用于MCQA中可靠的不确定性量化，适用于各种LLMs和数据集。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**频率-预测熵（PE）**：对多项选择题，在有效答案空间内进行M次独立抽样，得到包含M个候选答案的样本集E。计算每个候选答案的频率Pˆ(a)，选择频率最高的候选答案，以此构建经验频率分布，定义频率-预测熵。&lt;/li&gt;&lt;li&gt;**共形预测（CP）**：构建包含真实值的预测集，使其概率不低于预先设定的置信水平1-α。通过将数据划分为校准集和测试集，计算非一致性评分，设定分位数阈值，并构建预测集。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该研究提出了一种基于频率的预测熵（PE）方法，用于在黑盒环境下量化LLMs在MCQA任务中的不确定性。实验结果表明，该方法在不确定性量化性能方面优于基于logit的方法，并且可以有效控制经验误覆盖率。证实了采样频率可以作为黑盒LLMs中基于logit概率的可行替代方案。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05544v1</link>
      <guid isPermaLink="false">2508.05544v1</guid>
      <pubDate>Thu, 07 Aug 2025 16:22:49 GMT</pubDate>
    </item>
    <item>
      <title>Tractable Sharpness-Aware Learning of Probabilistic Circuits</title>
      <description>&lt;![CDATA[&lt;h3&gt;摘要&lt;/h3&gt;&lt;p&gt;该论文研究了概率电路（PCs）的过拟合问题，并从对数似然景观的角度分析了PCs的过拟合现象，发现它通常是由于收敛到泛化能力差的尖锐最优解所致。受神经网络中 sharpness aware minimization 的启发，该论文提出了一种基于 Hessian 的正则化方法来训练PCs。论文的关键贡献在于证明了对于PCs，对数似然的 Hessian 矩阵的迹（一个 sharpness 的代理指标）可以有效地计算出来，这在深度神经网络中通常是难以实现的。最小化 Hessian 迹会产生一个基于梯度范数的正则化项，该正则化项为 EM 算法产生简单的闭式参数更新，并无缝地与基于梯度的学习方法集成。在合成和真实世界数据集上的实验表明，该方法可以引导PCs趋向于更平坦的最小值，从而提高泛化性能。&lt;/p&gt;&lt;h3&gt;主要贡献&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;推导了树状结构PCs对数似然的精确完整Hessian矩阵的闭式表达式，并表明它可以被追踪地计算。&lt;/li&gt;&lt;li&gt;对于一般的（DAG结构的）PCs，论文确定了虽然完整的Hessian矩阵可能难以处理，但其迹仍然可以在时间和参数数量和数据集大小上呈线性关系地精确计算，从而为大规模PCs提供了第一个实用的曲率度量。&lt;/li&gt;&lt;li&gt;提出了一种新颖的 sharpness-aware 正则化方法来学习PCs，该方法源自 Hessian 迹。&lt;/li&gt;&lt;li&gt;表明虽然通过EM直接最小化Hessian迹会导致三次更新方程，但可以将此目标重新公式化为等效的梯度范数最小化问题，从而产生具有闭式参数更新的二次方程。&lt;/li&gt;&lt;li&gt;在多个合成和真实世界数据集上进行了详尽的实验，表明论文提出的正则化方法可以强制收敛到更平坦的最优解，并有助于减少过拟合，尤其是在有限的数据设置中。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;技术方法&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;**Hessian 矩阵计算**： 论文推导了树状结构PC的对数似然的精确完整 Hessian 矩阵的闭式表达式。对于一般的 DAG 结构的 PC，虽然完整的 Hessian 矩阵可能难以处理，但其迹仍然可以在时间和参数数量和数据集大小上呈线性关系地精确计算。&lt;/li&gt;&lt;li&gt;**Hessian 迹正则化**： 利用 Hessian 迹作为曲率的度量，提出了一个新的 sharpness-aware 正则化方法来学习 PCs。通过最小化 Hessian 迹，可以引导 PCs 趋向于更平坦的最小值。&lt;/li&gt;&lt;li&gt;**Sharpness-Aware EM**： 将 Hessian 迹作为正则化项添加到 EM 算法的 M 步骤中，通过约束每个和节点处的平方梯度之和来实现。导出了在梯度正则化目标下，参数的闭式更新公式，该公式是一个二次方程。&lt;/li&gt;&lt;li&gt;**梯度范数最小化**： 将直接最小化 Hessian 迹的问题重新公式化为等效的梯度范数最小化问题，从而产生具有闭式参数更新的二次方程。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;主要结论&lt;/h3&gt;&lt;p&gt;该论文提出了一种通过对数似然表面几何形状研究PCs训练的新方向。推导了树状结构PCs对数似然精确完整 Hessian 矩阵的闭式表达式并证明了其易处理性。对于一般的DAG结构的PCs，论文表明虽然完整的 Hessian 矩阵可能难以处理，但其迹仍然可以精确有效地计算，从而为训练大型PCs提供第一个可扩展的曲率度量。在此基础上，论文设计了一种新颖的正则化方法，其等效的梯度范数公式可产生闭式二次更新，从而实现高效优化。实验证实，该方法可以将训练引导至更平坦的最小值并减少过拟合，尤其是在低数据方案中。总的来说，该论文的工作为研究PCs开辟了一个有希望的新方向。&lt;/p&gt;]]&gt;</description>
      <link>https://arxiv.org/pdf/2508.05537v1</link>
      <guid isPermaLink="false">2508.05537v1</guid>
      <pubDate>Thu, 07 Aug 2025 16:13:24 GMT</pubDate>
    </item>
  </channel>
</rss>
