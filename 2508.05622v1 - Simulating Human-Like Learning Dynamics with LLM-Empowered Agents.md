## **Simulating Human-Like Learning Dynamics with LLM-Empowered Agents**
### Yu Yuan [12*], Lili Zhao [12*], Wei Chen [12], Guangting Zheng [1], Kai Zhang [12], Mengdi Zhang [3], Qi Liu [12†],

1 University of Science and Technology of China
2 State Key Laboratory of Cognitive Intelligence, China
3 Meituan
*{* yyhappier,liliz,chenweicw,zgt *}* @mail.ustc.edu.cn
*{* kkzhang08,qiliuql *}* @ustc.edu.cn
zhangmengdi02@meituan.com


**Abstract**

Capturing human learning behavior based on deep learning
methods has become a major research focus in both psychology and intelligent systems. Recent approaches rely on
controlled experiments or rule-based models to explore cognitive processes. However, they struggle to capture learning dynamics, track progress over time, or provide explainability. To address these challenges, we introduce LearnerAgent, a novel multi-agent framework based on Large Language Models (LLMs) to simulate a realistic teaching environment. To explore human-like learning dynamics, we
construct learners with psychologically grounded profilessuch as Deep, Surface, and Lazy-as well as a persona-free
General Learner to inspect the base LLM’s default behavior. Through weekly knowledge acquisition, monthly strategic choices, periodic tests, and peer interaction, we can track
the dynamic learning progress of individual learners over a
full-year journey. Our findings are fourfold: 1) Longitudinal
analysis reveals that only Deep Learner achieves sustained
cognitive growth. Our specially designed “trap questions”
effectively diagnose Surface Learner’s shallow knowledge.
2) The behavioral and cognitive patterns of distinct learners align closely with their psychological profiles. 3) Learners’ self-concept scores evolve realistically, with the General
Learner developing surprisingly high self-efficacy despite its
cognitive limitations. 4) Critically, the default profile of base
LLM is a “diligent but brittle Surface Learner”-an agent that
mimics the behaviors of a good student but lacks true, generalizable understanding. Extensive simulation experiments
demonstrate that LearnerAgent aligns well with real scenarios, yielding more insightful findings about LLMs’ behavior.
### **Introduction**

As Large Language Models (LLMs) become increasingly
prevalent in real-world applications (Wei et al. 2022; Guo
et al. 2025; Yuan et al. 2025), researchers have begun to investigate the parallels and distinctions between model behavior and human learning patterns. This stems from the
recognition that studying these similarities and differences

  - These authors contributed equally.

  - Corresponding author.
Preprint. Under review.


learning processes of different learners through simulating
real teaching scenarios.

can help bridge the gap between artificial and human cognition (Park et al. 2023; Tran et al. 2025). Specifically, Educational Psychology-with its robust theories on human learning processes (Marton and S¨alj¨o 1976; Sweller 2011)-offers
valuable insights for deep learning systems. By applying
these insights, researchers can explore a wide range of student learning behaviors (ranging from surface learning to
deep learning patterns). It enables targeted optimization of
the models’ own learning mechanisms, ultimately improving their performance across critical downstream tasks, including Adaptive Learning (Liu et al. 2019), and model capability diagnosis (Dong, Chen, and Wu 2025).
Traditional cross-over research (Marton and Dahlgren
1976; Marsh 1990; Ezzaim et al. 2023) mainly relies on
questionnaire surveys or rule-based measurement models
to assess student learning performance, whether surfacelevel or deep-level. However, this approach has notable limitations: it is not only time-consuming and labor-intensive
but also constrained by static inferences drawn from final
responses from learners or model outputs. As a result, it
struggles to provide dynamic and explainable evaluations of
learning behaviors in complex and flexible environments.
Inspired by the success of LLM-empowered agents in
simulating complex social systems—such as economic interactions (Zhao et al. 2024b), natural science (M. Bran et al.
2024), and quantitative political analysis (Li, Gong, and






-----

Figure 2: The LearnerAgent simulates a real teaching scenario by exploring how learners acquire knowledge and develop
cognition through mechanisms such as personal profiling, adaptive learning, memory modeling, and performance assessment.
Notably, some of its findings align with theories in Educational Psychology.


Jiang 2025), we propose a novel **LearnerAgent** framework
to address the aforementioned challenges. As illustrated in
Figure 1, LearnerAgent simulates real-world teaching environments. The teacher teaches knowledge and assigns tasks,
while learners engage in learning and improvement over 12month journey, complete exams, and interact with peers.
To fully explore dynamic and diverse learning behaviors in real-world scenarios, we construct distinct profiles
for learners from multiple dimensions as shown in Table
1. Learners acquire knowledge weekly and make monthly
strategic choices from knowledge consolidation and cognitive reflection. Periodic tests provide comprehensive assessment on their dynamic performance progress, while peer interaction and debate simulate social learning.
Through extensive experiments with LearnerAgent, we
uncover several key findings:

 - LearnerAgent successfully simulates distinct learners
( *Deep*, *Surface*, *Lazy* ) in a realistic teaching environment,
with each showing behaviors aligned with their profiles
in learning strategies, reasoning, and cognitive effort.

 - Longitudinal analysis shows that only the *Deep* Learner
achieves sustainable cognitive growth. The *Surface*
Learner’s knowledge proves brittle, exhibiting shortcut
learning behavior.

 - The self-concept of learners evolves dynamically. Profiled learners maintain stable self-perceptions, while the
persona-free *General* Learner develops an increasing
self-efficacy, mirroring human-like confidence growth.

 - Learners respond differently to peer influence: *Deep*
Learner acts as a rational debater, *Surface* Learner remains cognitively rigid, and *Lazy* Learner is highly susceptible to persuasion.

 - The *General* Learner (base LLM) defaults to a “diligent
but brittle surface learner” style, mimicking ideal student
behaviors while lacking deeper understanding, which reflects a reliance on shallow pattern-matching.


**Learner** **Motivation** **Self-Concept** **Dev. Strategies**

Deep Intrinsic High Long-term
Surface Extrinsic Moderate Test-oriented

Lazy Minimal effort Low Passive
General  -  -  
Table 1: Learners are defined along multiple dimensions,
including Learning Motivation, Self-Concept, and Development (Dev.) Strategies, in addition to basic information.
### **Related Work**
#### **LLM-empowered Agents**

Due to the powerful capabilities (Hurst et al. 2024; Comanici et al. 2025) and human-like behaviors demonstrated
by LLMs (Zhao et al. 2025b), several studies utilized the
perception, planning, memory, and collaboration abilities of
LLMs (Divband Soorati et al. 2022; Fischer et al. 2021)
to simulate realistic scenarios and construct more intelligent agents. Through coordination among different agents,
Agentic AI can be classified into three types: Cooperation
(Li et al. 2023; Wang et al. 2024), Competition (Zhao et al.
2024b; Liang et al. 2024; Chen et al. 2023), and Coopetition (Abdelnabi et al. 2024; Davidson et al. 2024). Utilizing
and exploring different types of coordination, agents have
been widely used to simulate real-world implementations,
including economic market (Zhao et al. 2024b; Horton 2023;
Li et al. 2024), human behavior (Aher, Arriaga, and Kalai
2023; Dillion et al. 2023; Park et al. 2023), social science
(Li, Gong, and Jiang 2025; Argyle et al. 2023; Park et al.
2022; G¨urcan 2024; Qian et al. 2023), and natural science
(M. Bran et al. 2024; Boiko et al. 2023).
Drawing on key findings from Educational Psychology (Chin and Brown 2000; Ryan and Deci 2000), such
as the progression from novice to expert—where surfacelevel strategies decrease while deep-level strategies increase


-----

( **cognitive development** ) (Alexander 2004); the role of
**self-concept** as a central driver of motivation and behavior (Marsh 1990); and the effect of **peer influence** on academic performance (DeLay et al. 2016), we simulate a realistic teaching environment. This allows us to explore human cognitive development and learning behavior in greater
depth, offering a novel perspective on how these psychological factors manifest in interactive settings.
#### **Shortcut Learning behavior of LLMs**

Due to the influence of training methods, data, and model architectures, LLMs, during the training process, rely on shortcuts to learn the spurious correlations between certain features, resulting in hallucinations and errors in the inference
process (Weng 2024). This behavior is similar to the shortcut learning exhibited by humans, where they quickly find
shortcuts to solve current problems without delving into the
underlying issues (Geirhos et al. 2020; Zhao et al. 2024a,
2025a). Several studies have revealed the shortcut learning
behaviors in LLMs. Yuan et al. (2024) found LLMs relied on
different shortcuts such as Lexical Overlap, Subsequence,
Constituent, Negation, Position, and Style, leading to hallucinations and failure in downstream tasks. Tang et al. (2023)
pointed out that LLMs act as lazy learners, giving up deep
thinking by directly learning the potential spurious correlations within the context examples.
In this paper, we draw a parallel between human and
model learning. By simulating learners through a multiagent system, we focus on their learning development, i.e.,
deep learning, shortcut learning, and lazy learning.
### **LearnerAgent Framework**

LearnerAgent constructs a realistic learning environment
through role-playing simulation as shown in Figure 2, which
simulates the full-year learning journey based on theories of
Educational Psychology and Cognitive Science (Ryan and
Deci 2000; Marsh and Martin 2011; DeLay et al. 2016). It
consists of two primary roles: a Teacher Agent and multiple
Learner Agents, each with a distinct profile construction.
#### **Profile Construction**

**Teacher Agent (** *T* **)**, as an experienced high school instructor, is responsible for delivering knowledge and assigning
tasks, including organizing teaching activities, evaluating
learner performance, and providing appropriate guidance.
**Learner Agents** ( *L* = *{L* *d* *, L* *s* *, L* *l* *, L* *g* *}* ) are categorized
into four predefined types, with their distinct behavioral patterns derived from individual role profiles. In the full-year
(12-month) learning, all learners primarily focus on knowledge acquisition and periodic assessments.
To simulate different learners that align with real-life scenarios, learners are depicted as various profiles based on
three dimensions in addition to basic information, as summarized in Table 1: 1) *Learning Motivation* : refers to the
drive to learn, including intrinsic curiosity, external rewards
(e.g., grades), and a desire to avoid efforts; 2) *Initial Self-*
*Concept Score* : represents learners’ assessment of their own


abilities, which is reflected not only in their confidence levels but also in how much they are affected by evaluations
(such as examination scores) and by their peers; 3) *Devel-*
*opment Strategies* : denotes the methodology learners adopt
in different learning processes, aligning with their learning
motivation and self-concept.
Based on these dimensions, we classify three distinct
learners: Deep Learner ( *L* *d* ), Surface Learner ( *L* *s* ), and Lazy
Learner ( *L* *l* ). Moreover, General Learner ( *L* *g* ), initialized
only with Basic Information, serves as an essential baseline
for comparison. Notably, *L* *g* can serve as a probe for observing the emergent behavioral tendencies of the underlying LLM itself. The detailed configurations for these learners can be found in Appendix A.
#### **Learning and Improvement**

To explore the cognitive development process of learners, a
structured cycle of learning, improvement, and assessment
is well-designed through a one-year learning period. Specifically, the initial baseline exam and final exam at the end of
cycle are designed for assessing overall knowledge acquisition and growth. In each month, learners engage in learning
and practice during the first three weeks, and dedicate the
fourth week to summary, review, and take a monthly exam.
**Weekly Learning and Strategic Choices.** In the first three
weeks of each month, learners follow a structured routine:
studying provided materials, taking notes, and completing
weekly tests. After each test, the *T* provides standard explanations for all questions. At the end of three weeks, learners
need to make two key choices that reflect self-regulation: 1)
*Knowledge Consolidation* : Summarize their learning notes
from all three weeks into a single document to prepare for
the monthly exam, or take a break. 2) *Cognitive Reflection* :
Reflect on their performance across the three weekly tests,
identifying key insights and mistakes, or take a break.
**Monthly Review and Assessment.** The fourth week of each
month focuses on final review and assessment. Before the
monthly exam, learners should make a final choice: to review their accumulated materials (e.g., summaries, reflections) thoroughly, or to rest.
**Peer Interaction and Debate.** To simulate social learning
and peer influence, LearnerAgent introduces a dynamic debate mechanism after each monthly exam. When two learners, *L* *i* and *L* *j*, provide different answers to the same question *q*, they are prompted to engage in a debate. During
the discussion, learners can defend their reasoning, challenge peers, or revise their initial answers. The teacher organizes the debate and determines its structure and number
of rounds. The debate ends when any of the following conditions are met: 1) A learner explicitly changes their answer
after being persuaded; 2) Both learners maintain their own
views with well-supported reasoning; 3) Their opinions converge or become repetitive; 4) The number of debate rounds
has become relatively high (exceeds *k* *d* rounds).
#### **Memory Mechanism**

Given that learning is inherently sequential and that LearnerAgent provides diverse scenarios to foster ongoing learner
improvement, we employ both short-term and long-term


-----

memory mechanisms to enable effective knowledge acquisition, assessment, and reflection.
**Short-Term Memory** maintains immediate conversational
context by storing the most recent *k* dialogue turns in a
fixed-size queue. This enables coherent and context-aware
interactions with the teacher and peers.
**Long-Term Memory** serves as a persistent, structured
store of the learner’s complete learning and improvement
history. It archives key memories—including knowledge
summaries, exam answers, self-reflections, debate records,
monthly exam scores, and self-concept scores—as distinct
entries for long-term retrieval. To support personalized assistance and temporal alignment, we introduce a **context-**
**dependent retrieval strategy** in which the framework dynamically provides the agent with only the most relevant
memory segments, based on the current time step or learning phase. As shown in Figure 2, the strategy adapts to key
learning stages by retrieving tailored memories:
1) Weekly learning retrieves topical summaries. 2)
Monthly exams provide prior knowledge summaries, reflections, relevant past exam answers, and teacher feedback.
3) Debates include similar past responses and discussion
threads. 4) Self-concept evaluation recalls prior self-concept
scores and performance comparisons. 5) Final exams offer a
consolidation of knowledge across the entire year.
#### **Competent Assessment**

To fully evaluate learners’ knowledge and ability development throughout the learning process, we employ a comprehensive assessment strategy covering both academic performance and psychological changes.
**Performance Evaluation.** In addition to the initial, weekly,
monthly, and final exams in the learning cycle, the ***Trap***
***Questions*** are constructed to evaluate the deeper understanding of learners beyond rote learning. Similar to (Yuan
et al. 2024), we design these trap questions with the same
structure as weekly practice questions but different reasoning due to subtle context changes, to deeply diagnose
and uncover learners’ behavior patterns. We use a powerful closed-source LLM to generate them, and then manually
annotated and filtered as shown in Figure 5.
**Psychological Evaluation.** To inform better self-evaluation
of different learners, they are provided with two key inputs:
1) their historical self-concept scores, and 2) exam scores
of other learners. They are then asked to update their selfconcept scores (e.g., on a 0–100 scale) by considering their
learning capability, knowledge mastery, progress, and their
perception of their position relative to classmates.
### **Experimental Setups**

In this section, we conduct extensive experiments to evaluate
the effectiveness of LearnerAgent and answer the following
Research Questions (RQs).

 - **RQ1** : What knowledge acquisition and cognitive development processes do learners exhibit during learning
journey? Can they solve the trap questions?

 - **RQ2** : What distinct behavioral and cognitive patterns are
associated with each learner?



 - **RQ3** : How do learners’ perceptions of themselves (selfconcept) evolve throughout learning processes?

 - **RQ4** : How do learners respond to peer influence in interactive debates?

 - **RQ5** : What is the emergent learning profile of a base
LLM—a learner without a predefined persona (as the
General Learner)?
#### **Test Suite Construction**

We formulate the learning task as English grammar acquisition, a natural testbed for evaluating knowledge mastery,
deep reasoning of learners. To support this, we manually
construct a new test suite to simulate a year-long grammar
learning process. All materials are collected from authoritative Gaokao [1] English preparation resources, including high
school textbooks, practice books, and official compilations
of past exams, ensuring both authenticity and comprehensive grammar coverage [2] .
The test suite consist of two key components: 1) **Knowl-**
**edge Points** : Each week introduces specific grammar concepts (e.g., verb tenses, clause types, sentence structure),
aligned with the sequencing in Gaokao curricula. 2) **Test**
**Questions** : For each concept, we provide diverse question
formats—multiple choice, fill-in-the-blank, and error correction—all designed to assess learners’ ability to apply
grammar rules flexibly. To further evaluate deep understanding beyond rote memorization, we construct *Trap Ques-*
*tions* : automatically generated using Gemini-2.5-Pro (Comanici et al. 2025) and manually verified. These questions
are structurally or lexically similar to past-learned questions,
but introduce subtle contextual shifts, requiring learners to
comprehend their knowledge in depth. Test questions are introduced in the following periodic tests:

 - **Initial and Final Exams** : Same set of 100 questions designed to measure overall grammar proficiency at the beginning and end of the learning period.

 - **Weekly Exercises** : 20 questions each week to review and
consolidate newly acquired grammar topics.

 - **Monthly Tests** : A total of 12 exams, each comprising 50
questions distributed across three sections: (1) 15 *Review*
questions targeting that month’s topics to evaluate shortterm retention; (2) 15 *Trap* questions to assess deep understanding and transfer learning; and (3) 20 *Knowledge-*
*Integration (K-I)* questions integrating all covered knowledge points to measure cumulative proficiency.
#### **Implementation Details**

We employ Qwen-2.5-72B-Instruct (Yang et al. 2024) as
the Teacher Agent to provide instruction and feedback, and
Qwen-2.5-7B-Instruct for all Learner Agents. Each learner
(Deep, Surface, Lazy, General) is configured with distinct
profiles, and each configuration is evaluated over 3 independent runs to ensure robustness. Experiments are conducted

1 The Gaokao is China’s National College Entrance Examination. Its English section emphasizes systematic grammar skills.
2 The materials are collected from gaokao.eol.cn


-----

**(a) Monthly Tests Performance.** **(b) Review.** **(c) Trap.** **(d) K-I.**

Figure 3: Development of learner performance. **(a)** : Total scores of the four learners over 12 months, covering all question types.
The dashed lines represent the linear trend for each learner’s scores; **(b)** : Accuracy on *review* questions, targeting short-term
retention of current content; **(c)** : Accuracy on *trap* questions, which assess transfer learning and deeper understanding; **(d)** :
Accuracy on *knowledge-integration (K-I)* questions, evaluating cumulative knowledge over time.

On ***Review*** questions assessing current-month knowledge, Surface Learner performs the best, reflecting a strategy well-suited to short-term memory and immediate assessments. Deep and General Learners achieve moderate performance, while Lazy Learners perform the weakest, consistent
with their limited engagement with recent learning.


**(a) Overall Performance.** **(b) Reasoning Length.**

Figure 4: The comparison of overall performance **(a)** and
reasoning abilities **(b)** across the initial to the final exams.

on four NVIDIA A800-80GB GPUs. Detailed prompt settings are available in Appendix A, and more experimental
results and analysis can be found in Appendix B.
### **Experimental Results and Analysis**

We conduct a series of detailed analyses of the learning and
development processes of different learners in various scenarios based on the four research questions presented.
#### **Cognition and Learning Development (RQ1)**

We track the longitudinal development of each learner by
analyzing three aspects: 1) their monthly exam performance
over 12 months, 2) their performance on diverse question
types (e.g., review, trap, and knowledge-integration (K-I))
to assess cognitive gains, and 3) their overall performance
and reasoning ability from the initial to the final exams.
**Longitudinal Performance.** As shown in Figure 3 (a), all
learners show a clear upward trend in monthly test scores
across the 12-month learning, though with considerable
volatility. Overall, the Deep Learner and General Learner
show a somewhat different pattern of improvement, while
the Lazy Learner and Surface Learner perform worst in most
months. Among these, Lazy Learner shows the greatest fluctuation in performance.
**Cognition Across Question Categories.** To reveal finegrained cognitive strengths and weaknesses, we evaluate
how distinct learners perform on diverse questions, as shown
in Figure 3 (b–d).


On ***Trap*** questions designed to assess deep understanding
and knowledge mastery, Deep Learner achieves the highest
accuracy, demonstrating a strong ability to generalize principles rather than rely on rote learning. In contrast, Surface and
General Learners struggle the most, reflecting their limited
capacity for deep and true reasoning. Despite performing
well on monthly review questions, their poor performance
on trap questions reveals superficial and fragile knowledge
mastery. As shown in Figure 5, a trap question where the correct answer changed from “broken” in the previous question
to “breaking”, only Deep Learner answers correctly, while
the Surface, Lazy, and General Learners reuse the incorrect prior answer. Deep Learner demonstrates contextual and
grammatical reasoning, whereas Surface and Lazy Learners rely on rote memory, and General Learner shows partial
adaptability but default to surface-level cues.

On ***Knowledge-Integration*** questions testing cumulative
knowledge, all learners perform similarly well. General
Learner achieves the highest average score, making it the
best knowledge accumulator.

**Overall Performance and Reasoning.** Through the direct
comparison between initial and final exams as shown in Figure 4, the performance of all other learners improves except for Lazy Learner. All learners increase their reasoning length over time, suggesting a tendency toward more
elaborate explanations. Deep Learner consistently shows the
longest reasoning and steady gains in both length and performance. In contrast, Surface and Lazy Learners, despite
large increases in reasoning length, remain the least elaborate reasoning overall, reflecting shallow and superficial responses. General Learner improves moderately on both metrics. LearnerAgent can effectively simulate diverse learning
journey, and true cognitive growth depends on maintaining
depth and quality—not just longer responses.


-----

Figure 5: A case study of a trap question distinguishing deep
understanding from rote learning. By introducing a subtle
contextual change to a familiar weekly item, this case illustrates that only the Deep Learner successfully adapts reasoning, while others rely on superficial pattern matching.
#### **Behavioral and Cognitive Patterns (RQ2)**

We make detailed analyses on distinct behavioral and cognitive patterns in each learner, based on their learning strategies and reasoning quality throughout the learning process.
**Learning Strategies.** We analyze strategic choices of different learners between self-improvement (e.g., summarizing,
reflecting, or reviewing) and rest when facing monthly exams described in Section by calculating their study-to-rest
ratios. As shown in Figure 6 (a), all learners mostly choose
to study, reflecting an overall tendency for active engagement rather than rest. Lazy Learners, however, rest slightly
more, suggesting lower motivation and efforts.
**Reasoning Patterns.**
To further analyze cognitive behaviors across learners, we
conduct experiments on reasoning responses along two key
dimensions: (1) *Reasoning Length* (measured by average
number of tokens per explanation), and (2) *Logical Connec-*
*tor Density* (the frequency and variety of logical connectors,
e.g., cause-effect, contrast, addition, used to structure reasoning).
First, reasoning length reveals clear differences in elaboration depth, as shown in Figure 6 (b). Deep Learner consistently produces the longest explanations, suggesting strong
cognitive engagement and a focus on explanation. Surface
and Lazy Learners, in contrast, produce significantly shorter
responses, reflecting minimal effort or surface-level recall.
Second, the use of logical connectors reveals significant
differences in reasoning complexity, as shown in Figure 6
(c). The Deep Learner has the highest connector density and


**(a) Learning Strategies.** **(b) Reasoning Length.** **(c) Logical Connectors.**

Figure 6: Behavioral and cognitive differentiation among
learners. **(a)** Learning Strategies: Proportion of time allocated to self-improvement or rest. **(b)** Reasoning Length:
Average number of tokens per reasoning. **(c)** Logical Connectors: Average number of logical connectors per reasoning
and their distribution by type (causal, contrastive, additive).

Figure 7: The evolution of self-concept scores for learners
throughout 12-month learning.

the Lazy Learner the lowest. Deep Learner employs more
contrastive connectors, a strong indicator of higher-order
thinking that reflects the ability to weigh alternatives and
reason nuances. In contrast, other learners use fewer contrastive connectors and rely more on simple causal connectors, indicating a more linear thinking style.
#### **Self-Concept Evolution (RQ3)**

We track how each learner’s self-concept evolves over a 12month period to examine how their perception changes in response to long-term learning and performance feedback. As
shown in Figure 7, learners with predefined personas generally mostly keep self-concepts in line with their initial profiles, though some subtle changes occur.
Deep Learner maintains consistently high and slightly rising self-concept scores, reflecting stable confidence largely
unaffected by short-term performance changes or peer comparison. Surface Learner shows a slight decline, suggesting
a more fragile self-view influenced by variable outcomes.
Lazy Learner, who starts with the lowest self-concept, shows
modest improvement, likely from small cumulative gains.
Each learner follows a distinct developmental trajectory,
demonstrating LearnerAgent’s ability to simulate realistic
learning journeys. Notably, General Learner shows a special pattern: it begins without a predefined profile, starts at a
moderate self-concept level, and exhibits a strong, steady increase over time. This emerging trend reflects how the base
LLM gradually forms a dynamic self-concept that is at times
overly optimistic.


-----

**Learner** **Persuasion** *↑* **Resist Wrong** *↑* **Accept Correct** *↑*

Deep ( *L* *d* ) **15.0** **98.4** 19.2
Surface ( *L* *s* ) 8.38 96.4 **22.1**
Lazy ( *L* *l* ) 7.13 86.9 17.1
General ( *L* *g* ) 12.0 90.9 19.1

Table 2: Debate performance is assessed over 12 months
using: Persuasion (successfully persuading peers), Resist
Wrong (resisting incorrect peer input), and Accept Correct
(updating beliefs in response to correct arguments).
#### **Peer Influence (RQ4)**

To evaluate how learners respond to peer influence during discussions, we define three metrics to capture interaction dynamics: 1) *Persuasion*, the proportion of debates
where the learner successfully persuades their peer, 2) *Re-*
*sist Wrong*, the rate at which the learner correctly rejects incorrect peer arguments, and (3) *Accept Correct*, the rate at
which the learner revises incorrect beliefs when given correct input. The results are summarized in Table 2.
Deep Learner performs best in both Persuasion and Resist
Wrong rate, while also maintaining a high Accept Correct
score. This combination reflects a learner that is both persuasive and resilient—capable of defending its views against
misinformation while staying open to valid corrections. Surface Learner shows strong resistance to incorrect arguments
and effectively accepts correct ones, yet it is the least persuasive, with a Persuasion rate as low as 7.13%. Lazy Learner
performs weakest overall, with the lowest scores in both Persuasion and Resist Wrong rate, making it especially prone to
misinformation. Although its Accept Correct rate is moderate, its engagement remains shallow and inconsistent. General Learner is surprisingly effective at arguing its views,
achieving the second-highest Persuasion Rate of 12.0%.
However, its relatively low Resist Wrong score and Accept
Correct rate indicate a weaker ability to resist incorrect arguments and accept valid feedback, leaving it vulnerable to
misinformation from peers.
#### **Emergent Profile of the General Learner (RQ5)**

As a learner without a pre-defined profile, it is important to investigate the General Learner’s behavior across
all tasks, which can be regarded as the learning trajectory
of the base model. Specifically, at first glance, the General
Learner appears highly engaged: it frequently chooses selfimprovement activities, provides reasonably detailed answers, and excels at knowledge-integration questions, with
performance second only to the Deep Learner. However, a
closer look reveals a disconnect between its outward diligence and actual learning depth. Although its self-concept
rises steadily to match the Deep Learner’s high confidence,
this confidence is not supported by performance on challenging tasks—especially Trap Questions, where its accuracy is nearly as low as the Surface Learner’s. Its weaker debate performance, with less persuasive arguments and limited reasoning, further reflects this gap. The results indicate


**System** **Goal** **Self-evaluation Learning Strategies**

Learner Test-oriented Self-concept Surface Learning
D-L Minimize Loss Confidence Fine-Tuning

Reinforcement
LLMs Minimize Loss Confidence
Learning

Table 3: Comparison of learning behaviors across surface
learners, Deep Learning (D-L) models, and LLMs.

that the General Learner adopts a profile best described as a
“ **diligent but brittle surface learner** ”.
In conclusion, the base LLM does not emerge as a capable
deep reasoner. Instead, it relies on surface-level strategies,
adopting the habits of a diligent but overly confident learner
while struggling with deeper, more flexible reasoning. These
findings highlight the need for cognitive guidance—such
as a structured environment and explicit instructional support—to help LLMs move beyond pattern-matching and develop more robust, human-like deep understanding.
### **Discussion**

As presented in Table 3, we compare learners, deep learning models, and LLMs, and find that despite their *differing*
*learning goals, evaluation methods, and strategies, all are*
*prone to shortcut learning* . Whether driven by test performance or loss minimization, their short-term-focused strategies often lead to behaviors such as exploiting spurious
feature-label correlations during fine-tuning or aligning with
human biases in reinforcement learning. Moreover, their
evaluation methods often reflect overconfidence. In this paper, we uncover the behavior exhibited by human-like learners and LLMs, particularly the General Learner—a personafree base LLM that employs shortcut learning (e.g., diligence and detailed answers) but fails on tasks requiring
deep, generalizable understanding.
Furthermore, LearnerAgent provides a novel simulation
framework with broad implications for AI and Education
domains. For AI researchers, it offers a psychologically
grounded approach to identify and mitigate shortcut learning. For Education scholars, it serves as a dynamic alternative to static surveys, enabling the study of learning and
development over time. Future research can build on this
framework to promote deep learning, mitigate the gap between self-concept and achievement, and benchmark emergent cognitive tendencies across diverse LLMs.
### **Conclusion**

In this paper, we introduced **LearnerAgent**, a multi-agent
framework designed to simulate and analyze the complex
dynamics of human learning based on Educational Psychology. Through a year-long simulation, we successfully
tracked diverse learning behaviors, developmental trajectories, and social interactions across distinct learners. Our
work yielded three key insights. First, persona-driven agents
could effectively replicate nuanced human learning behavior with high fidelity. Second, we identified distinct learn

-----

ing deficits among agents that exhibited similar short-term
performance but diverged significantly in long-term generalization—a finding illustrated by performance “traps” that
expose deeper vulnerabilities. Third, the default emergent
behavior of a persona-free base LLM, termed the “diligent
but brittle surface learner,” reflected an agent that mastered
surface competence yet lacked robust, generalizable understanding. We further showed that an inflated self-concept
contributed to overconfidence, ultimately hindering growth.
### **References**

Abdelnabi, S.; Gomaa, A.; Sivaprasad, S.; Sch¨onherr, L.;
and Fritz, M. 2024. Cooperation, competition, and maliciousness: Llm-stakeholders interactive negotiation. *Ad-*
*vances in Neural Information Processing Systems*, 37:
83548–83599.

Aher, G. V.; Arriaga, R. I.; and Kalai, A. T. 2023. Using large
language models to simulate multiple humans and replicate
human subject studies. In *International conference on ma-*
*chine learning*, 337–371.
Alexander, P. A. 2004. A model of domain learning: Reinterpreting expertise as a multidimensional, multistage process.
In *Motivation, emotion, and cognition*, 287–312. Routledge.
Argyle, L. P.; Busby, E. C.; Fulda, N.; Gubler, J. R.; Rytting,
C.; and Wingate, D. 2023. Out of one, many: Using language models to simulate human samples. *Political Analy-*
*sis*, 31(3): 337–351.

Boiko, D. A.; MacKnight, R.; Kline, B.; and Gomes, G.
2023. Autonomous chemical research with large language
models. *Nature*, 624(7992): 570–578.

Chen, J.; Yuan, S.; Ye, R.; Majumder, B. P.; and Richardson,
K. 2023. Put your money where your mouth is: Evaluating
strategic planning and execution of llm agents in an auction
arena. *arXiv preprint arXiv:2310.05746* .
Chin, C.; and Brown, D. E. 2000. Learning in science: A
comparison of deep and surface approaches. *Journal of Re-*
*search in Science Teaching: The Official Journal of the Na-*
*tional Association for Research in Science Teaching*, 37(2):
109–138.

Comanici, G.; Bieber, E.; Schaekermann, M.; Pasupat, I.;
Sachdeva, N.; Dhillon, I.; Blistein, M.; Ram, O.; Zhang,
D.; Rosen, E.; et al. 2025. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context,
and next generation agentic capabilities. *arXiv preprint*
*arXiv:2507.06261* .

Davidson, T. R.; Veselovsky, V.; Kosinski, M.; and West, R.
2024. Evaluating Language Model Agency Through Negotiations. In *The Twelfth International Conference on Learning*
*Representations* .
DeLay, D.; Zhang, L.; Hanish, L. D.; Miller, C. F.; Fabes,
R. A.; Martin, C. L.; Kochel, K. P.; and Updegraff, K. A.
2016. Peer influence on academic performance: A social
network analysis of social-emotional intervention effects.
*Prevention Science*, 17(8): 903–913.

Dillion, D.; Tandon, N.; Gu, Y.; and Gray, K. 2023. Can
AI language models replace human participants? *Trends in*
*Cognitive Sciences*, 27(7): 597–600.


Divband Soorati, M.; Gerding, E. H.; Marchioni, E.; Naumov, P.; Norman, T. J.; Ramchurn, S. D.; Rastegari, B.;
Sobey, A.; Stein, S.; Tarpore, D.; et al. 2022. From intelligent agents to trustworthy human-centred multiagent systems. *AI Communications*, 35(4): 443–457.

Dong, Z.; Chen, J.; and Wu, F. 2025. Knowledge is power:
Harnessing large language models for enhanced cognitive
diagnosis. In *Proceedings of the AAAI Conference on Artifi-*
*cial Intelligence*, volume 39, 164–172.

Ezzaim, A.; Dahbi, A.; Haidine, A.; and Aqqal, A. 2023. AIbased adaptive learning: A systematic mapping of the literature. *Journal of Universal Computer Science*, 29(10): 1161.

Fischer, J. E.; Greenhalgh, C.; Jiang, W.; Ramchurn, S. D.;
Wu, F.; and Rodden, T. 2021. In-the-loop or on-the-loop? Interactional arrangements to support team coordination with
a planning agent. *Concurrency and Computation: Practice*
*and Experience*, 33(8): e4082.

Geirhos, R.; Jacobsen, J.-H.; Michaelis, C.; Zemel, R.; Brendel, W.; Bethge, M.; and Wichmann, F. A. 2020. Shortcut
learning in deep neural networks. *Nature Machine Intelli-*
*gence*, 2(11): 665–673.

Guo, D.; Yang, D.; Zhang, H.; Song, J.; Zhang, R.; Xu, R.;
Zhu, Q.; Ma, S.; Wang, P.; Bi, X.; et al. 2025. Deepseek-r1:
Incentivizing reasoning capability in llms via reinforcement
learning. *arXiv preprint arXiv:2501.12948* .
G¨urcan, O. 2024. Llm-augmented agent-based modelling [¨]
for social simulations: Challenges and opportunities. *HHAI*
*2024: Hybrid human AI systems for the social good*, 134–
144.

Horton, J. J. 2023. Large language models as simulated economic agents: What can we learn from homo silicus? Technical report, National Bureau of Economic Research.

Hurst, A.; Lerer, A.; Goucher, A. P.; Perelman, A.; Ramesh,
A.; Clark, A.; Ostrow, A.; Welihinda, A.; Hayes, A.; Radford, A.; et al. 2024. Gpt-4o system card. *arXiv preprint*
*arXiv:2410.21276* .

Li, H.; Chong, Y.; Stepputtis, S.; Campbell, J. P.; Hughes,
D.; Lewis, C.; and Sycara, K. 2023. Theory of Mind for
Multi-Agent Collaboration via Large Language Models. In
*Proceedings of the 2023 Conference on Empirical Methods*
*in Natural Language Processing*, 180–192.

Li, H.; Gong, R.; and Jiang, H. 2025. Political actor agent:
Simulating legislative system for roll call votes prediction
with large language models. In *Proceedings of the AAAI*
*Conference on Artificial Intelligence*, volume 39, 388–396.

Li, N.; Gao, C.; Li, M.; Li, Y.; and Liao, Q. 2024. EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities. In *Proceedings of the*
*62nd Annual Meeting of the Association for Computational*
*Linguistics (Volume 1: Long Papers)*, 15523–15536.

Liang, T.; He, Z.; Jiao, W.; Wang, X.; Wang, Y.; Wang, R.;
Yang, Y.; Shi, S.; and Tu, Z. 2024. Encouraging Divergent
Thinking in Large Language Models through Multi-Agent
Debate. In *Proceedings of the 2024 Conference on Em-*
*pirical Methods in Natural Language Processing*, 17889–
17904.


-----

Liu, Q.; Tong, S.; Liu, C.; Zhao, H.; Chen, E.; Ma, H.; and
Wang, S. 2019. Exploiting cognitive structure for adaptive
learning. In *Proceedings of the 25th ACM SIGKDD inter-*
*national conference on knowledge discovery & data mining*,
627–635.

M. Bran, A.; Cox, S.; Schilter, O.; Baldassari, C.; White,
A. D.; and Schwaller, P. 2024. Augmenting large language
models with chemistry tools. *Nature Machine Intelligence*,
6(5): 525–535.

Marsh, H. W. 1990. Causal ordering of academic selfconcept and academic achievement: a multiwave, longitudinal panel analysis. *Journal of educational psychology*,
82(4): 646.

Marsh, H. W.; and Martin, A. J. 2011. Academic selfconcept and academic achievement: Relations and causal ordering. *British journal of educational psychology*, 81(1):
59–77.

Marton, F.; and Dahlgren, L. O. 1976. On non-verbatim
learning: III. The outcome space of some basic concepts in
economics. *Scandinavian Journal of Psychology*, 17(1): 49–
55.

Marton, F.; and S¨alj¨o, R. 1976. On qualitative differences in
learning: I—Outcome and process. *British journal of edu-*
*cational psychology*, 46(1): 4–11.

Park, J. S.; O’Brien, J.; Cai, C. J.; Morris, M. R.; Liang, P.;
and Bernstein, M. S. 2023. Generative agents: Interactive
simulacra of human behavior. In *Proceedings of the 36th*
*annual acm symposium on user interface software and tech-*
*nology*, 1–22.

Park, J. S.; Popowski, L.; Cai, C.; Morris, M. R.; Liang, P.;
and Bernstein, M. S. 2022. Social simulacra: Creating populated prototypes for social computing systems. In *Proceed-*
*ings of the 35th Annual ACM Symposium on User Interface*
*Software and Technology*, 1–18.

Qian, C.; Cong, X.; Yang, C.; Chen, W.; Su, Y.; Xu, J.; Liu,
Z.; and Sun, M. 2023. Communicative agents for software
development. *arXiv preprint arXiv:2307.07924*, 6(3): 1.

Ryan, R. M.; and Deci, E. L. 2000. Intrinsic and extrinsic
motivations: Classic definitions and new directions. *Con-*
*temporary educational psychology*, 25(1): 54–67.

Sweller, J. 2011. Cognitive load theory.

Tang, R.; Kong, D.; Huang, L.; and Xue, H. 2023. Large
Language Models Can be Lazy Learners: Analyze Shortcuts
in In-Context Learning. In *Findings of the Association for*
*Computational Linguistics: ACL 2023*, 4645–4657.

Tran, K.-T.; Dao, D.; Nguyen, M.-D.; Pham, Q.-V.;
O’Sullivan, B.; and Nguyen, H. D. 2025. Multi-agent collaboration mechanisms: A survey of llms. *arXiv preprint*
*arXiv:2501.06322* .

Wang, Z.; Yu, Y.; Zheng, W.; Ma, W.; and Zhang, M. 2024.
Macrec: A multi-agent collaboration framework for recommendation. In *Proceedings of the 47th International ACM*
*SIGIR Conference on Research and Development in Infor-*
*mation Retrieval*, 2760–2764.

Wei, J.; Tay, Y.; Bommasani, R.; Raffel, C.; Zoph, B.;
Borgeaud, S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler,


D.; et al. 2022. Emergent Abilities of Large Language Models. *Transactions on Machine Learning Research* .

Weng, L. 2024. Reward Hacking in Reinforcement Learning. https://lilianweng.github.io/posts/2024-11-28-rewardhacking/.
Yang, A.; Yang, B.; Hui, B.; Zheng, B.; Yu, B.; Zhou, C.; Li,
C.; Li, C.; Liu, D.; Huang, F.; Dong, G.; Wei, H.; Lin, H.;
Tang, J.; Wang, J.; Yang, J.; Tu, J.; Zhang, J.; Ma, J.; Xu,
J.; Zhou, J.; Bai, J.; He, J.; Lin, J.; Dang, K.; Lu, K.; Chen,
K.; Yang, K.; Li, M.; Xue, M.; Ni, N.; Zhang, P.; Wang,
P.; Peng, R.; Men, R.; Gao, R.; Lin, R.; Wang, S.; Bai, S.;
Tan, S.; Zhu, T.; Li, T.; Liu, T.; Ge, W.; Deng, X.; Zhou,
X.; Ren, X.; Zhang, X.; Wei, X.; Ren, X.; Fan, Y.; Yao, Y.;
Zhang, Y.; Wan, Y.; Chu, Y.; Liu, Y.; Cui, Z.; Zhang, Z.;
and Fan, Z. 2024. Qwen2 Technical Report. *arXiv preprint*
*arXiv:2407.10671* .

Yuan, Y.; Sun, S.; Liu, Q.; and Bian, J. 2025. CAD-Editor:
A Locate-then-Infill Framework with Automated Training
Data Synthesis for Text-Based CAD Editing. In *Forty-*
*second International Conference on Machine Learning* .

Yuan, Y.; Zhao, L.; Zhang, K.; Zheng, G.; and Liu, Q. 2024.
Do LLMs Overcome Shortcut Learning? An Evaluation of
Shortcut Challenges in Large Language Models. In *Pro-*
*ceedings of the 2024 Conference on Empirical Methods in*
*Natural Language Processing*, 12188–12200.

Zhao, L.; Liu, Q.; Chen, W.; Chen, L.; Sun, R.; Hou, M.;
Wang, Y.; and Wang, S. 2025a. MiMu: Mitigating Multiple
Shortcut Learning Behavior of Transformers. *arXiv preprint*
*arXiv:2504.10551* .

Zhao, L.; Liu, Q.; Yue, L.; Chen, W.; Chen, L.; Sun, R.; and
Song, C. 2024a. Comi: Correct and mitigate shortcut learning behavior in deep neural networks. In *Proceedings of the*
*47th International ACM SIGIR Conference on Research and*
*Development in Information Retrieval*, 218–228.

Zhao, L.; Wang, Y.; Liu, Q.; Wang, M.; Chen, W.; Sheng,
Z.; and Wang, S. 2025b. Evaluating large language models through role-guide and self-reflection: A comparative
study. In *The Thirteenth International Conference on Learn-*
*ing Representations* .

Zhao, Q.; Wang, J.; Zhang, Y.; Jin, Y.; Zhu, K.; Chen, H.;
and Xie, X. 2024b. CompeteAI: Understanding the Competition Dynamics of Large Language Model-based Agents.
In *International Conference on Machine Learning*, 61092–
61107. PMLR.


-----

### **Appendix A: Detailed Implementations**
#### **Partial Prompt Settings** Profile Construction - T Profile Construction - L d

2

5

8
#### Profile Construction - L s

2

6


10
#### Profile Construction - L l

2

6

10
#### Profile Construction - L g Weekl y Teachin g - T

2

5


-----

#### Weekl y Learnin g - L

2

5
#### Weekl y Exercise - T

2

5
#### Weekl y Exercise - L

2

5

8

11

13

14 {

16 {


20 },
21 {

25 },
26 {

30 },
31 {

35 },
36 {

40 }
41 ]
42 }
43
#### **Strategic Choices - Weekly Learning Summary**

2

5

8


-----

11

13

18

20

24

26 {

29 }
#### **Strategic Choices - Weekly Exercise Reflection**

2

5

8

11


14

16

19

21 {

24 }
#### **Strategic Choices - Pre-Monthly Test Review**

2

5

8

11

13

16

19

21 {


-----

24 }
25
#### Monthly Test - L

2

5

8

11

14

16

17 {

19 {

24 },
25 {

30 },
31 {

36 },
37 {


42 },
43 {

48 }
49 ]
50 }
51
#### **Psychological Evaluation**

1

3

6

9

12

15

17


-----

24

26 {

29 }
30
#### Peer Interaction and Debate - T

2

9

11

17

19

24

28

#### Peer Interaction and Debate - L

1

3

6

9

13

16

19

22

27
#### **Detailed Parameter Settings**

In this section, we specify the key parameters and detailed
settings to ensure the reproducibility of our experiments in
LearnerAgent.
**Short-Term Memory Window (** *k* **):** The size of the shortterm memory queue, denoted as *k*, is set to 3. This means
that for any given interaction, whether with the teacher or a
peer, learners maintain access to the three most recent interactive turns.

**Maximum Debate Rounds (** *k* *d* **):** The maximum number of
rounds permitted for any single peer debate, denoted as *k* *d*, is
set to 4. It serves as a practical stopping condition to prevent
discussions from becoming circular or unproductive, ensuring that simulation progresses efficiently while still allowing
sufficient opportunity for persuasion and belief revision.
**Prompt for Trap Questions** : We use Gemini-2.5-Pro (Co

-----

Hello, teacher and classmates! **I believe the correct answer is “whenever”** . This sentence expresses the idea that the speaker
thinks of the little girl at any time he reflects on life’s troubles. “Whenever” better captures this sense of continuous, recurring
reflection. In contrast, “when” tends to refer to specific moments or events. Since the sentence emphasizes attitude and habit,
“whenever” is more appropriate. Bob, what do you think? Do you believe “when” can also express this kind of ongoing pattern?

Hello, teacher and classmates! **I think the correct answer is “when”** . Although “whenever” means at any time, the
sentence seems to express a regular, habitual reflection rather than stressing randomness. “When” fits better for
describing a consistent pattern of thought. Alice, you mentioned that “whenever” better conveys continuity—can you
give a specific example showing how “whenever” works in this context? I feel “when” can also express habitual behavior.

**I still stand by my answer** —“whenever” expresses an unconditional, ongoing attitude more effectively. For example, “Whenever
I face challenges, I remember her lesson.” This emphasizes that every time challenges arise, the speaker remembers the girl.
On the other hand, “When I think about the troubles” sounds more like a one-time or specific instance, which doesn’t match the
habitual mental state being described. Bob, could you provide an example where “when” conveys the same sense of continuity?"

After thinking it over, **I agree that “whenever” does a better job** of expressing a continuous, reflective attitude.
Alice’s example helped me realize that “whenever” fits the intended meaning more accurately—it conveys the idea of
thinking about that little girl anytime troubles arise. My earlier view was a bit limited. Now, I believe the correct answer
is “whenever”. Thank you, Alice, for helping me see that!

Class, today’s debate was excellent! Alice and Bob not only clearly expressed their own viewpoints, but also deepened the
understanding of the distinction between “whenever” and “when” through examples and rebuttals. The correct answer is
“whenever”, and during the debate, Bob was convinced and changed his original opinion. I hope you will continue to maintain this
proactive and engaged attitude in your future learning and keep striving for improvement!

Figure 8: A case study of peer interaction and debate. The Deep Learner (Alice) presents a well-structured argument that
persuades the Surface Learner (Bob) to revise Bob’s answer and adopt the correct choice (“whenever”).


manici et al. 2025) to automatically generate and manually
verify Trap Questions.

2
### **Appendix B: Extended Results and Analyses**
#### **Peer Influence and Debate**

**Metric Definitions.** As shown in Table 2, to systematically
assess learners’ responsiveness to peer input, we categorize
each debate instance into one of three scenarios based on the
initial correctness for every learner: 1) the learner is correct
while the peer is incorrect; 2) the learner is incorrect while
the peer is correct; or 3) both are incorrect. Based on these
settings, we define the following outcome-based metrics:
1) *Persuasion* : The proportion of debates in which the
learner successfully persuades the peer to adopt their answer, without changing their own. This metric is computed
across all scenarios;
2) *Resist Wrong* : In “correct vs. incorrect” cases, the per

centage of instances where the learner maintains their correct stance despite an incorrect challenge;
3) *Accept Correct* : In “incorrect vs. correct” cases, the
percentage of instances where the learner revises their erroneous answer to align with the peer’s correct response.
**Case Study.** A representative case of peer interaction
is shown in Figure 8. Two learners—Deep and Surface—disagree on a fill-in-the-blank question. The Deep
Learner exemplifies a robust reasoning style, leveraging
nuanced interpretation, contextual evidence, and counterarguments to defend the correct answer (“whenever”). This
behavior demonstrates both Resist Wrong and Persuasion.
Conversely, the Surface Learner aligns with the quantitative
result: although not persuasive, it remains cognitively receptive and ultimately adopts the correct answer after evaluating
the superior argument, thereby exhibiting a strong tendency
toward Accept Correct.
#### **Experiments with other LLMs**

To validate the generalizability of LearnerAgent, we additionally conduct experiments with learners based on
LLaMA3.1-8B-Instruct.

**Cognition and Learning Development** To explore the
Cognition and Learning Development of different learners,
we list the performance of distinct learners on monthly exams and specific question types as depicted in Figure 9.
**(1) Longitudinal Performance.** As shown in Figure 9 (a),
all LLaMA-based learners demonstrate a capacity for improvement over the 12-month period, reflected in the positive overall trend lines, though their trajectories are marked
by significant performance volatility. Due to the learning


-----

**(a) Monthly Tests Performance.** **(b) Review.** **(c) Trap.** **(d) K-I.**

Figure 9: Development of learner performance based on LLaMA3.1-8B-Instruct. **(a)** : Total scores of the four learners over
12 months, covering all question types. The dashed lines represent the linear trend for each learner’s scores; **(b)** : Accuracy
on *review* questions, targeting short-term retention of current content; **(c)** : Accuracy on *trap* questions, which assess transfer
learning and deeper understanding; **(d)** : Accuracy on *knowledge-integration (K-I)* questions, evaluating cumulative knowledge
over time.

solidifying its profile as the most effective long-term knowledge accumulator. The other learners also demonstrate competence, with the Deep Learner being the second-best, indicating that all profiles are capable of retaining and integrating knowledge over time.


**(a) Learning Strategies.** **(b) Reasoning Length.** **(c) Logical Connectors.**

Figure 10: Behavioral and cognitive differentiation among
learners based on LLaMA3.1-8B-Instruct. **(a)** Learning
Strategies: Proportion of time allocated to self-improvement
or rest. **(b)** Reasoning Length: Average number of tokens per
reasoning. **(c)** Logical Connectors: Average number of logical connectors per reasoning and their distribution by type
(causal, contrastive, additive).

motivation, self-concept, and development strategy, the deep
learner has the best performance, while the surface learner
has the worst performance in overall performance.
**(2) Cognition Across Question Categories.** Following the
analysis in Figure 3, we assess the performance of distinct
learners on different types of questions—Review, Trap, and
K-I—as shown in Figure 9 (b-d).
On *Review* questions assessing current-month knowledge
(Figure 9 (b)), the Deep Learner performs best, unlike the
Qwen-based Surface Learner, which previously excelled in
the review questions. This indicates that the deep learning
strategy is more effective for LLaMA in consolidating and
recalling recent information, while the General Learner performs the weakest.
On *Trap* questions designed to assess deep understanding
(Figure 9 (c)), the LLaMA agents exhibit an intriguing pattern. Consistent with its profile, the Deep Learner performs
well. General and Surface learners struggle the most, reinforcing their tendency to avoid deep and complex reasoning.
On *Knowledge-Integration (K-I)* questions evaluating cumulative learning (Figure 9 (d)), the results align closely
with the Qwen experiments. The General Learner emerges
as the strongest performer with the highest average score,


**Behavioral and Cognitive Patterns** We analyze behavioral and cognitive patterns in LLaMA-based learners to
further assess the consistency of learner profiles. The results closely align with, and sometimes reinforce, those from
Qwen-based experiments.
**(1) Learning Strategies.** As shown in Figure 10 (a), behavioral patterns differ markedly. The Deep, General, and
Surface Learners strongly prefer self-improvement, whereas
the Lazy Learner—more pronounced than its Qwen-based
counterpart—chooses to “rest” 24.1% of the time, providing
clear evidence of its lower motivation and engagement.
**(2) Reasoning Patterns.** The cognitive patterns observed in
the agents’ reasoning are highly consistent and revealing.
First, as shown in Figure 10 (b), reasoning length varies
notably: the Deep Learner produces the longest and most
elaborate explanations (avg. 60 tokens), suggesting deeper
cognitive processing, while the General Learner is the most
concise. The Surface and Lazy Learners fall in between,
reinforcing a clear link between verbosity and reasoning
depth. Second, Figure 10 (c) highlights differences in reasoning complexity through logical connector usage. The
Deep Learner not only uses the highest density of connectors but also employs a significantly higher proportion of
nuanced, contrastive ones (e.g., “bu”, “although”), indicating a stronger ability to handle ambiguity and alternatives.
In contrast, the other learners rely more on simple causal
connectors (e.g., “because”, “therefore”), reflecting a more
linear reasoning style. Together, these findings confirm that
the cognitive distinctions among our learner profiles are robust and consistent across LLMs.

**Summary** Extensive experiments with LLaMA3.1-8BInstruct further demonstrate the generalizability of our
LearnerAgent framework and validate that the core behavioral patterns and learning trajectories of distinct learners
remain robust across different LLMs.


-----


