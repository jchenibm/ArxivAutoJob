{
  "title": "OMNI EAR: B ENCHMARKING A GENT R EASONING IN E MBODIED T ASKS",
  "detailed_summary": "该论文提出了OmniEAR，一个综合性的框架，用于评估大型语言模型在具身任务中关于物理交互、工具使用和多智能体协作的推理能力。与现有基准测试提供预定义的工具集或明确的协作指令不同，OmniEAR要求智能体动态地获取能力，并根据任务需求自主地确定协作策略。通过基于文本的环境表示，论文模拟了跨越家庭和工业领域的1500个场景中连续的物理属性和复杂的空间关系。系统评估揭示了当模型必须从约束中进行推理时，性能会严重下降：在明确的指令下达到85-96%的成功率，但对于工具推理，性能下降到56-85%，对于隐式协作，性能下降到63-85%，而复合任务的失败率超过50%。令人惊讶的是，完整的环境信息会降低协作性能，表明模型无法过滤任务相关的约束。微调可以显著提高单智能体任务的性能(0.6%到76.3%)，但对多智能体任务的收益最小(1.5%到5.5%)，暴露了根本的架构限制。这些发现表明，具身推理提出了与当前模型可以解决的问题截然不同的挑战，从而将OmniEAR确立为评估和推进具身AI系统的严格基准。",
  "background": "大型语言模型在复杂的推理任务中取得了显著的成功，但它们在具身环境中的推理能力仍然知之甚少。在具身任务中，智能体必须理解物体属性如何影响可能的操作，认识到自身能力不足以完成任务，并确定何时需要协作。这些推理能力与抽象问题求解有根本的不同，因为它们需要理解支配现实世界交互的物理原理。现有的评估方法未能捕捉到这种具身推理的复杂性。现有的基准测试通过离散状态(如门的打开/关闭或物体的拾取/放置)对环境进行建模，忽略了决定动作可行性的连续属性，如重量、温度或材料成分。工具使用评估通常提供固定的动作集，忽略了智能体应该如何推理能力差距。多智能体基准依赖于明确的协作指令或效率指标，而不是检查智能体是否能够识别任务何时超出个人能力。",
  "contributions": [
    "提出了OmniEAR框架，该框架通过需要智能体理解物理属性如何决定动作、能力和协作需求的场景来评估具身推理，解决了当前评估方法中的根本缺陷。",
    "开发了EAR-Bench，一个包含1500个场景的基准测试，具有连续的物理属性和动态能力，由EAR-Sim和一个自动生成管道支持。",
    "提供了经验证据，表明当前的语言模型缺乏核心的具身推理能力，当从明确的指令转移到具身推理时，性能下降超过60%，揭示了推进具身AI的关键需求。",
    "设计了EAR-Sim，可以捕获详细的物体属性和空间关系，同时支持通过工具获取实现动态能力演变。",
    "构建了自动化pipeline，生成多样化的场景，这些场景的解决方案自然取决于对具身原理的理解。"
  ],
  "problem": "要解决的问题是评估大型语言模型在具身环境中的推理能力，具体包括：理解物理属性如何影响可能的动作，识别自身能力不足以完成任务的情况，以及确定何时需要协作。现有的基准测试无法充分捕捉这种具身推理的复杂性，因为它们通常使用离散状态表示环境，提供固定的动作集，或者依赖于明确的协作指令。因此，该论文旨在创建一个更全面、更真实的评估框架，以评估智能体在具身任务中动态获取能力和自主确定协作策略的能力。",
  "methods": [
    "**环境表示：** 使用有向图 *G* *t* = (*V* *t* *, E* *t* *, A* *t* )来形式化具身环境，其中 *V* *t* 包含空间节点、物体节点和智能体节点三种实体类型，*A* *t* 存储连续的物理属性，*E* *t* 编码空间关系。",
    "**任务形式化：** 每个评估任务定义为一个元组 T = (*S* init *, I, G* goal *,* A task )，其中 *S* init 指定初始环境状态，*I* 提供自然语言指令，*G* goal 通过逻辑谓词定义成功条件，A task 标识参与的智能体。评估目标是评估智能体是否可以生成一个动作序列 Π = (*π* 1 *, . . ., π* *T* )，将环境从 *S* init 转换为满足 *G* goal 中所有谓词的终端状态 *S* final。",
    "**分层任务分类：** 任务按照两个正交维度组织：智能体配置（单智能体 vs. 多智能体）和认知复杂性（L1: 基础, L2: 中级, L3: 高级）。",
    "**EAR-Sim环境模拟器：** 使用基于文本的环境建模来实现大规模高效模拟。图结构 *G* *t* 通过拓扑连接维护空间关系，而不是连续坐标，从而避免了昂贵的碰撞检测，同时保留了必要的空间约束。状态更新采用增量方法，其中动作仅修改直接受影响的节点和边。",
    "**动态能力管理：** 通过动态工具-能力绑定系统，当智能体抓住一个工具时，系统会动态地将相关能力绑定到智能体的动作集；释放工具时，这些能力会自动解除绑定。",
    "**涌现协作：** EAR-Sim支持从物理约束中涌现的协作。当智能体尝试对属性超出个体能力的物体执行动作时，系统会启用协作请求机制。",
    "**自动化基准生成：** 通过四阶段pipeline，结合LLM和基于规则的验证，自动生成多样化、物理一致的场景。包括场景生成、任务生成、评估逻辑提取和专家轨迹生成。"
  ],
  "experimental_design": "实验评估了九个代表性的模型，涵盖了三种架构范式：GPT-4o和Gemini-2.5-Flash（闭源模型），Deepseek-V3、Qwen2.5系列和Llama3.1-8B（开源基础模型），以及Deepseek-R1和QwQ-32B（推理专用模型）。所有模型都经过相同的评估，以确保公平比较。实验采用部分可观测性，智能体必须探索环境才能发现物体的位置和属性。每个模型完成2800个测试场景，涵盖七个任务类别，并进行三次独立运行以确保统计可靠性。对Qwen2.5-3B进行微调，使用来自Qwen2.5-72B的1942个成功演示，其中包含20346个指令-动作对，训练模型使用标准的因果语言建模目标。",
  "results": "评估结果显示，任务难度和模型规模对性能有显著影响。在直接指令任务中，模型成功率达到85.2-96.6%，但在复合协作任务中下降到32.0-48.5%。模型规模越大，直接指令任务的性能提升越明显，但对于需要物理约束推理的任务，提升效果不明显。推理专用模型在复合协作任务中表现更好，但难以将抽象属性与物理环境关联。微调Qwen2.5-3B在单智能体任务中显著提升了性能，但在多智能体任务中提升效果有限。",
  "result_analysis": "结果分析表明，任务的复杂程度与模型性能直接相关，Tool Use和Attribute Reasoning任务需要从环境约束中进行推理，因此性能下降明显。模型规模的增加可以提高执行能力和规划能力，但不能显著提高对物理属性的理解。推理专用模型擅长逻辑规划，但在物理约束方面表现不佳。微调可以提高单智能体任务的性能，但不能推广到多智能体场景，表明协调推理需要超出当前训练方法的架构能力。",
  "conclusions": "该论文提出的OmniEAR基准测试表明，当前的语言模型在具身推理方面存在严重不足，尤其是在需要从物理约束进行推理的任务中。研究结果揭示了维持多步骤计划的关键参数阈值，环境信息对协作的矛盾影响，以及微调无法解决多智能体推理差距的问题。具身推理需要与当前语言模型不同的计算机制。OmniEAR为诊断这些局限性并开发下一代具身AI系统提供了一个严谨的平台。",
  "limitations": "该论文的局限性在于其基于文本的框架抽象掉了连续控制、感觉运动反馈和物理具身系统中存在的实时约束。虽然这种抽象实现了系统评估，但可能无法捕捉到具身智能的所有方面。架构需求需要在连续控制设置中进行验证。未来的工作应该研究这些组件如何与感觉运动处理集成，并检查在物理接地系统中是否仍然存在观察到的计算瓶颈。",
  "future_work": "未来的工作应该调查这些组件如何与感觉运动处理集成，并检查在物理接地系统中是否仍然存在观察到的计算瓶颈。此外，探索混合符号-神经架构，可以显式地推理物理定律，同时保持学习的灵活性，代表了一个有希望的方向。",
  "applications": "这项研究的实际应用场景包括：开发更智能的机器人，可以在复杂的环境中执行任务，例如家庭护理、工业自动化和医疗保健。此外，该研究还可以用于改进虚拟助手，使其能够更好地理解用户的指令并提供更有效的帮助。通过提高具身AI系统的推理能力，可以实现更安全、更可靠和更高效的自动化解决方案。",
  "related_work": "文中提到了与本研究相关的重要文献，包括ALFRED、BEHAVIOR-1K、RoCo、PARTNR、TDW-MAT和EmbodiedBench等。这些文献在具身智能评估、工具使用评估和多智能体协作评估等方面做出了重要贡献，但与OmniEAR相比，它们在物理属性建模、动态动作空间和隐式协作等方面存在局限性。",
  "github_links": [
    "https://github.com/ZJU-REAL/OmniEmbodied"
  ],
  "published": "2025-08-07T17:54:15+00:00"
}