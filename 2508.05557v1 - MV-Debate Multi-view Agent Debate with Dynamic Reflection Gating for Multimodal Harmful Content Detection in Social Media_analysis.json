{
  "title": "MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media",
  "detailed_summary": "这篇论文提出了一种名为MV-Debate的多视角Agent辩论框架，用于在社交媒体中检测多模态有害内容。由于社交媒体中图像、文本和其他信号相互作用，导致讽刺、仇恨言论或虚假信息等有害意图难以识别，该框架旨在解决这一挑战。MV-Debate集成了四个互补的辩论Agent，分别从表面分析、深度推理、模态对比和社会背景四个角度分析内容。通过迭代辩论和反思，Agent们根据∆-gain准则改进回应，确保准确性和效率。在三个基准数据集上的实验表明，MV-Debate显著优于强大的单模型和现有的多Agent辩论基线模型。这项工作突出了多Agent辩论在推进高可靠性的社交意图检测方面的潜力，对于在线安全领域至关重要。",
  "background": "社交媒体平台作为多模态交流渠道（整合图像、短视频、表情符号和风格化文本）的快速发展，显著增加了在线信息的复杂性和模糊性，给有效检测多模态有害内容带来了严峻挑战。例如，当看似中性的标题与讽刺图片或夸张的视觉提示搭配时，会表达出隐藏的嘲讽，而仅凭文本无法检测到；类似地，表情包或编辑过的视频常常会放大超出其字面内容的的情感或说服意味，使有害意图的检测变得复杂。准确识别潜在的*社会意图*至关重要，无论帖子是*嘲笑*（讽刺）、*诋毁*（仇恨言论）还是*误导*（虚假信息），这不仅对于内容审核和社区安全，而且对于舆情挖掘、公共讨论分析和操纵活动检测都至关重要。用户创造性地融合各种模态，常常依赖于文化参照、讽刺或模糊性来掩盖有害信息，这进一步加剧了挑战。因此，有效的检测需要整合语言线索、视觉语义和背景知识，以揭示多模态内容的真实交流意图，确保在日益复杂的在线环境中，在安全关键应用中的可靠性能。\n然而，这种意图仍然难以辨别，因为线索通常是（i）*跨模态的*：图像可以反转或加强标题的含义；（ii）*依赖于上下文的*：表情包、俚语和文化参照快速演变；以及（iii）*微妙或稀疏分布的*：有害意图可能巧妙地隐藏在主要为良性的内容中。实证研究证实了这些障碍：最先进的多模态分类器难以处理具有文化基础的讽刺（Lu et al. 2025），而像BERT变体这样的单流文本模型在视觉证据与文本情感相矛盾时会变得脆弱（Hee, Chong, and Lee 2023）。\n最近，随着LLM Agent的发展，基于多Agent的框架在许多领域取得了显著进展（Guo et al. 2024；Chan et al. 2023）。其中，多Agent辩论（Chan et al. 2023；Madaan et al. 2023）是一种利用多个Agent之间的辩论来提升推理性能的有效方式，它可以弥补个体Agent的盲点。代表性的方法包括意见持有（Estornell and Liu 2024）和自由形式方法（Chan et al. 2023），前者为讽刺任务分配预定义的意见（例如，真），而后者执行自由形式预测。通过鼓励Agent暴露、捍卫和反驳替代解释，多Agent辩论机制提高了复杂推理任务的性能，例如零样本立场检测和价值敏感型决策制定（Du et al. 2023a；Zhang et al. 2024）。虽然取得了显著的性能，但很少有工作探索多Agent辩论用于多模态有害内容检测。",
  "contributions": [
    "提出了MV-Debate，一个多Agent辩论框架，引导Agent采用多样化的推理视角来检测社交媒体中的多模态有害内容。",
    "设计了四个特定视角的辩论Agent，并结合动态反射门控机制来提高性能。",
    "通过多个多模态有害内容基准数据集，验证了所提出方法的有效性。",
    "利用Top-k ∆-Reflection Gating 机制，权衡辩论质量与效率，实现性能提升。",
    "通过消融实验验证了不同辩论Agent和反射机制的有效性，并分析了模型大小和辩论轮数对性能的影响。"
  ],
  "problem": "当前的多Agent辩论系统在此场景中通常存在以下缺点：（i）在多Agent辩论设置中，现有方法通常在各个角色中使用相同的LLM提示，由于预训练偏差，导致类似的推理模式和重复的错误。（ii）通用MAD策略是为通用问题解答任务设计的，这通常忽略了特定任务的设计，导致次优的性能。（iii）现有方法侧重于*单个语用类别*，这需要针对不同的任务采用多种不同的方法。",
  "methods": [
    "**问题形式化:** 给定一个由文本 *x*[text] 和相关视觉内容 *x*[img] 组成的多模态社交媒体帖子，目标是预测其潜在的 *社会意图* 标签 *y ∈Y*，其中 *Y* = {*Yes, No*} 表示是否存在讽刺、仇恨内容或虚假信息。目标是最大化预测准确率。",
    "**系统架构:** MV-Debate系统由四种类型的专业辩论Agent以及三个附加的控制Agent组成。 每个辩论Agent都需要用相应的指定视角回答问题，而控制Agent旨在对推理路径进行评分和反思，并最终做出最终预测。",
    "**专业辩论Agent:**\n - **表面分析师Agent (SA):** 此Agent专门关注显式的文本和视觉线索以进行检测。\n - **深度推理师Agent (DR):** 此Agent揭示了隐含的含义和隐藏的意图以进行检测。\n - **模态对比Agent (MC):** 此Agent评估文本和视觉模态之间的对齐或矛盾以进行检测。\n - **社会背景主义者Agent (SC):** 此Agent利用外部文化和社会背景知识进行检测。",
    "**法官Agent:** 此Agent评估辩论Agent生成的论点。 它根据逻辑连贯性、一致性和合理性分配分数，其中较好的响应会获得更高的分数。",
    "**反思Agent:** 此Agent生成结构化的反馈，突出显示逻辑缺陷和改进建议。",
    "**总结Agent:** 此Agent汇总辩论历史并提供最终预测。",
    "**多视角辩论:** 在辩论的第一轮，给定一个图像-文本对，每个专业辩论Agent都会生成其响应 *r* *i,* 1，其中下标“1”表示第一轮，由相应的任务视角提示 *p* *i* 指导：\n\n*r* *i,* 1 = *M* *i* ( *x* [*text*] *, x* [*img*] *|h* *i* *, p* *i* ) *, i* = 1 *,* 2 *, ...,* 4 *.* (1)\n\n其中 *h* *i* 是第 *i* 个Agent的历史消息，并初始化为空列表。 *r* *i,* 1 输出为结构化的JSON对象，其中包含二进制决策（“YES”或“NO”）和简要推理。 它们特定角色的提示严格执行不同的分析视角，从而确保整个推理过程中的多样性和互补性。\n因此，法官Agent会收集所有辩论Agent的解决过程和对问题的回答，并为每个Agent的响应分配一个分数 *s* *i,* 1，其中较好的响应会获得更高的分数。",
    "**Top-** *k* ∆ **-反思门控:** 由于这些Agent的初始响应可能包含不正确的信息，因此，按照以前的工作，我们引入了一种反思机制来自我改进响应质量。\n\n为了减少计算开销，我们引入了一种Top-*k* ∆-反思门控策略。 在每一轮中，反思Agent都会收到所有辩论Agent的响应，并检查每个Agent的推理过程。 然后，它将指出推理错误并提供修改建议。 接下来，选择由法官Agent评分的最高的*k*个响应。 然后，每个选定的原始辩论Agent都会生成一个新的响应ˆ*r* *i,* 1，其中包含查询实例、初始响应和修改建议。 之后，法官Agent将重新评分新的响应，表示为 *s* ˆ*i,* 1。\n\n然后，我们通过比较具有和不具有反思反馈的Agent的分数来估计反思的预期效用。 正式地，反思增益∆*i,* 1的计算方式如下：\n\n∆ *i,* 1 = [1]\n\n*k*\n\n (ˆ*s* *i,* 1 *−* *s* *i,* 1 ) (2)\n\n*i∈* Top *k*\n\n仅当∆*i,* 1超过预定义的阈值*τ*时，才触发反思，即∆*i,* 1 *≥* *τ*。 否则，我们将使用原始响应。\n在我们的实验中，我们凭经验设置*k* = 2和*τ* = 0 *.* 1以实现效率提升。 与反映所有辩论Agent相比，它可以减少超过60％的冗余反思调用，同时保持或提高准确性，与无条件反思基线相比。",
    "**历史更新:** 反思之后，如果未采用较新的响应，则法官Agent将收集得分最高的响应，并将其附加到历史记录中。 否则，我们还将推理错误和修改建议*ϕ* 1附加到历史记录中。",
    "**辩论循环:** 从第二轮开始，将上一轮得分最高的响应（包括推理过程和答案）纳入每个Agent的历史记录 *h* *i* 中。 在接下来的回合中，每个Agent都利用这些推理轨迹和解决方案作为附加输入，有选择地从不同的角度提取有用的信息，以完善自己的答案。 此迭代辩论过程遵循与上述相同的过程，直到达到最大回合数*N*或Agent收敛到相同的判断为止。 在我们的实验中，我们将*N*设置为3。最后，在辩论结束时，总结Agent将汇总辩论历史并提供最终预测ˆ*y*。 算法1总结了迭代辩论和反思过程。",
    "建议的反射门控多视图辩论框架（MV-Debate）为多模式有害内容检测提供了三个主要优势。首先，将专门的角色分配给辩论代理，从而可以采用不同的推理视角。与单视图提示不同，此设计结合了表面水平、深度语义、跨模态和社文化分析，从而降低了错过隐式或特定于上下文的有害线索的风险。",
    "其次，Top- *k* ∆ -反射门控机制可在保持效率的同时提高可靠性。 通过仅在期望有显着改进时自适应地触发反射，该框架避免了冗余计算，但实现了与无条件反射相当或更好的准确性。 这与可伸缩性和成本效益至关重要的实际部署相关。",
    "第三，迭代辩论循环鼓励累积推理。 代理通过将高质量的响应和结构化反馈集成到他们的历史记录中来完善其预测，从而促进了代理间多样性和代理内改进，同时减少了重复错误。"
  ],
  "experimental_design": "遵循之前的工作（Lin et al. 2024b；Liang et al. 2022），在本节中，我们对三个广泛使用的多模态社交上下文数据集进行了全面的实验，包括用于讽刺检测任务的MMSD数据集（Benchekroun et al. 2022），用于仇恨言论任务的HatefulMeMe数据集（Kiela et al. 2020）以及用于虚假信息检测任务的GossipCop数据集（Shu et al. 2020）。由于我们的方法和基线多Agent辩论方法需要给定实例的许多token，因此遵循先前的工作（Du et al. 2023a；Liu et al. 2025）。我们不使用整个数据集，而是随机选择一个子集进行评估。MMSD，HatefulMeMe和GossipCop数据集的数量均为500。",
  "results": "与基线方法的比较如表1所示。根据结果，我们有以下发现。\n**单模型基线。** 封闭源模型通常优于开放源模型。 Claude-4-Sonnet在单模型中实现了最佳的整体性能，而GPT 4o和GPT o4-mini略有落后。 相比之下，开放源模型显示出显着的性能差距，其中Qwen2.5-VL变体的性能较差。 这些结果表明将现成的开放源LMM应用于有害内容检测的难度。\n\n**现有的多Agent辩论基线。** 我们在具有SOTA开放源LMM（包括Qwen2.5-VL-7B-instruct，InternVL3-14B，LLaMA-4-Maverick-17B和Gemma-3-12B）的异构设置中实现了现有的多Agent辩论基线。 结果表明，现有的多Agent辩论框架（例如，DMAD，ChatEval）显示出优于单模型的明显优势。 例如，ChatEval达到了76.6％的F1分数，这证实了以辩论方式进行的多Agent协作提高了鲁棒性。\n\n**我们的同质MV-Debate。** 在同质场景中，我们使用四种开放源LMM实现了MV-Debate。 结果表明，我们的同质框架始终比其基本模型有所改进。 例如，Gemma-3-12B的准确率从70.2（单个）提高到MV-Debate的75.6，而InternVL3-14B从71.6提高到76.1。 LLaMA-4-Maverick-17B以78.0的准确率实现了最佳的开放源结果。 这些收益验证了即使没有异构Agent，也可以强制执行多视角推理和反射的有效性。\n\n**我们的异构MV-Debate。** 我们在具有开放源和封闭源LMM的异构场景中实现了MV-Debate，并且我们的异构框架实现了最高的性能。 此外，开放源变体的准确率为80.5，优于现有的多Agent辩论方法。 封闭源变体的准确率达到84.9，超过了所有基线。 这表明反射门控的多视角辩论建立了新的最先进的结果。 此外，异构Agent在开放源模型下比同质Agent实现了更好的结果，这意味着不同的模型也可能导致不同的思考方式。\n\n总而言之，MV-Debate有效地将各种推理视角与自适应反射相结合，从而实现了卓越的准确率和效率。 结果凸显了其作为可伸缩且可靠的多模态有害内容检测框架的前景。",
  "result_analysis": "消融研究表明，移除任何一个Agent都会导致性能下降，其中Modality Contrast Agent的影响最大，其次是Deep Reasoner Agent。此外，历史记录的质量对结果有显著影响，选择最佳历史记录能显著提升性能。消融实验还表明，增加辩论轮数通常会提高性能，但收益会逐渐饱和。模型大小的增加也能带来性能的提升。",
  "conclusions": "论文提出了一种名为MV-Debate的多视角辩论框架，用于检测社交媒体上的多模态有害内容。通过协调四个具有互补推理策略和动态反射门控机制的特定视角Agent，MV-Debate有效地整合了跨模态证据和上下文线索，以识别复杂的社会意图，例如讽刺、仇恨言论和虚假信息。在多个基准测试中进行的大量实验证实了其与强大的基线相比具有卓越的准确性、效率和可解释性。除了性能提升之外，MV-Debate还生成了透明的辩论记录，从而支持模型调试、审计和用户信任。展望未来，我们的框架为将多Agent辩论方法扩展到更广泛的安全关键型多模态推理任务奠定了基础。",
  "limitations": "该框架的性能取决于底层的LMM，这些LMM可能会继承偏差或难以处理具有文化细微差别的讽刺等内容。 当前的设计还修复了推理视角的数量，这可能并不总是平衡准确性和效率。",
  "future_work": "未来的工作可以探索如何自适应地调整推理视角的数量和类型，以及如何减轻底层LMM的偏差。",
  "applications": "这项研究可以应用于社交媒体平台的内容审核，自动检测和过滤有害内容，维护社区安全。还可以应用于舆情分析、公共讨论分析和操纵活动检测。",
  "related_work": "论文详细讨论了与有害内容检测、多Agent辩论和大型多模态模型相关的研究工作，并对比了现有方法的不足之处。",
  "github_links": [],
  "published": "2025-08-07T16:38:25+00:00"
}