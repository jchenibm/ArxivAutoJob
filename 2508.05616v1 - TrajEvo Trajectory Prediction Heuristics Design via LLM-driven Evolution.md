## **T RAJ E VO : Trajectory Prediction Heuristics Design via LLM-driven Evolution**
### Zhikai Zhao [1*], Chuanbo Hua [1, 2*], Federico Berto [1, 2*], Kanghoon Lee [1], Zihan Ma [1], Jiachen Li [3], Jinkyoo Park [1, 2]

1 KAIST, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea
2 OMELET, Daejeon, South Korea
3 University of California, Riverside, CA, USA
*{* zzk020202, cbhua, fberto, leehoon, zihanma *}* @kaist.ac.kr; jiachen.li@ucr.edu; jinkyoo.park@kaist.ac.kr


**Abstract**

Trajectory prediction is a critical task in modeling human
behavior, especially in safety-critical domains such as social robotics and autonomous vehicle navigation. Traditional
heuristics based on handcrafted rules often lack accuracy and
generalizability. Although deep learning approaches offer improved performance, they typically suffer from high computational cost, limited explainability, and, importantly, poor
generalization to out-of-distribution (OOD) scenarios. In this
paper, we introduce T RAJ E VO, a framework that leverages
Large Language Models (LLMs) to automatically design trajectory prediction heuristics. T RAJ E VO employs an evolutionary algorithm to generate and refine prediction heuristics from past trajectory data. We propose two key innovations: Cross-Generation Elite Sampling to encourage population diversity, and a Statistics Feedback Loop that enables
the LLM to analyze and improve alternative predictions. Our
evaluations demonstrate that T RAJ E VO outperforms existing
heuristic methods across multiple real-world datasets, and notably surpasses both heuristic and deep learning methods in
generalizing to an unseen OOD real-world dataset. T RAJ E VO
marks a promising step toward the automated design of fast,
explainable, and generalizable trajectory prediction heuristics. We release our source code to facilitate future research
[at https://github.com/ai4co/trajevo.](https://github.com/ai4co/trajevo)


Manual Heuristic Design Deep Learning **TrajEvo (Ours)**







...... ......



Poor

Genera
lization


Poor

Performance



Slow


|Col1|Col2|
|---|---|
|||

|Col1|-|
|---|---|
|||


ID OOD ID OOD ID OOD




### **Introduction**

Trajectory prediction is a cornerstone of intelligent autonomous systems (Madjid et al. 2025; Wang et al.
2025a,b), with numerous real-world applications, including
autonomous driving (Wang et al. 2024a; Li et al. 2024b;
Wang et al. 2025c; Lange et al. 2024; Wang et al. 2025d;
Lange, Li, and Kochenderfer 2024), industrial safety (RoblaG´omez et al. 2017), robotic navigation (Vishwakarma et al.
2024; Li et al. 2024a; Yao et al. 2024), and planning (Li
et al. 2022b, 2023b). The inherent stochasticity of these environments demands systems that can accurately process
data with both temporal and spatial precision (Li et al. 2021;
Nakamura, Tian, and Bajcsy 2024; Toyungyernsub et al.
2024). For instance, in autonomous vehicle navigation, accurately predicting pedestrian trajectories is essential for
avoiding collisions in complex urban settings (Cao et al.
2021; Li et al. 2023a; Choi et al. 2021). Similarly, in in

Figure 1: Motivation for our T RAJ E VO framework. Traditional manual heuristic design (left) relies on human expertise and trial-and-error processes. Deep learning approaches
(center) produce more accurate predictions but demand substantial computational resources, yield black-box models,
and often struggle with generalization. T RAJ E VO (right) automates the heuristic design process using evolutionary algorithms, enabling the generation of novel and effective trajectory prediction heuristics.

dustrial and indoor environments, robots must generate precise trajectory predictions to collaborate safely with humans
in shared workspaces without causing harm (Mavrogiannis
et al. 2023; Mahdi et al. 2022; Ma et al. 2022).
Accurately predicting the movement patterns of multiple agents, such as pedestrians or vehicles, remains fundamentally challenging. Human motion is inherently complex, characterized by nonlinear behaviors, sudden directional changes, and spontaneous decisions influenced by individual factors such as habits or urgency (Li et al. 2020; Xu
et al. 2024). Moreover, agents interact dynamically, adjusting their paths to avoid collisions, responding to traffic, or
moving cohesively in groups, which results in high stochasticity (Amirian et al. 2020; Zhou et al. 2022; Li et al. 2022a).
Early efforts to model these behaviors relied on heuristic


 - These authors contributed equally.


-----

methods, including the Social Force model (Helbing and
Molnar 1995), which captures interactions through physicsinspired forces (Helbing and Molnar 1995; Luber et al.
2010; Zanlungo, Ikeda, and Kanda 2011; Farina et al. 2017;
Chen et al. 2018); constraint-based approaches that define
collision-free velocities (van den Berg, Lin, and Manocha
2008; Ma, Manocha, and Wang 2018); and agent-based simulations of decision making processes (Yamaguchi et al.
2011). While these handcrafted heuristics offer interpretability, they are often difficult to tune for dynamic scenarios and
tend to suffer from limited accuracy and generalization.
Deep learning methods have emerged as a powerful alternative to traditional heuristics (Alahi et al. 2016; Salzmann et al. 2020; Li et al. 2022a). Social-LSTM (Alahi
et al. 2016) was among the earliest influential models, leveraging LSTMs for trajectory prediction. Since then, a wide
range of approaches, such as graph neural networks (GNNs)
(Rainbow, Men, and Shum 2021; Ma et al. 2021) and generative adversarial networks (GANs) (Gupta et al. 2018; Li,
Ma, and Tomizuka 2019; Dendorfer, Elflein, and Leal-Taix´e
2021), have been proposed to further improve prediction accuracy. More recently, Transformer-based frameworks (Kim
et al. 2025; Bae, Lee, and Jeon 2024) and diffusion models
(Yang et al. 2024; Gu et al. 2022; Fu et al. 2025) have shown
promise in capturing complex dependencies in human motion patterns. However, deep learning methods suffer from
several practical limitations. *a) Running Speed:* They often require significant computational resources and exhibit
high latency, making them unsuitable for deployment on
resource-constrained robots or vehicles (Itkina and Kochenderfer 2023; Jiang et al. 2025). *b) Interpretability:* As blackbox models, they lack transparency, which hinders verification and reduces trust, especially in safety-critical applications (Dax et al. 2023; Liu et al. 2024c; Cai and Ren 2024).
*c) Generalization Ability:* Perhaps most critically, they often generalize poorly in out-of-distribution (OOD) scenarios, potentially leading to unsafe behavior in unfamiliar environments (Korbmacher and Tordeux 2022; Rudenko et al.
2020). These challenges highlight the continued importance
of robust and predictable heuristics in safety-critical systems
(Phong et al. 2023), which requires methods that are not only
accurate but also fast, explainable, and generalizable.
Therefore, we pose the following research question: *Can*
*we automatically design computationally efficient, accurate,*
*interpretable, and highly generalizable trajectory prediction*
*heuristics?* Inspired by recent research exploring combinations of Large Language Models (LLMs) with Evolutionary Algorithms (EAs) for automated algorithm design (Dat,
Doan, and Binh 2025; Ye et al. 2024; Chen et al. 2024; Liu
et al. 2024a; Yuksekgonul et al. 2025; Liu et al. 2024b; Wu
et al. 2024; Zhang et al. 2024; Zheng et al. 2025; Novikov
et al. 2025), we propose a novel approach to automatically
generate effective prediction heuristics. We hypothesize that
coupling the generative and reasoning capabilities of LLMs
with the structured search of EAs can overcome the limitations of manual heuristic design to discover novel, highperformance heuristics suitable for real-world deployment.
In this paper, we introduce T RAJ E VO ( **Traj** ectory
**Evo** lution), a novel framework designed to achieve this goal.


T RAJ E VO leverages LLMs within an evolutionary loop to iteratively generate, evaluate, and refine prediction heuristics
directly from data. Our main contributions are as follows:

 - We present T RAJ E VO, the first framework, to the best of
our knowledge, that integrates LLMs with evolutionary
algorithms specifically for the automated discovery and
design of fast, explainable, and robust trajectory prediction heuristics for real-world applications.

 - We introduce a Cross-Generation Elite Sampling strategy
to maintain population diversity and a Statistics Feedback Loop that enables the LLM to analyze heuristic performance and guide the generation of improved candidates based on past trajectory data.

 - We demonstrate that T RAJ E VO generates heuristics
that significantly outperform prior heuristic methods on
public-open real-world datasets and exhibit remarkable
generalization, achieving an over 20% performance improvement on an unseen OOD dataset against both traditional heuristics and deep learning methods, while remaining computationally fast and interpretable.
### **Related Work**

**Heuristic Methods for Trajectory Prediction** Traditional heuristic approaches provide interpretable frameworks for trajectory prediction, but often with accuracy
limitations. The Constant Velocity Model (CVM) and its
sampling variant (CVM-S) (Sch¨oller et al. 2020) represent
foundational baselines that assume uniform motion patterns.
More sophisticated approaches include Constant Acceleration (Polychronopoulos et al. 2007), CTRV (Constant Turn
Rate and Velocity) (Lu et al. 2021), and CSCRCTR (Zhai,
Meng, and Wang 2014), which incorporate different kinematic assumptions. The Social Force Model (Helbing and
Molnar 1995) pioneered physics-inspired representations of
pedestrian dynamics, with numerous extensions incorporating social behaviors (Zanlungo, Ikeda, and Kanda 2011;
Farina et al. 2017; Chen et al. 2018) and group dynamics
(Helbing, Farkas, and Vicsek 1997). Despite their efficiency
and explainability, they typically struggle with complex realworld, multi-agent interactions due to their limited expressiveness and reliance on manually defined parameters – limitations our proposed T RAJ E VO framework specifically addresses through automatic heuristic generation.

**Learning-based Trajectory Prediction** Deep learning
has substantially advanced trajectory prediction accuracy
at the cost of computational efficiency and interpretability
(Sun et al. 2022; Xie, Li, and Wang 2023). Social-LSTM
(Alahi et al. 2016) is a seminal work using a social pooling
mechanism to model inter-agent interactions, while SocialGAN (Gupta et al. 2018) leveraged generative approaches
to capture trajectory multimodality. Graph-based architectures like STGAT (Huang et al. 2019) and Social-STGCNN
(Mohamed et al. 2020) explicitly model the dynamic social graph between pedestrians. Recent approaches include
Trajectron++ (Salzmann et al. 2020), which integrates various contextual factors, MemoNet (Xu et al. 2022) with its
memory mechanisms, EigenTrajectory (Bae, Oh, and Jeon


-----

Constant Velocity Model


















|MSE=0.18|Col2|
|---|---|
|||


Number of Function Evaluations

|Init Short-term Long-term Population Statistics Population Reflection Reflection Heuristic Generator ...... ex.e....i.n.fo Reflection Reflection LLMs Heuristic LLMs LLMs exe.info ...... Generator ...... Generator LLMs LLMs Elitist Mutation Crossover|Col2|Col3|
|---|---|---|
||......||
|Short-term Long-term ... ... Reflection Reflection ...... High-performing heuristics Cross-Generation Elite Sampling (CGES) ...... Elitist Mutation ...... Crossover|||



Figure 2: An illustration of the T RAJ E VO evolutionary process. **(Left)** The framework continuously discovers and evaluates a
variety of heuristic strategies, such as those based on constant velocity or social forces. **(Middle)** As the evolution progresses,
the performance of these heuristics steadily improves, evidenced by the decreasing objective value from a simple seed to a final,
optimized solution. **(Right)** The overall T RAJ E VO pipeline orchestrates this entire discovery and optimization process, using
an LLM-driven evolutionary algorithm to automatically generate and refine the heuristics.


2023) focusing on principal motion patterns, Hyper-STTN
(Wang et al. 2024b) utilizing hypergraph-based spatialtemporal transformers for group-aware trajectory prediction, and MoFlow (Fu et al. 2025) employing normalizing
flows for stochastic prediction. While these methods achieve
high in-distribution accuracy, their three well-documented
challenges: high computational cost, lack of interpretability,
and poor out-of-distribution generalization (Rudenko et al.
2020), motivate the design of our T RAJ E VO framework.

**LLMs for Algorithmic Design** Recent work has combined Large Language Models (LLMs) with Evolutionary
Algorithms (EAs) for automated algorithm design (Ye et al.
2024; Dat, Doan, and Binh 2025). However, applying this
paradigm to the safety-critical and stochastic domain of trajectory prediction remains unexplored. To the best of our
knowledge, T RAJ E VO is the first framework to adapt LLMdriven EAs for discovering fast, interpretable, and generalizable trajectory prediction heuristics. While these studies
establish the general potential of LLM-driven evolution, its
application to specialized, safety-critical domains remains
largely unexplored. The domain of multi-agent trajectory
prediction presents unique challenges, including stochastic
interactions and the need for both high accuracy and computational efficiency. To the best of our knowledge, T RAJ E VO
is the first framework to adapt the LLM-driven evolutionary
paradigm specifically for this task.
### **T RAJ E VO**
#### **Problem Definition**

**Task** We address multi-agent trajectory prediction. The
task is, for each agent *i*, to predict its future path *Y* *i* =


( *P* *i* *[T]* [obs] [+1] *, . . ., P* *i* *[T]* [obs] [+] *[T]* [pred] ) given its observed history *H* *i* =
( *P* *i* [1] *[, . . ., P]* *i* *[ T]* [obs] ), where *P* *i* *[t]* *[∈]* [R] [2] [ is the position at timestep]
*t* . Here, *T* obs is the historical observation span and *T* pred is
the future prediction length.

**Metrics** We adopt the widely used standard measurement matrix in trajectory prediction to ensure fair comparison with all baselines (Gupta et al. 2018). Performance
is measured by the minimum Average Displacement Error (minADE *K* ) and minimum Final Displacement Error
(minFDE *K* ). This matrix evaluates a model’s ability to capture the multi-modal nature of human motion by generating
*K* trajectory samples and selecting the one with the lowest
error against the ground truth. Following the same setting as
the baselines, we use *K* = 20 for our method to ensure a
fair and direct comparison.

**Optimization** **Objective** To guide the evolutionary
search, we employ the Mean Squared Error (MSE) and
calculate the average squared Euclidean distance between
the predicted and ground truth trajectory points, where a
lower MSE corresponds to a higher fitness. The choice of
MSE is motivated by its simplicity and generality, as well as
its capacity to provide a continuous and well-defined error
signal, which is crucial for guiding the evolutionary process.
Its widespread adoption ensures our results are comparable
across the literature, while its parameter-free nature aligns
with our goal of automated heuristic design.
#### **Evolutionary Framework**

Our evolutionary framework is designed not merely to minimize prediction error on a given dataset, but to discover
heuristics that are fundamentally simple and robust enough


-----

to generalize across different environments. Inspired by the
Reflective Evolution approach (Ye et al. 2024), the framework is illustrated in Fig. 2 (right). In this algorithm, Large
Language Models (LLMs) serve as the core genetic operators, following these steps:

**Initial Population** The process starts by seeding the generator LLM with a task specification (including problem details, input/output format, and the objective *J* ) alongside
a basic heuristic like the Constant Velocity Model (CVM)
(Sch¨oller et al. 2020). The LLM then generates an initial
population of *N* diverse heuristics, providing the starting
point for the evolutionary search.

**Selection for Crossover** Parents for crossover are chosen
from successfully executed heuristics in the current population. The selection balances exploration and exploitation:
70% of parents are selected uniformly at random from successfully running candidates, while 30% are chosen from the
elite performers (those with the lowest objective *J* ).

**Reflections** T RAJ E VO employs two types of reflection as
in Ye et al. (2024). *Short-term reflections* compare the performance of selected crossover parents, offering immediate
feedback to guide the generation of offspring. *Long-term*
*reflections* accumulate insights across generations, identifying effective design patterns and principles to steer mutation
and broader exploration. Both reflection mechanisms produce textual guidance (i.e. “verbal gradients” (Pryzant et al.
2023)) for the generator LLM.

**Crossover** This operator creates new offspring by combining code from two parent heuristics. Guided by short-term
reflections that compare the ‘better’ and ‘worse’ performing
parent, the LLM is prompted to mix their effective “genes”,
enabling the emergence of potentially superior heuristics.

**Elitist Mutation** The mutation operator mutates the elitist
(best found so far) heuristic. In T RAJ E VO, this involves the
generator LLM modifying an elite heuristic selected. This
mutation step is informed by the insights gathered through
long-term reflections.
It is crucial to note that this entire evolutionary process
is a one-time, offline procedure. The final output is a standalone Python heuristic that runs with high computational
efficiency and does not require the LLM during inference.
#### **Cross-Generation Elite Sampling**

Evolving effective heuristics for complex tasks like trajectory prediction poses a significant search challenge, where
standard evolutionary processes can easily get trapped in
local optima (Osuna and Sudholt 2018). Simple mutations
often yield only incremental improvements, failing to explore sufficiently diverse or novel strategies. To address
this limitation and enhance exploration, we introduce CrossGeneration Elite Sampling (CGES), a core component influencing the mutation step within the T RAJ E VO framework.
In contrast to typical elitism focusing on the current generation’s best, CGES maintains a history archive of highperforming heuristics accumulated across all past generations. Specifically, CGES modifies how the elite individ

Figure 3: Cross-Generation Elite Sampling (CGES) helps
escape local optima by sampling elite individuals from past
generations (left), which greatly helps achieve much better
objective values (right).

Figure 4: Statistics Feedback Loop: (top) distribution of prediction index effectiveness by minimum ADE frequency;
(bottom) LLM prompt incorporating statistical feedback for
guided mutation.

ual targeted for mutation is selected: instead of necessarily choosing the top performer from the current population, the heuristic designated to undergo mutation is sampled by CGES directly from this history. This sampling uses
a Softmax distribution based on the recorded objectives *J*
of the historical elites, thus prioritizing individuals that have
proven effective. By potentially reintroducing and modifying diverse, historically successful strategies during the mutation phase, CGES significantly improves the exploration
capability, facilitating escape from local optima and the discovery of more robust heuristics, as demonstrated in Fig. 3.
#### **Statistics Feedback Loop**

While the objective *J* measures overall quality, it does
not reveal *which* of a heuristic’s diverse internal prediction strategies are actually effective. To provide this crucial insight for effective refinement, T RAJ E VO incorporates
a Statistics Feedback Loop (SFL), illustrated in Fig. 4.
This loop specifically analyzes the contribution of the 20


Classical Elitism Selection Cross-Generation Elite Sampling (CGES)








-----

distinct trajectory prediction sets (indexed *k* = 0 *. . .* 19) generated by a heuristic. After evaluation, we compute a key
statistic: a distribution showing how frequently each prediction index *k* delivered the minimum ADE for individual trajectory instances across the dataset (Fig. 4 top). This directly
highlights the empirical utility of the different diversification strategies associated with each index *k* . This statistical
distribution, together with the heuristic’s code, is fed to the
reflector and mutation LLMs to identify which strategies ( *k* )
contribute most effectively to performance (Fig. 4 bottom).
Such feedback provides actionable guidance to the generator LLM, enabling specific improvements to the heuristic’s
multi-prediction generation logic based on the observed effectiveness of its constituent strategies. A qualitative example of the full T RAJ E VO evolution is provided in Fig. 2.
### **Experiments**
#### **Experimental Setup**

**Datasets** We evaluate T RAJ E VO on the ETH-UCY benchmark (Pellegrini et al. 2009; Lerner, Chrysanthou, and
Lischinski 2007), a collection of datasets comprising realworld pedestrian trajectories with the standard leave-one-out
protocol where heuristics are evolved on four datasets and
tested on the remaining one (Alahi et al. 2016). To specifically assess OOD generalization, we use the SDD dataset
(Robicquet et al. 2016) as a completely unseen test set. For
all experiments, following the standard setting widely used
by baseline methods on these benchmarks, we observe 8 past
frames (3.2s) to predict 12 future frames (4.8s).

**Baselines** We compare heuristics generated by T RAJ E VO
against both heuristic and deep learning baselines. *Heuris-*
*tic baselines*, which are well-suited for resource-constrained
systems, include kinematic models such as the Constant
Velocity Model (CVM) and its sampling variant (CVM-S)
(Sch¨oller et al. 2020), Constant Acceleration (ConstantAcc)
(Polychronopoulos et al. 2007), and Constant Turn Rate and
Velocity (CTRV) (Lu et al. 2021), as well as CSCRCTR
(Zhai, Meng, and Wang 2014), Linear Regression (LinReg)
(Bishop and Nasrabadi 2006), and the physics-inspired Social Force model (Helbing and Molnar 1995). To benchmark against more complex data-driven approaches, we also
evaluate *deep learning baselines*, including early influential
models like Social-LSTM (Alahi et al. 2016) and SocialGAN (Gupta et al. 2018); graph-based methods such as
STGAT and Social-STGCNN (Mohamed et al. 2020); and
recent state-of-the-art models like Trajectron++ (Salzmann
et al. 2020), MemoNet (Xu et al. 2022), EigenTrajectory
(Bae, Oh, and Jeon 2023), and MoFlow (Fu et al. 2025).
To ensure robustness, all reported results for T RAJ E VO are
averaged over 10 independent evolutionary runs. The standard deviations across runs were consistently low, typically
ranging from 0.02 to 0.06.

**Hardware and Software** All experiments were conducted
on a workstation equipped with an AMD Ryzen 9 7950X 16Core Processor and a single NVIDIA RTX 3090 GPU. The
T RAJ E VO framework generates trajectory prediction heuristics as executable Python code snippets in a Python 3.12


Observed Ground-truth CVM-S TrajEvo

Figure 5: Trajectory prediction results for CVM-S (Sch¨oller
et al. 2020) and T RAJ E VO across different datasets. Each
row illustrates a distinct pattern: (top) linear trajectories,
(middle) non-linear trajectories, and (bottom) collisionavoidance cases. We visualize the single best trajectory out
of *K* = 20 samples based on the optimization objective.

environment, employing Google’s Gemini 2.0 Flash model
(Google AI for Developers 2025) in the main experiment. To
evaluate the stability and generalizability of our framework,
its performance was systematically tested with a variety of
alternative models, including DeepSeek V3 & R1, Qwen332B, ChatGPT-4o, and Claude 3.7 Sonnet.
#### **In-Distribution Performance**

**Comparison with Heuristic Methods** We report results
against heuristic baselines in Table 1. T RAJ E VO consistently
achieves the best performance across all ETH-UCY datasets
and significantly outperforms all competitors on average.
This establishes T RAJ E VO as the new state-of-the-art among
heuristic approaches on this benchmark. Interestingly, the
general performance trend across baseline methods suggests
that heuristics incorporating more complexity beyond basic
constant velocity assumptions are generally worse suited for
real-world pedestrian data, including SocialForce, with the
second-best result obtained by the relatively simple CVMS. Fig. 5 shows examples of the generated trajectories.

**Comparison with Deep Learning Methods** Table 2 reports results against deep learning methods. On this indistribution benchmark, while T RAJ E VO does not surpass
highly specialized neural networks like MoFlow (Fu et al.
2025), it establishes a strong baseline. It consistently outperforms several established models, including Social-LSTM
(Alahi et al. 2016), and even more recent ones like Trajectron++ (Salzmann et al. 2020) on certain datasets. This
performance is highly competitive for a heuristic-based approach. However, as the next section demonstrates, the primary strength of our method lies not in incremental indistribution gains, but in its superior generalization capabil

-----

Table 1: Comparison of T RAJ E VO with trajectory prediction heuristics across datasets with mean minADE 20 / minFDE 20
(meters) on the ETH-UCY dataset.

|Social-LSTM (Alahi et al. 2016) Social-GAN (Gupta et al. 2018) STGAT (Huang et al. 2019) Social-STGCNN (Mohamed et al. 2020) Trajectron++ (Salzmann et al. 2020) MemoNet (Xu et al. 2022) EigenTrajectory (Bae, Oh, and Jeon 2023) MoFlow (Fu et al. 2025)|1.09/2.35 0.87/1.62 0.65/1.12 0.64/1.11 0.61/1.03 0.41/0.61 0.36/0.53 0.40/0.57|0.79/1.76 0.67/1.37 0.35/0.66 0.49/0.85 0.20/0.28 0.11/0.17 0.12/0.19 0.11/0.17|0.67/1.40 0.76/1.52 0.52/1.10 0.44/0.79 0.30/0.55 0.24/0.43 0.24/0.43 0.23/0.39|0.56/1.17 0.35/0.68 0.34/0.69 0.34/0.53 0.24/0.41 0.18/0.32 0.19/0.33 0.15/0.26|0.72/1.54 0.42/0.84 0.29/0.60 0.30/0.48 0.18/0.32 0.14/0.24 0.14/0.24 0.12/0.22|0.77/1.64|
|---|---|---|---|---|---|---|
|||||||0.61/1.21|
|||||||0.43/0.83|
|||||||0.44/0.75|
|||||||0.31/0.52 0.21/0.35 0.21/0.34 0.20/0.32|



Table 2: Comparison of T RAJ E VO with deep learning approaches (mean minADE 20 /minFDE 20 on ETH-UCY). Each
underlined number indicates that the result is worse than the corresponding result from T RAJ E VO on at least one metric.


ities in OOD situations.
#### **Out-of-Distribution Performance**

A crucial capability for robotic systems deployed in the real
world is generalizing to unseen (OOD) environments during development. We evaluate this on the unseen dataset
SDD, directly testing both deep learning models (trained on
ETH-UCY) and the heuristics from T RAJ E VO (evolved on
the ETH-UCY). We report these OOD performance results
in Table 3 for three selected heuristics and three recent established neural methods. Remarkably, T RAJ E VO demonstrates superior generalization, significantly outperforming
not only all heuristic baselines but also all tested deep learning methods, including SOTA models like MoFlow (Fu et al.
2025). T RAJ E VO performs substantially better than the best
deep learning competitor, EigenTrajectory (Bae, Oh, and
Jeon 2023) and MoFlow. This suggests that the interpretable
and efficient heuristics discovered by T RAJ E VO may possess greater robustness to domain shifts compared to complex neural networks trained on specific distributions. For a
bidirectional validation of generalization ability, we provide
the reverse experiment in the Appendix.
#### **Ablation Study**

We conducted an ablation study, reported in Table 4, to validate the effectiveness of the core components introduced
in T RAJ E VO . The results demonstrate that both the SFL and
CGES meaningfully improve performance. Removing either
component from the full framework leads to a noticeable
degradation in prediction accuracy, confirming their positive


contribution. The significant impact of CGES on enhancing
the quality of generated heuristics during evolution is further
visualized in Appendix Fig. 10.
#### **Analysis and Discussion**

**Performance of Different LLMs** To demonstrate the robustness of the T RAJ E VO framework and the stability of its
outcomes, we evaluated its performance when driven by several state-of-the-art LLMs, including DeepSeek-V3 & R1,
Qwen3-32B, ChatGPT-4o, and Claude 3.7 Sonnet. As detailed in Table 5, a key finding is the consistent effectiveness across all models. Each LLM was capable of generating high-performing heuristics, which underscores the general utility and stability of T RAJ E VO . While the overall performance level remained high and stable, we did observe
minor variations that highlight opportunities for fine-tuning.
For instance, Deepseek-R1 achieved the best average results,
while other models excelled on specific datasets. This analysis confirms that the T RAJ E VO framework is effective and
not reliant on a single specific LLM, ensuring stable, highquality outcomes regardless of the chosen model.

**Evolution Resources** A single T RAJ E VO evolutionary
run takes approximately 5 minutes using Google’s Gemini
2.0 Flash (Google AI for Developers 2025) with an average API cost of $0.05. In contrast, training neural methods
can take a full day on a contemporary GPU, incurring significantly higher estimated compute costs – e.g., on an RTX
3090 as reported by Bae, Oh, and Jeon (2023), around $4
based on typical rental rates, 80 *×* more than T RAJ E VO .


-----

Method (tested on SDD dataset) ETH HOTEL UNIV ZARA1 ZARA2 AVG

SocialForce (Helbing and Molnar 1995) 33.64/60.63 33.64/60.63 33.64/60.63 33.64/60.63 33.64/60.63 33.64/60.63
CVM (Sch¨oller et al. 2020) 18.82/37.95 18.82/37.95 18.82/37.95 18.82/37.95 18.82/37.95 18.82/37.95
CVM-S (Sch¨oller et al. 2020) 16.28/31.84 16.28/31.84 16.28/31.84 16.28/31.84 16.28/31.84 16.28/31.84

Trajectron++ (Salzmann et al. 2020) 46.72/69.11 47.30/67.76 46.08/75.90 47.30/72.19 46.78/68.59 46.84/70.71
EigenTrajectory (Bae, Oh, and Jeon 2023) 14.51/25.13 14.69/24.64 14.31/27.60 14.69/26.25 14.53/24.94 14.55/25.71
MoFlow (Fu et al. 2025) 17.00/27.98 17.21/27.43 17.00/30.63 17.24/29.22 17.27/27.56 17.14/28.56

T RAJ E VO **12.58** / **23.82 12.26** / **23.60 12.78** / **23.71 13.10** / **25.23 12.22** / **23.57 12.59** / **23.99**

Table 3: Out of distribution performance of methods trained on different ETH-UCY splits and tested on the unseen SDD dataset.
We report minADE 20 / minFDE 20 (pixels) on the SDD dataset.


Dataset    - SFL - CGES    - SFL T RAJ E VO

ETH 0.68/1.36 0.59/1.12 **0.47/0.77**

HOTEL 0.26/0.45 0.19/0.33 **0.17/0.30**

UNIV 0.59/1.22 0.52/1.13 **0.51/1.10**

ZARA1 0.37/0.77 0.36/0.76 **0.35/0.75**

ZARA2 0.31/0.65 0.28/0.59 **0.27/0.57**

Table 4: Ablation study for the evolution framework removing different components. Lower is better ( *↓* ).

**Model** **ETH** **HOTEL** **UNIV**

ADE FDE ADE FDE ADE FDE

deepseek-R1 0.46 0.74 0.16 **0.29** **0.49** **1.06**
deepseek-V3 **0.43** **0.71** 0.21 0.39 0.50 1.08
Qwen3-32B 0.49 0.74 0.18 0.32 0.51 1.09
ChatGPT-4o 0.51 0.82 **0.15** 0.30 0.54 1.13

Claude-3.7 0.49 0.93 0.18 0.36 **0.49** 1.07

**Model** **ZARA1** **ZARA2** **AVG**

ADE FDE ADE FDE ADE FDE

deepseek-R1 0.33 0.72 **0.26** **0.54** **0.34** **0.67**
deepseek-V3 0.34 **0.69** 0.27 0.56 0.35 0.69
Qwen3-32B 0.35 0.75 0.27 0.59 0.36 0.70
GPT-4o 0.36 0.72 0.31 **0.54** 0.37 0.70

Claude-3.7 **0.32** **0.61** 0.27 0.57 0.35 0.71

Table 5: Performance of various LLMs on the standard ETH
UCY benchmark datasets. Best results are in bold.

**Inference Resources** Crucially, the LLM is only used during the offline evolutionary design phase and is not called
at inference time. The resulting heuristics are lightweight
Python functions. As such, T RAJ E VO -generated heuristics
demonstrate significant speed advantages, requiring only
0.65ms per instance on a single CPU core with the Python
version and less than 5 *µ* s for a version of the heuristic rewritten in C++. In contrast, neural baselines need 12-29ms on
GPU and 248-375ms on (multi-core) CPU. Notably, T RA J E VO achieves over 10 *×* speedup for the original Python
version and more than 2400 *×* speedup for the C++ version
compared to the optimized MoFlow running on a dedicated
GPU, highlighting its relevance for resource-constrained,
real-time robotic systems.


**Explainability** Unlike the black-box nature of neural networks, T RAJ E VO produces human-readable Python code.
For instance, the heuristic evolved for the Zara1 dataset (see
Supplementary Material for the full code) is not a simple
tweak of a known model. It intelligently combines four distinct strategies to generate its 20 samples. The primary strategy ( *k* = 0 *..* 9) is a sophisticated form of adaptive linear
extrapolation, where the velocity vector is averaged over the
last few steps and perturbed by noise scaled to the agent’s
current speed—allowing it to model both smooth paths and
sudden hesitations. A second strategy ( *k* = 10 *..* 14) introduces rotational noise, effectively simulating curved paths.
A third ( *k* = 15 *..* 17) implements a memory-based collision
avoidance mechanism by checking potential future positions
against the recent paths of nearby agents. The final strategy
( *k* = 18 *,* 19) acts as a conservative fallback, using a heavily
damped extrapolation. This automated discovery of a complex, multi-faceted strategy combining adaptive kinematics
and interaction rules is a key advantage, making the model’s
logic transparent and verifiable, which is crucial for safetycritical applications.
### **Conclusion**

We introduced T RAJ E VO, a novel framework leveraging
Large Language Models and evolutionary algorithms to automate the design of trajectory prediction heuristics. Our experiments demonstrate that T RAJ E VO generates heuristics
which not only outperform traditional methods on standard
benchmarks but also exhibit superior out-of-distribution
generalization performance, remarkably surpassing even
deep learning models on unseen data while remaining fast
and interpretable. We believe T RAJ E VO represents a significant first step towards automatically discovering efficient,
explainable, and generalizable trajectory prediction heuristics, offering a practical and powerful alternative to conventional black-box models.
Future research will focus on bridging the performance
gap to state-of-the-art models by enhancing the sophistication of the evolutionary search and incorporating multimodal contextual inputs. To ensure greater real-world applicability, the optimization objective will be reframed from
single metrics of predictive accuracy towards holistic performance on downstream tasks like navigation and planning.


-----

### **References**

Alahi, A.; Goel, K.; Ramanathan, V.; Robicquet, A.; FeiFei, L.; and Savarese, S. 2016. Social lstm: Human trajectory prediction in crowded spaces. In *Proceedings of the*
*IEEE conference on computer vision and pattern recogni-*
*tion*, 961–971.

Amirian, J.; Zhang, B.; Castro, F. V.; Baldelomar, J. J.;
Hayet, J.-B.; and Pettr´e, J. 2020. Opentraj: Assessing prediction complexity in human trajectories datasets. In *Pro-*
*ceedings of the asian conference on computer vision* .

Bae, I.; Lee, J.; and Jeon, H.-G. 2024. Can language beat numerical regression? language-based multimodal trajectory
prediction. In *Proceedings of the IEEE/CVF Conference on*
*Computer Vision and Pattern Recognition*, 753–766.

Bae, I.; Oh, J.; and Jeon, H.-G. 2023. Eigentrajectory: Lowrank descriptors for multi-modal trajectory forecasting. In
*Proceedings of the IEEE/CVF International Conference on*
*Computer Vision*, 10017–10029.

Bishop, C. M.; and Nasrabadi, N. M. 2006. *Pattern recogni-*
*tion and machine learning*, volume 4. Springer.

Cai, Y.; and Ren, Z. 2024. PWTO: A Heuristic Approach
for Trajectory Optimization in Complex Terrains. *arXiv*
*preprint arXiv:2407.02745* .

Cao, D.; Li, J.; Ma, H.; and Tomizuka, M. 2021. Spectral
temporal graph neural network for trajectory prediction. In
*2021 IEEE International Conference on Robotics and Au-*
*tomation (ICRA)*, 1839–1845. IEEE.

Chen, X.; Treiber, M.; Kanagaraj, V.; and Li, H. 2018. Social
force models for pedestrian traffic–state of the art. *Transport*
*reviews*, 38(5): 625–653.

Chen, Z.; Zhou, Z.; Lu, Y.; Xu, R.; Pan, L.; and Lan, Z. 2024.
UBER: Uncertainty-Based Evolution with Large Language
Models for Automatic Heuristic Design. *arXiv preprint*
*arXiv:2412.20694* .

Choi, C.; Choi, J. H.; Li, J.; and Malla, S. 2021. Shared
cross-modal trajectory prediction for autonomous driving.
In *Proceedings of the IEEE/CVF Conference on Computer*
*Vision and Pattern Recognition*, 244–253.

Dat, P. V. T.; Doan, L.; and Binh, H. T. T. 2025. Hsevo:
Elevating automatic heuristic design with diversity-driven
harmony search and genetic algorithm using llms. In *Pro-*
*ceedings of the AAAI Conference on Artificial Intelligence*,
volume 39, 26931–26938.

Dax, V. M.; Li, J.; Sachdeva, E.; Agarwal, N.; and Kochenderfer, M. J. 2023. Disentangled neural relational inference
for interpretable motion prediction. *IEEE Robotics and Au-*
*tomation Letters*, 9(2): 1452–1459.

Dendorfer, P.; Elflein, S.; and Leal-Taix´e, L. 2021. Mggan: A multi-generator model preventing out-of-distribution
samples in pedestrian trajectory prediction. In *Proceedings*
*of the IEEE/CVF International Conference on Computer Vi-*
*sion*, 13158–13167.

Farina, F.; Fontanelli, D.; Garulli, A.; Giannitrapani, A.; and
Prattichizzo, D. 2017. Walking ahead: The headed social
force model. *PloS one*, 12(1): e0169734.


Fu, Y.; Yan, Q.; Wang, L.; Li, K.; and Liao, R. 2025.
MoFlow: One-Step Flow Matching for Human Trajectory
Forecasting via Implicit Maximum Likelihood Estimation
based Distillation. In *Proceedings of the IEEE/CVF Confer-*
*ence on Computer Vision and Pattern Recognition (CVPR)* .
Google AI for Developers. 2025. Gemini API Pricing —
[Gemini API — Google AI for Developers. https://ai.google.](https://ai.google.dev/gemini-api/docs/pricing)
[dev/gemini-api/docs/pricing. Last updated: 2025-04-21, Ac-](https://ai.google.dev/gemini-api/docs/pricing)
cessed: 2025-05-01.

Gu, T.; Chen, G.; Li, J.; Lin, C.; Rao, Y.; Zhou, J.; and Lu, J.
2022. Stochastic trajectory prediction via motion indeterminacy diffusion. In *Proceedings of the IEEE/CVF conference*
*on computer vision and pattern recognition*, 17113–17122.
Gupta, A.; Johnson, J.; Fei-Fei, L.; Savarese, S.; and Alahi,
A. 2018. Social gan: Socially acceptable trajectories with
generative adversarial networks. In *Proceedings of the*
*IEEE conference on computer vision and pattern recogni-*
*tion*, 2255–2264.

Helbing, D.; Farkas, I.; and Vicsek, T. 1997. Modeling the
dynamics of human behavior in complex systems. *Physical*
*Review E*, 56(4): 4282.
Helbing, D.; and Molnar, P. 1995. Social force model for
pedestrian dynamics. *Physical review E*, 51(5): 4282.
Huang, Y.; Bi, H.; Li, Z.; Mao, T.; and Wang, Z. 2019.
STGAT: Modeling Spatial-Temporal Interactions for Human
Trajectory Prediction. In *Proceedings of the IEEE/CVF In-*
*ternational Conference on Computer Vision (ICCV)* .
Itkina, M.; and Kochenderfer, M. 2023. Interpretable selfaware neural networks for robust trajectory prediction. In
*Conference on Robot Learning*, 606–617. PMLR.
Jiang, J.; Yan, K.; Xia, X.; and Yang, B. 2025. A Survey
of Deep Learning-Based Pedestrian Trajectory Prediction:
Challenges and Solutions. *Sensors (Basel, Switzerland)*,
25(3): 957.
Kim, S.; Baek, J.; Kim, J.; and Lee, J. 2025. GUIDECoT: Goal-driven and User-Informed Dynamic Estimation
for Pedestrian Trajectory using Chain-of-Thought. *arXiv*
*preprint arXiv:2503.06832* .
Korbmacher, R.; and Tordeux, A. 2022. Review of pedestrian trajectory prediction methods: Comparing deep learning and knowledge-based approaches. *IEEE Transac-*
*tions on Intelligent Transportation Systems*, 23(12): 24126–
24144.

Lange, B.; Itkina, M.; Li, J.; and Kochenderfer, M. J. 2024.
Self-supervised multi-future occupancy forecasting for autonomous driving. *arXiv preprint arXiv:2407.21126* .
Lange, B.; Li, J.; and Kochenderfer, M. J. 2024. Scene
informer: Anchor-based occlusion inference and trajectory
prediction in partially observable environments. In *2024*
*IEEE International Conference on Robotics and Automation*
*(ICRA)*, 14138–14145. IEEE.
Lerner, A.; Chrysanthou, Y.; and Lischinski, D. 2007.
Crowds by example. In *Computer graphics forum*, volume 26, 655–664. Wiley Online Library.
Li, J.; Hua, C.; Ma, H.; Park, J.; Dax, V.; and Kochenderfer,
M. J. 2024a. Multi-agent dynamic relational reasoning for
social robot navigation. *arXiv preprint arXiv:2401.12275* .


-----

Li, J.; Hua, C.; Park, J.; Ma, H.; Dax, V.; and Kochenderfer,
M. J. 2022a. Evolvehypergraph: Group-aware dynamic relational reasoning for trajectory prediction. *arXiv preprint*
*arXiv:2208.05470* .

Li, J.; Li, J.; Bae, S.; and Isele, D. 2024b. Adaptive prediction ensemble: Improving out-of-distribution generalization
of motion forecasting. *IEEE Robotics and Automation Let-*

*ters* .

Li, J.; Ma, H.; and Tomizuka, M. 2019. Conditional generative neural system for probabilistic trajectory prediction.
In *2019 IEEE/RSJ International Conference on Intelligent*
*Robots and Systems (IROS)*, 6150–6156. IEEE.

Li, J.; Ma, H.; Zhang, Z.; Li, J.; and Tomizuka, M. 2021.
Spatio-temporal graph dual-attention network for multiagent prediction and tracking. *IEEE Transactions on Intel-*
*ligent Transportation Systems*, 23(8): 10556–10569.

Li, J.; Shi, X.; Chen, F.; Stroud, J.; Zhang, Z.; Lan, T.; Mao,
J.; Kang, J.; Refaat, K. S.; Yang, W.; et al. 2023a. Pedestrian
Crossing Action Recognition and Trajectory Prediction with
3D Human Keypoints. In *2023 IEEE International Con-*
*ference on Robotics and Automation (ICRA)*, 1463–1470.
IEEE.

Li, J.; Yang, F.; Tomizuka, M.; and Choi, C. 2020. Evolvegraph: Multi-agent trajectory prediction with dynamic relational reasoning. *Advances in neural information processing*
*systems*, 33: 19783–19794.

Li, K.; Chen, Y.; Shan, M.; Li, J.; Worrall, S.; and Nebot,
E. 2023b. Game theory-based simultaneous prediction and
planning for autonomous vehicle navigation in crowded environments. In *2023 IEEE 26th International Conference*
*on Intelligent Transportation Systems (ITSC)*, 2977–2984.
IEEE.

Li, P.; Pei, X.; Chen, Z.; Zhou, X.; and Xu, J. 2022b. Humanlike motion planning of autonomous vehicle based on probabilistic trajectory prediction. *Applied Soft Computing*, 118:
108499.

Liu, F.; Tong, X.; Yuan, M.; Lin, X.; Luo, F.; Wang, Z.; Lu,
Z.; and Zhang, Q. 2024a. Evolution of heuristics: Towards
efficient automatic algorithm design using large language
model. *arXiv preprint arXiv:2401.02051* .

Liu, F.; Zhang, R.; Xie, Z.; Sun, R.; Li, K.; Lin, X.; Wang,
Z.; Lu, Z.; and Zhang, Q. 2024b. Llm4ad: A platform for
algorithm design with large language model. *arXiv preprint*
*arXiv:2412.17287* .

Liu, P.; Liu, H.; Li, Y.; Shi, T.; Zhu, M.; and Pu, Z.
2024c. Traj-Explainer: An Explainable and Robust Multimodal Trajectory Prediction Approach. *arXiv preprint*
*arXiv:2410.16795* .

Lu, T.; Watanabe, Y.; Yamada, S.; and Takada, H. 2021.
Comparative evaluation of Kalman filters and motion models in vehicular state estimation and path prediction. *Journal*
*of Navigation*, 74.

Luber, M.; Stork, J. A.; Tipaldi, G. D.; and Arras, K. O.
2010. People tracking with human motion predictions from
social forces. In *2010 IEEE International Conference on*
*Robotics and Automation*, 464–469.


Ma, H.; Li, J.; Hosseini, R.; Tomizuka, M.; and Choi, C.
2022. Multi-objective diverse human motion prediction with
knowledge distillation. In *Proceedings of the IEEE/CVF*
*Conference on Computer Vision and Pattern Recognition*,
8161–8171.

Ma, H.; Sun, Y.; Li, J.; and Tomizuka, M. 2021. Multiagent driving behavior prediction across different scenarios
with self-supervised domain knowledge. In *2021 IEEE In-*
*ternational Intelligent Transportation Systems Conference*
*(ITSC)*, 3122–3129. IEEE.

Ma, Y.; Manocha, D.; and Wang, W. 2018. Efficient Reciprocal Collision Avoidance between Heterogeneous Agents
Using CTMAT. In *AAMAS* .

Madjid, N. A.; Ahmad, A.; Mebrahtu, M.; Babaa, Y.; Nasser,
A.; Malik, S.; Hassan, B.; Werghi, N.; Dias, J.; and Khonji,
M. 2025. Trajectory Prediction for Autonomous Driving:
Progress, Limitations, and Future Directions. *arXiv preprint*
*arXiv:2503.03262* .

Mahdi, H.; Akgun, S. A.; Saleh, S.; and Dautenhahn, K.
2022. A survey on the design and evolution of social
robots—Past, present and future. *Robotics and Autonomous*
*Systems*, 156: 104193.

Mavrogiannis, C.; Baldini, F.; Wang, A.; Zhao, D.; Trautman, P.; Steinfeld, A.; and Oh, J. 2023. Core challenges
of social robot navigation: A survey. *ACM Transactions on*
*Human-Robot Interaction*, 12(3): 1–39.

Mohamed, A.; Qian, K.; Elhoseiny, M.; and Claudel, C.
2020. Social-stgcnn: A social spatio-temporal graph convolutional neural network for human trajectory prediction.
In *Proceedings of the IEEE/CVF conference on computer*
*vision and pattern recognition*, 14424–14432.

Nakamura, K.; Tian, R.; and Bajcsy, A. 2024. Not All Errors
Are Made Equal: A Regret Metric for Detecting Systemlevel Trajectory Prediction Failures. In *8th Annual Confer-*
*ence on Robot Learning* .

Novikov, A.; V˜u, N.; Eisenberger, M.; Dupont, E.; Huang,
P.-S.; Wagner, A. Z.; Shirobokov, S.; Kozlovskii, B.; Ruiz,
F. J.; Mehrabian, A.; et al. 2025. AlphaEvolve: A coding
agent for scientific and algorithmic discovery. *arXiv preprint*
*arXiv:2506.13131* .

Osuna, E. C.; and Sudholt, D. 2018. Runtime analysis of
probabilistic crowding and restricted tournament selection
for bimodal optimisation. In *Proceedings of the Genetic and*
*Evolutionary Computation Conference*, 929–936.

Pellegrini, S.; Ess, A.; Schindler, K.; and van Gool, L. 2009.
You’ll Never Walk Alone: Modeling Social Behavior for
Multi-target Tracking. In *2009 IEEE 12th International*
*Conference on Computer Vision (ICCV)*, 261–268.

Phong, T.; Wu, H.; Yu, C.; Cai, P.; Zheng, S.; and Hsu, D.
2023. What truly matters in trajectory prediction for autonomous driving? *Advances in Neural Information Pro-*
*cessing Systems*, 36: 71327–71339.

Polychronopoulos, A.; Tsogas, M.; Amditis, A. J.; and Andreone, L. 2007. Sensor fusion for predicting vehicles’ path
for collision avoidance systems. *IEEE Transactions on In-*
*telligent Transportation Systems*, 8(3): 549–562.


-----

Pryzant, R.; Iter, D.; Li, J.; Lee, Y. T.; Zhu, C.; and Zeng, M.
2023. Automatic prompt optimization with” gradient descent” and beam search. *arXiv preprint arXiv:2305.03495* .
Rainbow, B. A.; Men, Q.; and Shum, H. P. 2021. SemanticsSTGCNN: A semantics-guided spatial-temporal graph convolutional network for multi-class trajectory prediction. In
*2021 IEEE International Conference on Systems, Man, and*
*Cybernetics (SMC)*, 2959–2966. IEEE.
Robicquet, A.; Sadeghian, A.; Alahi, A.; and Savarese, S.
2016. Learning Social Etiquette: Human Trajectory Understanding in Crowded Scenes. In *European Conference on*
*Computer Vision (ECCV)*, 549–565. Springer International
Publishing.
Robla-G´omez, S.; Becerra, V. M.; Llata, J. R.; Gonz´alezSarabia, E.; Torre-Ferrero, C.; and P´erez-Oria, J. 2017.
Working Together: A Review on Safe Human-Robot Collaboration in Industrial Environments. *IEEE Access*, 5: 26754–
26773.

Rudenko, A.; Palmieri, L.; Herman, M.; Kitani, K. M.;
Gavrila, D. M.; and Arras, K. O. 2020. Human motion trajectory prediction: A survey. *The International Journal of*
*Robotics Research*, 39(8): 895–935.
Salzmann, T.; Ivanovic, B.; Chakravarty, P.; and Pavone, M.
2020. Trajectron++: Dynamically-feasible trajectory forecasting with heterogeneous data. In *Computer Vision–ECCV*
*2020: 16th European Conference, Glasgow, UK, August 23–*
*28, 2020, Proceedings, Part XVIII 16*, 683–700. Springer.
Sch¨oller, C.; Aravantinos, V.; Lay, F.; and Knoll, A. 2020.
What the constant velocity model can teach us about pedestrian motion prediction. *IEEE Robotics and Automation Let-*
*ters*, 5(2): 1696–1703.
Sun, F.-Y.; Kauvar, I.; Zhang, R.; Li, J.; Kochenderfer, M. J.;
Wu, J.; and Haber, N. 2022. Interaction modeling with multiplex attention. *Advances in Neural Information Processing*
*Systems*, 35: 20038–20050.
Toyungyernsub, M.; Yel, E.; Li, J.; and Kochenderfer, M. J.
2024. Predicting future spatiotemporal occupancy grids with
semantics for autonomous driving. In *2024 IEEE Intelligent*
*Vehicles Symposium (IV)*, 2855–2861. IEEE.
van den Berg, J.; Lin, M.; and Manocha, D. 2008. Reciprocal Velocity Obstacles for real-time multi-agent navigation.
In *2008 IEEE International Conference on Robotics and Au-*
*tomation*, 1928–1935.

Vishwakarma, L. P.; Singh, R. K.; Mishra, R.; Demirkol, D.;
and Daim, T. 2024. The adoption of social robots in service
operations: a comprehensive review. *Technology in Society*,
76: 102441.

Wang, L.; Lavoie, M.-A.; Papais, S.; Nisar, B.; Chen, Y.;
Ding, W.; Ivanovic, B.; Shao, H.; Abuduweili, A.; Cook, E.;
Zhou, Y.; Karkus, P.; Li, J.; Liu, C.; Pavone, M.; and Waslander, S. 2025a. Deployable and Generalizable Motion Prediction: Taxonomy, Open Challenges and Future Directions.
*arXiv preprint arXiv:2505.09074* .
Wang, S.; Chen, Z.; Zhao, Z.; Mao, C.; Zhou, Y.; He, J.; and
Hu, A. S. 2024a. EscIRL: Evolving Self-Contrastive IRL for
Trajectory Prediction in Autonomous Driving. In *8th Annual*
*Conference on Robot Learning* .


Wang, W.; Wang, C.; Yang, B.; Chen, G.; and Min, B.C. 2024b. Hyper-sttn: Social group-aware spatial-temporal
transformer network for human trajectory prediction with
hypergraph reasoning. *arXiv preprint arXiv:2401.06344* .

Wang, Y.; Huang, X.; Sun, X.; Yan, M.; Xing, S.; Tu, Z.; and
Li, J. 2025b. Uniocc: A unified benchmark for occupancy
forecasting and prediction in autonomous driving. *arXiv*
*preprint arXiv:2503.24381* .

Wang, Y.; Xing, S.; Can, C.; Li, R.; Hua, H.; Tian, K.; Mo,
Z.; Gao, X.; Wu, K.; Zhou, S.; You, H.; Peng, J.; Zhang,
J.; Wang, Z.; Song, R.; Yan, M.; Zimmer, W.; Zhou, X.; Li,
P.; Lu, Z.; Chen, C.-J.; Huang, Y.; Rossi, R. A.; Sun, L.;
Yu, H.; Fan, Z.; Yang, F. H.; Kang, Y.; Greer, R.; Liu, C.;
Lee, E. H.; Di, X.; Ye, X.; Ren, L.; Knoll, A.; Li, X.; Ji, S.;
Tomizuka, M.; Pavone, M.; Yang, T.; Du, J.; Yang, M.-H.;
Wei, H.; Wang, Z.; Zhou, Y.; Li, J.; and Tu, Z. 2025c. Generative ai for autonomous driving: Frontiers and opportunities.
*arXiv preprint arXiv:2505.08854* .

Wang, Z.; Wang, Y.; Wu, Z.; Ma, H.; Li, Z.; Qiu, H.; and Li,
J. 2025d. Cmp: Cooperative motion prediction with multiagent communication. *IEEE Robotics and Automation Let-*

*ters* .

Wu, X.; Wu, S.-h.; Wu, J.; Feng, L.; and Tan, K. C.
2024. Evolutionary computation in the era of large language
model: Survey and roadmap. *IEEE Transactions on Evolu-*
*tionary Computation* .

Xie, S.; Li, J.; and Wang, J. 2023. A cognition-inspired trajectory prediction method for vehicles in interactive scenarios. *IET Intelligent Transport Systems*, 17(8): 1544–1559.

Xu, C.; Mao, W.; Zhang, W.; and Chen, S. 2022. Remember intentions: Retrospective-memory-based trajectory prediction. In *Proceedings of the IEEE/CVF Conference on*
*Computer Vision and Pattern Recognition*, 6488–6497.

Xu, Z.; Zhou, R.; Yin, Y.; Gao, H.; Tomizuka, M.; and Li,
J. 2024. MATRIX: multi-agent trajectory generation with
diverse contexts. In *2024 IEEE International Conference on*
*Robotics and Automation (ICRA)*, 12650–12657. IEEE.

Yamaguchi, K.; Berg, A. C.; Ortiz, L. E.; and Berg, T. L.
2011. Who are you with and where are you going? In *CVPR*
*2011*, 1345–1352.

Yang, Y.; Zhu, P.; Qi, M.; and Ma, H. 2024. Uncovering the human motion pattern: Pattern Memory-based Diffusion Model for Trajectory Prediction. *arXiv preprint*
*arXiv:2401.02916* .

Yao, J.; Zhang, X.; Xia, Y.; Wang, Z.; Roy-Chowdhury,
A. K.; and Li, J. 2024. Sonic: Safe social navigation with
adaptive conformal inference and constrained reinforcement
learning. *arXiv preprint arXiv:2407.17460* .

Ye, H.; Wang, J.; Cao, Z.; Berto, F.; Hua, C.; Kim, H.; Park,
J.; and Song, G. 2024. ReEvo: Large Language Models as
Hyper-Heuristics with Reflective Evolution. In *Advances in*
*Neural Information Processing Systems* .

Yuksekgonul, M.; Bianchi, F.; Boen, J.; Liu, S.; Lu, P.;
Huang, Z.; Guestrin, C.; and Zou, J. 2025. Optimizing generative AI by backpropagating language model feedback.
*Nature*, 639(8055): 609–616.


-----

Zanlungo, F.; Ikeda, T.; and Kanda, T. 2011. Social force
model with explicit collision prediction. *Europhysics Let-*
*ters*, 93(6): 68005.

Zhai, G.; Meng, H.; and Wang, X. 2014. A Constant Speed
Changing Rate and Constant Turn Rate Model for Maneuvering Target Tracking. *Sensors*, 14(3): 5239–5253.
Zhang, R.; Liu, F.; Lin, X.; Wang, Z.; Lu, Z.; and Zhang, Q.
2024. Understanding the importance of evolutionary search
in automated heuristic design with large language models. In
*International Conference on Parallel Problem Solving from*
*Nature*, 185–202. Springer.
Zheng, Z.; Xie, Z.; Wang, Z.; and Hooi, B. 2025. Monte
carlo tree search for comprehensive exploration in llm-based
automatic heuristic design. *International Conference on*
*Learning Representations* .

Zhou, R.; Zhou, H.; Gao, H.; Tomizuka, M.; Li, J.; and
Xu, Z. 2022. Grouptron: Dynamic multi-scale graph convolutional networks for group-aware dense crowd trajectory
forecasting. In *2022 International Conference on Robotics*
*and Automation (ICRA)*, 805–811. IEEE.


-----

### **Supplementary Materials** **Qualitative Example of the Evolutionary Process**

The evolutionary process of T RAJ E VO is qualitatively illustrated in Figure 6. The optimization begins with a simple **Seed**
**Heuristic**, which has a relatively high initial objective value (lower is better). Guided by the LLM, T RAJ E VO then explores the
solution space by generating and testing diverse new heuristics.
As shown in the figure, this exploration phase involves testing various distinct strategies, such as adding noise to an acceleration model ( **Acceleration model with Noise** ), simulating social forces ( **Constant Velocity with Repulsion** ), or averaging
velocity over time ( **Weighted Average Velocity** ). Through mechanisms like the Statistics Feedback Loop and Cross-Generation
Elite Sampling, the system identifies and refines the most effective of these strategies.
The process ultimately converges on a highly optimized **Final Heuristic** . This final algorithm is not a single, simple model
but a complex combination of the most successful traits discovered during evolution, such as a drift towards the mean position
and other agent-specific adjustments. This demonstrates the ability of T RAJ E VO to automate the design of a sophisticated,
high-performance heuristic from a basic starting point.




|Seed Heuristic Acceleration model with Noise current_velocity += acceleration + np.random.normal(0, noise_level) Simple Random Walk current_pos += np.random.normal(0, noise_level) Constant Velocity with Repulsion repulsion_force += direction * repulsion_strength / (distance *" 2 + epsilon) Acceleration with Clipping current_velocity *= np.minimum(1.0, max_speed / speed) Final Heuristic Weighted Average Velocity velocity = weight1 * velocity1 + ..$ + weight 3 * velocity3 Drift Towards the Mean Position drift_force = 0.001 * (mean_position - current_pos) Agent-specific Adjustments velocity = if near_origin: velocity = 0.0 elif random_chance: add_small_random_deviation()|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|
|---|---|---|---|---|---|---|---|---|
||||||||||


0 10 20 30 40 50 60 70 80

Number of Function Evaluations

Figure 6: A qualitative illustration of the T RAJ E VO evolutionary process. The optimization begins with a simple seed heuristic
and iteratively discovers more complex and effective strategies by exploring different concepts like acceleration with noise,
social repulsion, and weighted velocity averaging. The process converges on a final, highly-optimized heuristic that combines
multiple discovered strategies, achieving a significantly lower objective value.
### **Experimental Details**
#### **Hyperparameters**

The T RAJ E VO framework employs several hyperparameters that govern the evolutionary search process and the interaction
with Large Language Models. Key parameters used in our experiments are detailed in Table 6.
These include settings for population management within the evolutionary algorithm, the genetic operators, LLM-driven
heuristic generation and reflection mechanisms, as well as task-specific constants for trajectory prediction evaluation. Many of


-----

these settings were determined based on common practices in evolutionary computation, adaptations from the ReEvo framework
(Ye et al. 2024), or empirically tuned for the trajectory prediction task.

Table 6: Main hyperparameters for the TRAJEVO framework.

**Hyperparameter** **Value**

**Evolutionary Algorithm**
Population size 10
Number of initial generation 8
Elite ratio for crossover 0.3

Crossover rate 1

Mutation rate 0.5
CGES Softmax temperature 1.0

**Large Language Model (LLM)**
LLM model Gemini 2.0 Flash
LLM temperature (generator & reflector) 1
Max words for short-term reflection 200 words
Max words for long-term reflection 20 words

**Trajectory Prediction**
Num. prediction samples ( *K* ) 20
Observation length ( *T* obs ) 8 frames (3.2s)
Prediction length ( *T* pred ) 12 frames (4.8s)
#### **Analysis of Exploration Ratio**

In our evolutionary framework, the selection of parents for crossover is governed by an exploration-exploitation trade-off. A
portion of parents is chosen uniformly at random from all successful candidates (exploration), while the remainder is selected
from the top-performing elite heuristics (exploitation). To determine the optimal balance for this process, we conducted a
sensitivity analysis by varying the exploration ratio from 0.0 (pure exploitation) to 1.0 (pure exploration).
The results of this analysis are presented in Figure 7. The plot shows the final Mean Squared Error (MSE) score as a
function of the exploration ratio. We observed that performance generally improves as the exploration ratio increases from
0.0, reaching its peak at a ratio of 0.7. Beyond this point, further increasing the exploration led to a slight degradation in the
mean performance. While a higher exploration ratio could occasionally yield a superior result in a specific run due to greater
randomness, it also introduced significant performance instability, as indicated by the larger standard deviation. Therefore, an
exploration ratio of 0.7 was identified as the optimal setting, offering the best balance between high performance and reliable
outcomes. This value was used for all experiments conducted in this paper.
#### **Detailed Resources**

**Evolution and Inference Resources** We conducted a comprehensive analysis of the computational resources required by
T RAJ E VO and other baseline methods, covering both the one-time evolution cost and the per-instance inference cost. The
results, detailed in Fig. 8 and Fig. 9, show that T RAJ E VO is exceptionally efficient in both regards.
A single evolution run of T RAJ E VO takes approximately 5 minutes and costs about $0.05. In contrast, a state-of-the-art
(SOTA) neural method requires a full day of training, costing around $4.00. This efficiency is highlighted in Fig. 8. For realtime robotics applications, inference speed is critical. As shown in Fig. 9, T RAJ E VO -generated heuristics require only 0.65ms
on a single CPU core, while neural baselines are significantly slower, even on a GPU.
#### **Visualizing the Impact of CGES**

To complement the quantitative results presented in the main paper’s ablation study (Table 4), we provide a visual illustration
of the impact of Cross-Generation Elite Sampling (CGES) on the evolutionary process. Figure 9 plots the convergence of the
objective value during the evolutionary search, comparing the full T RAJ E VO framework against an ablated version without
CGES.

As the figure demonstrates, the inclusion of CGES allows the framework to escape local optima more effectively. The full
T RAJ E VO framework (represented by the red line) consistently achieves a lower (better) objective value compared to the version
without CGES (blue line). This visually confirms the data in Table 4 and underscores the importance of CGES for enhancing
the quality and performance of the heuristics generated during evolution. The shaded areas represent the standard deviation
across multiple runs, showing the consistency of this performance improvement.


-----

0.26


Algorithm Performance vs. Exploration Ratio


0.24

0.22

0.20

0.18

0.16

|Col1|Col2|Col3|Col4|Bes|t Point (ratio=0.7)|Col7|Col8|
|---|---|---|---|---|---|---|---|
|||||Me|an Performance (wi|th Std. D|ev.)|
|||||||||
|||||||||
|||||||||
|||||||||
|||||||||



0.0 0.1 0.3 0.5 0.7 0.9 1.0

Exploration Ratio

Figure 7: Performance sensitivity to the exploration ratio for crossover parent selection. The x-axis represents the proportion
of parents selected uniformly at random (exploration), while the y-axis shows the resulting MSE score (lower is better). The
optimal performance is achieved at an exploration ratio of 0.7, effectively balancing exploration and exploitation.
### **Limitations**

While T RAJ E VO introduces a promising paradigm for heuristic design in trajectory prediction, achieving a compelling balance
of performance, efficiency, interpretability, and notably strong generalization (Table 3), we identify several limitations that also
serve as important directions for future research:

**In-Distribution Accuracy** Although T RAJ E VO significantly advances the state-of-the-art for heuristic methods and surpasses
several deep learning baselines, the generated heuristics do not consistently achieve the absolute lowest error metrics on standard benchmarks compared to the most recent, highly specialized deep learning models when evaluated strictly *in-distribution* .
This likely reflects the inherent complexity trade-off; heuristics evolved for interpretability and speed may have a different
expressivity limit compared to large neural networks. Future work could investigate techniques to further close this gap, potentially through more advanced evolutionary operators and heuristics integration into parts of simulation frameworks while
preserving the core benefits.

**Input Data Complexity** Our current evaluations focus on standard trajectory datasets using primarily positional history.
Real-world robotic systems often have access to richer sensor data from which several features can be extracted, including
agent types (pedestrians, vehicles), semantic maps (lanes, intersections), and perception outputs (detected obstacles, drivable
space) – for instance, given obstacle positions, we would expect T RAJ E VO to discover more likely trajectories that tend to
avoid obstacles. T RAJ E VO currently does not leverage this complexity. Extending the framework to incorporate and reason
about such inputs would represent a significant next step. This could enable the automatic discovery of heuristics that are more
deeply context-aware and reactive to complex environmental factors.

**Downstream Task Performance** We evaluate T RAJ E VO based on standard trajectory prediction metrics (minADE/minFDE).
While these metrics often correlate to downstream task performance (Phong et al. 2023), these may not always perfectly correlate with performance on downstream robotic tasks like navigation or planning. Further developing our framework to optimize
heuristics directly for task-specific objectives within a closed loop (e.g., minimizing collisions or travel time in simulation)
represents an interesting avenue for future works that could lead to more practically effective trajectory prediction.


-----

### Evolution Resources Comparison


3
10

2
10

1
10


Evolution Time



Estimated Evolution Cost


scale.


2
10

1
10

0
10



|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|Col16|Col17|Col18|Col19|Col20|Col21|Col22|Col23|Col24|Col25|Col26|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|||||||||||||||||||||||||||
|||||||||||||||||||||||||||
|||||||||||||||||||||||||||
|||||||||||||||||||||||||||
||||||||||||||||$0.||||05|||||||
|5||||||||||||||||||||||||||
|||||||||||||||||||||||||||
|||TrajEvo Resources Com lution time and c Inf||||pari ost ( ere||SOTA NN Method son. Compared e.g., 5 minutes vs nce Resour||||||||TrajEvo ral network met vs. 4.00). Both m parison|||||hods etri||||ws n|
||||||||||||||||||||||||Platform CP GP||U U|
|||||||||||||||||||||||||||
|||||||||||||||||||||||||||
|||||||||||||||||||||||||||
|||||||||||||||||||||||||||
|||||||||||||||||||||||||||
|||||||||||||||||||||||||||
|||||||||||||||||||||||||||
|||||||||||||||||||||||||||
|||||||||||||||||||||||||||
|||Single||Single|Core|||||||||||||||||||||
|||||||||||||||||||||||||||


TrajEvo MoFlow EigenTrajectory Trajectron++
Model

Figure 9: **Inference Resources Comparison.** T RAJ E VO achieves a fast 0.65ms inference time on a single CPU core, while
baseline methods require more time even on a GPU. All times are displayed on a logarithmic scale.


-----

0 *.* 70



0 *.* 65

0 *.* 60

0 *.* 55

|Col1|Col2|Col3|Col4|Col5|o CGES|Col7|
|---|---|---|---|---|---|---|
||||Tr|ajEvo w/|o CGES||
||||Tr|ajEvo|||
||||||||
||||||||
||||||||
||||||||
||||||||



0 10 20 30 40 50

Number of Function Evaluations

Figure 10: Visual comparison of the evolutionary process with and without CGES. The plot shows the objective value (lower is
better) over the number of function evaluations, averaged over multiple runs. The T RAJ E VO framework with CGES consistently
converges to better solutions than the ablated version, highlighting the effectiveness of CGES in improving the search process.
### **Prompts**
#### **Common prompts**

The prompt formats are given below for the main evolutionary framework of T RAJ E VO . These are based on ReEvo (Ye et al.
2024), but with modified prompts tailored specifically for the task of trajectory prediction heuristic design and to incorporate
the unique mechanisms of T RAJ E VO .

Prompt 1: System prompt for generator LLM.

Prompt 2: System prompt for reflector LLM.

Prompt 3: Task description.




Prompt 4: User prompt for population initialization.




-----

Prompt 5: User prompt for crossover.

**Integration of Statistics Feedback Loop** The prompts for reflection and mutation are designed to leverage T RAJ E VO ’s
Statistics Feedback Loop.
Specifically, the short-term reflection prompt (Listing 6) and the elitist mutation prompt (Listing 8) explicitly require the LLM
to consider ”trajectory statistics” or ”Code Results Analysis” when generating reflections or new heuristic code. This allows
the LLM to make data-driven decisions based on the empirical performance of different heuristic strategies.






Prompt 6: User prompt for short-term reflection.



Prompt 7: User prompt for long-term reflection.



-----

Prompt 8: User prompt for elitist mutation.
#### **Trajectory Prediction-specific Prompts**

**Domain Specialization** All prompts are contextualized for the domain of trajectory prediction heuristics. For example, the
system prompts are deeply contextualized through specific prompts detailing the trajectory prediction problem:

Prompt 9: Function Signature

Prompt 10: Function Description



Prompt 11: Seed Function



-----

Prompt 12: External Knowledge
### **T RAJ E VO Output**
#### **Generated Heuristics**

2

5

8

15

18

29

33

38

42


-----

69

70

76

82

87

90

96

107

109

114


-----

119

132

137

139

144

147

154

156

Heuristic 13: The best T RAJ E VO -generated heuristic for Zara 1.
#### **Reflections**




-----

Output 14: Long-term reasoning output

Listing 14 shows an example of long-term reasoning output for the model, based on the comparative analysis. T RAJ E VO
discovers several interesting heuristics for trajectory forecasting, such as applying diverse noise factors, social force models,
diversity, and modeling intentions to model possible future trajectories.
Listing 15 shows some more outputs of T RAJ E VO from various runs, which discovers some interesting helper functions that
model interactions such as stochastic, social force, and diversity.

45

58

59

63

69

79

80

84

Output 15: Selected T RAJ E VO Interactions


-----


