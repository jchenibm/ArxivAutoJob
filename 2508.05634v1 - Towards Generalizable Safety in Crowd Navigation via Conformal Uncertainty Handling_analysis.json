{
  "title": "Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling",
  "detailed_summary": "This paper tackles the challenge of performance degradation in reinforcement learning-based crowd navigation robots when faced with out-of-distribution scenarios. The core idea is to improve the robot's ability to generalize by explicitly accounting for uncertainties in pedestrian behavior predictions. The proposed method leverages adaptive conformal inference (ACI) to quantify prediction uncertainty, generating prediction sets that contain the true future positions with a specified probability. These uncertainty estimates are then integrated into a constrained reinforcement learning (CRL) framework to guide the agent's behavior and ensure robustness to distribution shifts. Experiments demonstrate that the system achieves state-of-the-art performance in in-distribution settings and exhibits significantly improved robustness in out-of-distribution scenarios involving velocity variations, policy changes, and group dynamics. The method is also validated on a real robot, showcasing its effectiveness in safe and robust navigation among both sparse and dense crowds.",
  "background": "Mobile robots are expected to safely navigate in crowded environments, which is crucial for robots working closely with humans. Reinforcement learning (RL) offers a promising approach, but RL-based navigation agents often suffer from performance degradation in out-of-distribution (OOD) scenarios, indicating overfitting and poor generalization. Existing methods that incorporate human trajectory predictions into robot observations can exacerbate this issue, as real-world human dynamics are complex and difficult to fully capture. Existing methods lack a systematic way to handle prediction errors to improve policy generalizability.",
  "contributions": [
    "Proposes a novel learning-based framework that explicitly reasons about prediction uncertainty in RL-based crowd navigation to improve generalizability.",
    "Applies adaptive conformal inference (ACI) to quantify the uncertainty of predicted human trajectories, providing a prediction set that contains the true future position with a user-defined coverage probability.",
    "Employs constrained reinforcement learning (CRL) to introduce effective controllability into the decision-making system, using uncertainty estimates to guide both the learning process and the agent's behavior.",
    "Achieves state-of-the-art performance in safety metrics and demonstrates much smaller performance drops in OOD settings compared to existing methods.",
    "Demonstrates successful deployment of the learned policy on a real Mecanum-wheel robot, showcasing safe and robust navigation in both sparse and dense crowds."
  ],
  "problem": "The paper addresses the problem of poor generalization in RL-based crowd navigation robots when deployed in out-of-distribution scenarios. Specifically, it aims to mitigate the negative impact of inaccurate human trajectory predictions on robot decision-making, which often leads to collisions and unsafe navigation behaviors. This problem arises from the difficulty in capturing the full complexity of real-world human dynamics in simulation environments or datasets, causing RL agents to overfit to specific training conditions.",
  "methods": [
    "**Adaptive Conformal Inference (ACI):** Used to quantify the uncertainty of predicted human trajectories. ACI dynamically adjusts its parameters to maintain coverage in an online and distribution-free manner, making it suitable for time-sequential applications.",
    "**Constrained Reinforcement Learning (CRL):** Employed to guide the agent's behavior using uncertainty estimates. CRL incorporates constraints on the agent's actions to ensure safety, maximizing rewards while satisfying cost constraints.",
    "**Policy Network with Attention Mechanism:** A policy network with a combined human-human (H-H) and human-robot (H-R) attention mechanism is used to process uncertainty information along with other features. This allows the RL agents to account for prediction uncertainty in their decision-making process.",
    "**PPO Lagrangian:** The PPO Lagrangian method is used for optimization. Two critics are used to compute the state value for reward and the state value for cost."
  ],
  "experimental_design": {
    "environment": "CrowdNav, a widely adopted simulation environment for crowd navigation. The environment consists of 20 humans and one robot in a 12 m × 12 m area, with randomized initial positions and goal locations.",
    "baselines": "Optimal reciprocal collision avoidance (ORCA), social force (SF), model-predictive control (MPC), SafeCrowdNav, and CrowdNav++.",
    "evaluation_metrics": "Success rate (SR), collision rate (CR), timeout rate (TR), navigation time (NT), path length (PL), intrusion time ratio (ITR), and social distance (SD).",
    "OOD_scenarios": "Velocity shifts (20% of humans with max speed of 2.0 m/s), policy shifts (human behavior policy changed from ORCA to SF), and pedestrian grouping behavior."
  },
  "results": "In the in-distribution setting, the proposed approach achieves a 96.93% success rate, which is over 8.80% higher than the previous state-of-the-art baselines. It also results in over 3.72 times fewer collisions and 2.43 times fewer intrusions into ground-truth human future trajectories. In three out-of-distribution scenarios, the method demonstrates stronger robustness, maintaining a high success rate and low collision rate compared to competing approaches. Real-robot experiments show that the policy transfers directly from simulation and achieves safe navigation in both sparse and dense crowds.",
  "result_analysis": "The results demonstrate the effectiveness of incorporating uncertainty estimates into RL-based crowd navigation. ACI effectively quantifies prediction uncertainty, allowing the robot to adapt to different crowd dynamics and avoid collisions. CRL provides a mechanism for guiding the agent's behavior, ensuring that safety constraints are met. The real-robot experiments validate the practical applicability of the proposed approach.",
  "conclusions": "The paper presents an RL-based trajectory-planning framework that integrates conformal uncertainty into a CRL scheme to mitigate OOD performance degradation. By dynamically leveraging uncertainty estimates, the method adapts to velocity variations, policy changes, and transitions from individual to group dynamics. The method achieves robust stability across diverse OOD scenarios and practical effectiveness in real-world trials.",
  "limitations": [
    "The approach requires additional perception and mapping capabilities to naturally handle static obstacles of arbitrary shapes.",
    "The perception errors (e.g., human miss-detections and the 2D LiDAR’s sensitivity to lighting) can affect the system's performance.",
    "The strategy effectively *mitigates* OOD performance degradation but does not yet *eliminate* it.",
    "The space of possible distributional shifts is vast and cannot be exhaustively tested."
  ],
  "future_work": [
    "Integrate SLAM and feeding multi-modal observations into the policy network to handle static obstacles of arbitrary shape.",
    "Augment the sensor suite with cameras, apply sensor-fusion techniques, and upgrade to a higher-frequency, more robust LiDAR to mitigate perception errors.",
    "Adopting larger models (e.g., LLMs or VLMs) and advanced alignment methods to eliminate OOD performance degradation, although these may introduce increased computational demands.",
    "Conduct larger-scale real-world experiments once static-obstacle handling is resolved and employ metrics such as the intervention rate."
  ],
  "applications": "This research has potential applications in various domains where robots need to navigate safely and efficiently in crowded human environments, such as:",
  "related_work": "The paper discusses related work in crowd navigation, planning under uncertainty, and the use of RL in robotics. It mentions several important papers in these areas, including ORCA, Social Force, MPC, SafeCrowdNav, and CrowdNav++.",
  "github_links": [
    "https://gen-safe-nav.github.io/"
  ],
  "published": "2025-08-07T17:59:43+00:00"
}