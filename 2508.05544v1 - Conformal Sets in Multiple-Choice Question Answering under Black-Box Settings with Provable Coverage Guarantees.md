## **Conformal Sets in Multiple-Choice Question** **Answering under Black-Box Settings with Provable** **Coverage Guarantees**


**Guang Yang** *[∗]*
School of Electrical Engineering
University of Jinan
Jinan, Shandong 250024
```
guangyang.acad@gmail.com

```

**XinYangLiu**
School of Electrical Engineering
University of Jinan
Jinan, Shandong 250024
```
liuliuxinyang09@gmail.com

```
### **Abstract**

Large Language Models (LLMs) have shown remarkable progress in multiplechoice question answering (MCQA), but their inherent unreliability, such as hallucination and overconfidence, limits their application in high-risk domains. To
address this, we propose a frequency-based uncertainty quantification method
under black-box settings, leveraging conformal prediction (CP) to ensure provable
coverage guarantees. Our approach involves multiple independent samplings of
the model’s output distribution for each input, with the most frequent sample serving as a reference to calculate predictive entropy (PE). Experimental evaluations
across six LLMs and four datasets (MedMCQA, MedQA, MMLU, MMLU-Pro)
demonstrate that frequency-based PE outperforms logit-based PE in distinguishing
between correct and incorrect predictions, as measured by AUROC. Furthermore,
the method effectively controls the empirical miscoverage rate under user-specified
risk levels, validating that sampling frequency can serve as a viable substitute for
logit-based probabilities in black-box scenarios. This work provides a distributionfree model-agnostic framework for reliable uncertainty quantification in MCQA
with guaranteed coverage, enhancing the trustworthiness of LLMs in practical
applications.
### **1 Introduction**

LLMs have witnessed substantial progress in their evolutionary trajectory [ 9, 8, 13, 22 ], transforming
human-machine interaction [ 5, 6, 4, 16 ], yet their core flaw "hallucination" is prominent: generating
content that appears plausible but lacks a factual basis, such as factual errors like fictional events and
scientific conclusions, along with logical contradictions and overconfidence issues [ 7, 11, 12, 19 ]. This
unreliability severely restricts their application in high-risk fields such as healthcare and finance [ 14 ].

Conformal prediction (CP) [ 1, 2, 3 ], a classical frequentist statistical framework grounded in hypothesis testing and exchangeable data theory, aims to deliver reliable confidence intervals and uncertainty
quantification for machine learning predictions, relying on the "nonconformity score", quantifying
the deviation between predicted samples and calibration data to form prediction sets for new queries
through hypothesis testing. CP distinguishes itself from traditional uncertainty quantification methods
through distinctive features: providing distribution-free risk control by eschewing distributional
assumptions and offering nonasymptotic guarantees; ensuring user-specified coverage probability for
prediction sets containing the true value, outperforming point estimates; exhibiting model agnosticism

*∗* Use footnote for providing further information about author (webpage, alternative address)— *not* for
acknowledging funding agencies.

Preprint. Under review.


-----

by adapting any pre-trained model from point to interval predictions; and maintaining robustness
under model misspecification or distribution shifts [ 20 ]. Researchers have explored the application of
CP to MCQA tasks with notable results [ 21, 10 ]. With the proliferation of LLMs via API services,
their "black-box" nature necessitates quantifying output uncertainty [ 15 ]. For instance, ConU [ 17 ]
aligns nonconformity scores strictly with uncertainty conditions for acceptable answers, achieving
user-specified coverage guarantees of correctness.

In this study, to quantify the uncertainty of the general prediction of the model, we employed a
multiple sampling strategy. Specifically, for each input, we conducted repeated independent samplings
of the model’s output distribution, with the most frequent sample replacing the traditional maximumprobability (logit-based) point prediction as the reference. This modal-output-referenced uncertainty
quantification is intuitively valid: output variability from multiple samplings effectively mirrors the
model’s predictive confidence for specific inputs. The high concentration of samples around the
mode indicates low uncertainty, whereas a higher dispersion corresponds to a higher uncertainty.
To verify the effectiveness of the above idea, we designed and conducted a series of experiments
focusing on evaluating indicators such as Area Under the Receiver Operating Characteristic Curve
(AUROC) and the commonly used uncertainty quantification measure of PE to assess the ability of
the proposed method to distinguish between correct and incorrect predictions of the model under
different uncertainty thresholds.

In our experimental investigation, which encompassed six datasets and four models, the results
demonstrate that frequency-based Predictive Entropy (PE) generally outperforms its logit-based
counterpart in terms of performance. Specifically, in the experimental combination of the Qwen2.53B-Instruct model and the MedMCQA dataset, the AUROC value obtained by the frequency-based
method is 2% higher than that achieved by the logit-based method. Meanwhile, under various
user-specified risk levels, the frequency-based method can effectively constrain the miscoverage
rate. Through systematic experimental verification, we not only confirmed the feasibility of using
the modal output as a reference benchmark to quantify the overall uncertainty of the model but also
further demonstrated its potential in improving the effectiveness of uncertainty assessment.
### **2 Related Work**

**Background of CP.** CP [ 1, 18 ], a salient uncertainty quantification methodology in machine learning, ensures predictive reliability by providing prediction intervals or sets. Unlike conventional
methods relying on strict data distribution assumptions, CP operates under the weaker “exchangeability” condition. As a potent and flexible framework, it dispenses with data distribution presuppositions,
anchors on data exchangeability, and leverages non - conformity scores and the exchangeability hypothesis to ensure statistical coverage of generated prediction sets—critical for dependable uncertainty
quantification—while enabling adaptability to real - world scenarios with tenuous or inapplicable
distributional presumptions.

Recent work focuses on constructing prediction sets by calibrating sampling stopping rules and rejection rules, ensuring the inclusion of at least one acceptable response while maintaining distributionfree performance guarantees. Additionally, another line of research has demonstrated that humanmachine collaborative CP can enhance performance in relevant tasks. Furthermore, a separate study
has proposed an approach to building distribution-free prediction sets with finite-sample conditional
guarantees, effectively bridging the gap between marginal and conditional coverage.

**CP in MCQA.** CP has been extensively employed in MCQA tasks, with its core essence lying in
providing uncertainty quantification and reliable performance guarantees for LLMs. Specifically, the
prediction sets constructed by CP are capable of including the correct answer with a user-specified
coverage probability *α*, and this guarantee is independent of the underlying data distribution or model
architecture. Consequently, it is well-suited for LLMs that are costly to retrain or inaccessible through
commercial APIs.

In relevant studies, several lines of research have been explored: some works have achieved
distribution-free uncertainty quantification, verified the role of CP in selective classification, and
evaluated its performance when the exchangeability assumption is violated. Notably, Vishwakarma et
al. (2024) proposed an optimized CP method, which enhances the decision quality and final accuracy
of MCQ tasks by reprompting LLMs to reduce answer options. Barber et al. (2019) investigated the

2


-----

feasibility of achieving conditional coverage under distribution-free conditions and put forward a
variety of relaxation strategies. In addition, Kumar et al. (2023) validated the effectiveness of CP in
MCQA tasks through experiments and found that it exhibits favorable calibration across different
domains.
### **3 Method**

**3.1** **Preliminaries**

This paper focuses on the problem of answer prediction for multiple-choice questions. We partition
the samples into a calibration set *D* cal = *{x* *i* *}* *[n]* *i* =1 [and a test sample] *[ x]* *[n]* [+1] [, where each] *[ x]* *[i]* [ corresponds]
to a true label *y* *i* *[∗]* [. Given a pre-trained classification model] *[ F]* [ with K-classification capability, for]
any input sample *x*, *F* ( *x* ) *y* denotes the output score of the model for label *y* . Let the input question
be *x*, with its valid answer space denoted as *A* = *{a* 1 *, a* 2 *, . . ., a* *K* *}*, where *y* *[∗]* *∈A* represents the
true answer. The output of the model for input *x* is a probability distribution *P* ( *y|x* ) over the answer
space, characterizing the confidence level of each option. The research aims to enhance the reliability
and interpretability of answer prediction by quantifying predictive entropy and controlling error risks.

**3.2** **Conformal Prediction**

**Frequency-based PE** For a specific multiple-choice question, first, *M* independent samples are
performed within the space of its valid answers (ensuring that each sampling result conforms to the
question’s response specifications, such as constraints on the number of options). From this, a sample
set *E* containing *M* candidate answers is obtained. Based on this sample set, the frequency *P* [ˆ] ( *a* ) of
each candidate answer is calculated, and the candidate answer with the highest frequency is selected.

*P* ˆ( *a* ) = [1] (1)

*M* [I][(] *[a]* *[m]* [ =] *[ a]* [)]

Furthermore, based on the empirical frequency distribution constructed from the above *M* samplings,
the frequency-based predictive entropy can be defined as the predictive entropy of this empirical
distribution, with its calculation formula as follows:


PE freq = *−*


*n*
� *P* ˆ *i* ( *a* ) log *b* ˆ *P* *i* ( *a* ) (2)

*i* =1


**Risk Control** CP is a statistical prediction framework capable of providing finite-sample coverage
guarantees. Its core lies in constructing a prediction set that contains the true value, with the
probability that this set includes the true value (coverage rate) being no less than the pre-specified
confidence level 1 *−* *α* . For input from the test set *X* and the corresponding true label *Y*, if the
prediction set is *C* ( *X* ), the coverage rate must satisfy:

P( *Y ∈* *C* ( *X* )) *≥* 1 *−* *α* (3)

This guarantee must hold under the conditions of finite samples and distribution-freeness. For each
sample *x* *i* in the calibration set, we define its non-conformity score as:

*s* *i* = 1 *−* *F* ( *x* *i* ) *y* *i* *[∗]* (4)

where *F* ( *x* *i* ) *y* *i* *[∗]* [is the output score of the model for the true label] *[ y]* *i* *[∗]* [. For the set of non-conformity]
scores *{s* *i* *}* *[n]* *i* =1 [from the calibration set, after sorting them in ascending order, we calculate the]
quantile ˆ *q* corresponding to the quantile point *[|]* [(] *[n]* [+] [1] [)(] *n* [1] *[−][α]* [)] *[|]*, that is:


ˆ
*q* = quantile *{s* *i* *}* *[n]* *i* =1 *[,]* *[|]* [(] *[n]* [ + 1] [)(] [1] *[ −]* *[α]* [)] *[|]*
� *n*

For the test sample ( *x* *n* +1 *, y* ), its non-conformity score is defined as:


(5)
�


*s* *n* +1 ( *x* *n* +1 *, y* ) = 1 *−* *F* ( *x* *n* +1 ) *y* (6)

Based on the above quantile threshold ˆ *q*, the prediction set is constructed as follows:

*C* ( *x* *n* +1 ) = *{y | s* *n* +1 ( *x* *n* +1 *, y* ) *≤* *q* ˆ *}* (7)

3


-----

Table 1: Logit vs Frequency Entropy


(a) MMLU

Model Model logit Sampling set

Qwen2.5-3B-Instruct 0.6266 0.6383
Llama-3.2-1B 0.4909 0.5082
Qwen2.5-7B-Instruct 0.6208 0.6311
Llama-3.1-8B-Instruct 0.8059 0.8215

Vicuna-7b-v1.5 0.6896 0.7041

Vicuna-13b-v1.5 0.7298 0.7346
Average 0.6606 0.6729

(c) MMLU_PRO

Model Model logit Sampling set

Qwen2.5-3B-Instruct 0.6457 0.6553
Llama-3.2-1B 0.5293 0.5285
Qwen2.5-7B-Instruct 0.6524 0.6500
Llama-3.1-8B-Instruct 0.7401 0.7546

Vicuna-7b-v1.5 0.6630 0.6589

Vicuna-13b-v1.5 0.6946 0.6998
Average 0.6542 0.6579


(b) MEDMCQA

Model Model logit Sampling set

Qwen2.5-3B-Instruct 0.6262 0.6462
Llama-3.2-1B 0.5017 0.4796
Qwen2.5-7B-Instruct 0.6289 0.6442
Llama-3.1-8B - Instruct 0.7404 0.7415

Vicuna-7b-v1.5 0.5928 0.6121

Vicuna-13b-v1.5 0.6201 0.6314
Average 0.6183 0.6258

(d) MEDQA

Model Model logit Sampling set

Qwen2.5-3B-Instruct 0.5669 0.5651
Llama-3.2-1B 0.4861 0.4771
Qwen2.5-7B-Instruct 0.5670 0.5645
Llama-3.1-8B-Instruct 0.7687 0.7719

Vicuna-7b-v1.5 0.5725 0.5767

Vicuna-13b-v1.5 0.6306 0.6299
Average 0.5986 0.5975


Assuming that the *n* samples in the calibration set and the test sample *x* *n* +1 satisfy the independent
and identically distributed (i.i.d.) condition, we have:

*i*
P � *s* *n* +1 ( *x* *n* +1 *, y* *n* *[∗]* +1 [)] *[ ≤]* *[s]* *[i]* � = (8)
*n* + 1

Furthermore, the coverage probability of the prediction set satisfies:

P � *y* *n* *[∗]* +1 *[∈]* *[C]* [(] *[x]* *[n]* [+1] [)] � = P � *s* *n* +1 ( *x* *n* +1 *, y* *n* *[∗]* +1 [)] *[ ≤]* *[s]* *⌊* ( *n* +1)(1 *−α* ) *⌋* � = *[⌊]* [(] *[n]* [ + 1] [)(] [1] *[ −]* *[α]* [)] *[⌋]* *≥* 1 *−* *α*

*n* + 1

(9)
That is, the prediction set can guarantee coverage of the true label with a probability of no less than
1 *−* *α* .
### **4 Evaluations**

**4.1** **Experimental Set-up**

**Base LLMs.** We perform empirical evaluations on six large language models (LLMs) with diverse sizes and architectural designs to ensure a comprehensive analysis. The selected models
include Vicuna-7B-v1.5, Vicuna-13B-v1.5, Qwen2.5-3B-Instruct, Qwen2.5-7B-Instruct, Llama3.1-8B-Instruct, and Llama-3.2-1B. For all open-source LLMs, we adopt the default generation
configurations and checkpoints available through the HuggingFace platform.

**Datasets.** To evaluate the efficacy of the proposed method and validate its correctness coverage
guarantees, we employ four datasets: MedMCQA (a large-scale multi-subject, multi-choice medical
question-answering dataset), MedQA (a large-scale open-domain dataset sourced from medical
examinations), MMLU (a comprehensive cross-disciplinary benchmark for assessing LLMs’ general
knowledge and problem-solving abilities), and MMLU-Pro (an enhanced MMLU variant with more
challenging questions to probe the depth of models’ understanding and reasoning).

**Evaluation Metric.** Consistent with prior literature, we assess uncertainty quantification (UQ)
performance by framing it as a task of predicting the trustworthiness of model generations, employing
the AUROC to quantify the discriminative power of uncertainty scores in distinguishing between
correct and incorrect outputs. For validity verification, we compute the empirical miscoverage

4


-----

|diagonal vicuna-7b-v1.5 Qwen2.5-3B-Instruct Llama-3.2-1B Qwen2.5-7B-Instruct Llama-3.1-8B-Instruct vicuna-13b-v1.5|Col2|
|---|---|
|||


0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(b) Colle g e Chemistr y

|diagonal vicuna-7b-v1.5 Qwen2.5-3B-Instruct Llama-3.2-1B Qwen2.5-7B-Instruct Llama-3.1-8B-Instruct|Col2|
|---|---|
|vicuna-13b-v1.5||



0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(f) Computer Security


0.8

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0



|diagonal vicuna-7b-v1.5 Qwen2.5-3B-Instruct Llama-3.2-1B Qwen2.5-7B-Instruct Llama-3.1-8B-Instruct vicuna-13b-v1.5|Col2|
|---|---|
|||


0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(c) Colle g e Medicine

0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(g) Anatomy


0.8

0.6

0.4

0.2

0.0


0.8

0.6

0.4

0.2

0.0


|diagonal vicuna-7b-v1.5 Qwen2.5-3B-Instruct Llama-3.2-1B Qwen2.5-7B-Instruct Llama-3.1-8B-Instruct vicuna-13b-v1.5|Col2|
|---|---|
|||


0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(a) Clinical Knowled g e


0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(d) Professional Medicine


0.8

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0


0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(h) Formal Logic

0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(d) Histor y

0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(h) Law


0.8

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0


0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(e) Machine Learning

0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(a) Health

0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(e) Chemistry


0.8

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0


Figure 1: Empirical Miscoverage Rate on MMLU


0.8

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0


0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(b) Math

0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(f) Biology


0.8

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0


0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(c) Business

0.1 0.2 0.3 0.4 Alpha0.5 0.6 0.7 0.8 0.9

(g) Psychology


Figure 2: Empirical Miscoverage Rate on MMLU Pro

rate (EMR) -defined as the proportion of test samples where the prediction set fails to include the
correct answer - to ensure it adheres to user-specified thresholds. Additionally, we report the average
prediction set size (APSS) as a metric of efficiency, where smaller sizes denote enhanced practical
utility.

**Hyperparameters.** We set the maximum length of generation based on dataset characteristics: 36
tokens for CoQA and TriviaQA, and 1 token for MMLU-Pro, MMLU, MedMCQA, and MedQA, to
align with the nature of their outputs . We randomly sample 20 candidate generations per prompt for
uncertainty quantification, using a temperature of 1.0 for sampling to ensure diverse outputs . The
ratio of calibration to test set is set to 0.5 by default, balancing the need for sufficient calibration data
and reliable test evaluation.

**4.2** **Sampling Frequency as Logit Substitute for Black-Box LLMs UQ**

In black-box LLMs scenarios where internal logits are inaccessible, UQ must rely on observable
outputs. This study investigates whether sampling frequency can substitute logit-based probabilities
(via logits + softmax) as a proxy for predictive entropy, enabling logit-free UQ. Correctness is
determined by the consistency between the most frequent output and the reference answer; effective
uncertainty metrics should distinguish correct from incorrect outputs, aligning with failure prediction
criteria.

Predictive entropy for uncertainty scoring is computed from two probability sources: (1) logitbased probabilities in white-box settings (logits + softmax); (2) frequency-based probabilities in
black-box settings (derived from the most frequent answer across multiple samplings, inspired by selfconsistency theory). Both metrics are evaluated using AUROC to assess their ability to differentiate
correct and incorrect outputs, verifying whether frequency-based predictive entropy—using only

5


-----

0.8

0.6

0.4

0.2

0.0

4.0

3.5

3.0

2.5

2.0

1.5

1.0

0.5

0.0


0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Alpha

(a) MEDMCQA


0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Alpha

(a) MEDMCQA


0.8

0.6

0.4

0.2

0.0


0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Alpha

(b) MEDQA


Figure 3: Empirical Miscoverage Rate


0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Alpha

(b) MEDQA


5

4

3

2

1

0


Figure 4: Average Prediction Set Size

sampled outputs—achieves AUROC comparable to logit-based methods, thus validating sampling
frequency as a viable logit substitute for UQ in black-box LLMs.

Experiments show that frequency-based methods yield AUROC values essentially equivalent to
logit-based counterparts in Table 1. For example, across six models on the MMLU dataset, the
frequency-based approach achieves a 1.2% higher average AUROC, with a 0.7% average increase on
MEDMCQA. These results confirm the feasibility of sampling frequency as a logit substitute for UQ
in black-box LLMs.

**4.3** **Conformal Prediction Coverage**

In this section, based on the theoretical analysis in Equation (9), we analyze the EMR and APSS to
validate the performance of the constructed calibrated prediction sets.

**Emperical miscoverage rate** In this section, based on the theoretical analysis presented in Equation
(9), we conduct a systematic verification of the Empirical Miscoverage Rate (EMR). Specifically,
relying on the conformal framework, we partition the data into a calibration set and a test set at a 1:1
ratio. To ensure the robustness and reliability of the experimental results, for eight subject categories
including Clinical Knowledge, College Chemistry, and College Medicine, we independently repeated
the partitioning process of the calibration and test sets 100 times for each category. For each subject
category, we calculated the mean and standard deviation (mean±std) of the EMR. The experimental
results show that the mean EMR of all subject categories is strictly controlled within the user-specified
alpha threshold. This outcome verifies the effective control of the conformal framework over the
miscoverage rate in practical applications, which is consistent with theoretical expectations.

**Average prediction set size** Building on this, we further investigated the dynamic variation pattern
of Prediction Set Size with respect to the user-specified alpha coverage threshold. Experimental
results demonstrate that as the requirement for coverage guarantees gradually increases, the size of the
prediction set exhibits a significant upward trend. This phenomenon is highly consistent with intuitive

6


-----

cognition: the expansion of the prediction set implies a corresponding increase in the probability of
containing the correct answer, thereby meeting higher coverage requirements. Notably, under the
same level of coverage guarantee, there exists a clear negative correlation between model performance
and prediction set size — superior-performing models can achieve the equivalent coverage target
with a smaller prediction set, which directly reflects lower uncertainty in their output results and
higher decision-making reliability. This finding not only verifies the intrinsic connection between
model performance and the compactness of prediction sets but also provides empirical support for
measuring model uncertainty through set size.
### **5 Conclusion**

This study focuses on the problem of uncertainty quantification for LLMs in MCQA tasks under
black-box settings. It proposes a frequency-based Predictive Entropy (PE) method, which quantifies
uncertainty by taking the most frequent sample as a reference through multiple independent samplings
of the model’s output distribution. Combined with the CP framework, this method constructs
prediction sets aiming to ensure that the prediction sets have provable coverage guarantees.

Experimental results demonstrate that across six models and four datasets (MedMCQA, MedQA,
MMLU, and MMLU-Pro), the frequency-based PE generally outperforms the logit-based method in
terms of uncertainty quantification performance as measured by AUROC. Moreover, it can effectively
control the empirical miscoverage rate under various user-specified risk levels. This confirms that
sampling frequency can serve as a viable alternative to logit-based probabilities in black-box LLMs,
providing an effective means of uncertainty quantification for scenarios where internal logits are
inaccessible.
### **References**

[1] Anastasios N Angelopoulos and Stephen Bates. A gentle introduction to conformal prediction
and distribution-free uncertainty quantification. *arXiv preprint arXiv:2107.07511*, 2021.

[2] Anastasios N Angelopoulos, Stephen Bates, Emmanuel J Candès, Michael I Jordan, and Lihua
Lei. Learn then test: Calibrating predictive algorithms to achieve risk control. *The Annals of*
*Applied Statistics*, 2025.

[3] Anastasios Nikolas Angelopoulos, Stephen Bates, Adam Fisch, Lihua Lei, and Tal Schuster.
Conformal risk control. In *The Twelfth International Conference on Learning Representations*,
2024.

[4] Jinhe Bi, Yifan Wang, Danqi Yan, Xun Xiao, Artur Hecker, Volker Tresp, and Yunpu Ma. Prism:
Self-pruning intrinsic selection method for training-free multimodal data selection. *arXiv*
*preprint arXiv:2502.12119*, 2025.

[5] Jinhe Bi, Yujun Wang, Haokun Chen, Xun Xiao, Artur Hecker, Volker Tresp, and Yunpu Ma.
LLaVA steering: Visual instruction tuning with 500x fewer parameters through modality linear
representation-steering. In *Proceedings of the 63rd Annual Meeting of the Association for*
*Computational Linguistics (Volume 1: Long Papers)*, 2025.

[6] Jinhe Bi, Danqi Yan, Yifan Wang, Wenke Huang, Haokun Chen, Guancheng Wan, Mang Ye,
Xun Xiao, Hinrich Schuetze, Volker Tresp, et al. Cot-kinetics: A theoretical modeling assessing
lrm reasoning process. *arXiv preprint arXiv:2505.13408*, 2025.

[7] Neeloy Chakraborty, Melkior Ornik, and Katherine Driggs-Campbell. Hallucination detection
in foundation models for decision-making: A flexible definition and review of the state of the
art. *ACM Computing Surveys*, 2025.

[8] Haokun Chen, Hang Li, Yao Zhang, Jinhe Bi, Gengyuan Zhang, Yueqi Zhang, Philip Torr,
Jindong Gu, Denis Krompass, and Volker Tresp. Fedbip: Heterogeneous one-shot federated
learning with personalized latent diffusion models. In *Proceedings of the Computer Vision and*
*Pattern Recognition Conference (CVPR)*, 2025.

7


-----

[9] Haokun Chen, Yueqi Zhang, Yuan Bi, Yao Zhang, Tong Liu, Jinhe Bi, Jian Lan, Jindong
Gu, Claudia Grosser, Denis Krompass, et al. Does machine unlearning truly remove model
knowledge? a framework for auditing unlearning in llms. *arXiv preprint arXiv:2505.23270*,
2025.

[10] Vasily Kostumov, Bulat Nutfullin, Oleg Pilipenko, and Eugene Ilyushin. Uncertainty-aware
evaluation for vision-language models. *arXiv preprint arXiv:2402.14418*, 2024.

[11] Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. Semantic uncertainty: Linguistic invariances
for uncertainty estimation in natural language generation. In *The Eleventh International*
*Conference on Learning Representations*, 2023.

[12] Xin Qiu and Risto Miikkulainen. Semantic density: Uncertainty quantification for large
language models through confidence measurement in semantic space. *Advances in neural*
*information processing systems*, 2024.

[13] Xuankun Rong, Wenke Huang, Jian Liang, Jinhe Bi, Xun Xiao, Yiming Li, Bo Du, and
Mang Ye. Backdoor cleaning without external guidance in mllm fine-tuning. *arXiv preprint*
*arXiv:2505.16916*, 2025.

[14] Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Mohamed Amin, Le Hou,
Kevin Clark, Stephen R Pfohl, Heather Cole-Lewis, et al. Toward expert-level medical question
answering with large language models. *Nature Medicine*, 2025.

[15] Qingni Wang, Tiantian Geng, Zhiyuan Wang, Teng Wang, Bo Fu, and Feng Zheng. Sample then
identify: A general framework for risk control and assessment in multimodal large language
models. In *The Thirteenth International Conference on Learning Representations*, 2025.

[16] Yujun Wang, Jinhe Bi, Yunpu Ma, and Soeren Pirk. Ascd: Attention-steerable contrastive
decoding for reducing hallucination in mllm. *arXiv preprint arXiv:2506.14766*, 2025.

[17] Zhiyuan Wang, Jinhao Duan, Lu Cheng, Yue Zhang, Qingni Wang, Xiaoshuang Shi, Kaidi Xu,
Heng Tao Shen, and Xiaofeng Zhu. Conu: Conformal uncertainty in large language models with
correctness coverage guarantees. In *Findings of the Association for Computational Linguistics:*
*EMNLP 2024*, 2024.

[18] Zhiyuan Wang, Jinhao Duan, Qingni Wang, Xiaofeng Zhu, Tianlong Chen, Xiaoshuang Shi,
and Kaidi Xu. Coin: Uncertainty-guarding selective question answering for foundation models
with provable risk guarantees. *arXiv preprint arXiv:2506.20178*, 2025.

[19] Zhiyuan Wang, Jinhao Duan, Chenxi Yuan, Qingyu Chen, Tianlong Chen, Yue Zhang, Ren
Wang, Xiaoshuang Shi, and Kaidi Xu. Word-sequence entropy: Towards uncertainty estimation
in free-form medical question answering applications and beyond. *Engineering Applications of*
*Artificial Intelligence*, 2025.

[20] Zhiyuan Wang, Qingni Wang, Yue Zhang, Tianlong Chen, Xiaofeng Zhu, Xiaoshuang Shi, and
Kaidi Xu. SConU: Selective conformal uncertainty in large language models. In *Proceedings*
*of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long*
*Papers)*, 2025.

[21] Fanghua Ye, Mingming Yang, Jianhui Pang, Longyue Wang, Derek Wong, Emine Yilmaz,
Shuming Shi, and Zhaopeng Tu. Benchmarking llms via uncertainty quantification. *Advances*
*in Neural Information Processing Systems*, 37:15356–15385, 2024.

[22] Gengyuan Zhang, Jinhe Bi, Jindong Gu, Yanyu Chen, and Volker Tresp. Spot! revisiting
video-language models for event understanding. *arXiv preprint arXiv:2311.12919*, 2023.

8


-----


